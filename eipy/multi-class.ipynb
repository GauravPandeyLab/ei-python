{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "import eipy.utils\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import  datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is multi-class, run a check on the allowable base and meta models.\n",
    "\n",
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}\n",
    "natively_multi_class_predictors = [\"XGBClassifier\",\n",
    "\"BernoulliNB\",\n",
    "\"DecisionTreeClassifier\",\n",
    "\"ExtraTreeClassifier\",\n",
    "\"GaussianNB\",\n",
    "\"KNeighborsClassifier\",\n",
    "\"LabelPropagation\",\n",
    "\"LabelSpreading\",\n",
    "\"LinearDiscriminantAnalysis\",\n",
    "\"LinearSVC\", #(setting multi_class=”crammer_singer”)\n",
    "\"LogisticRegression\", #(setting multi_class=”multinomial”)\n",
    "\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\n",
    "\"MLPClassifier\",\n",
    "\"NearestCentroid\",\n",
    "\"QuadraticDiscriminantAnalysis\",\n",
    "\"RadiusNeighborsClassifier\",\n",
    "\"RandomForestClassifier\",\n",
    "\"RidgeClassifier\",\n",
    "\"RidgeClassifierCV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGB': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "               num_parallel_tree=None, random_state=None, ...),\n",
       " 'DT': DecisionTreeClassifier(),\n",
       " 'RF': RandomForestClassifier(),\n",
       " 'KNN': KNeighborsClassifier(),\n",
       " 'LR': LogisticRegression(),\n",
       " 'NB': GaussianNB(),\n",
       " 'MLP': MLPClassifier()}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\n",
    "base_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "multi modal multi-class toy data generation\"\"\"\n",
    "\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "modality_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "modality_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "modality_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_train, y_test = train_test_split(modality_0, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_1_train, X_1_test, _,_ = train_test_split(modality_1, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_2_train, X_2_test, _,_ = train_test_split(modality_2, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,  #balanced classes\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |          |  0%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [720, 112]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, modality \u001b[39min\u001b[39;00m data_train\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     EI\u001b[39m.\u001b[39;49mtrain_base(modality, y_train, modality_name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/eipy/eipy/ei.py:224\u001b[0m, in \u001b[0;36mEnsembleIntegration.train_base\u001b[0;34m(self, X, y, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_base(\n\u001b[1;32m    218\u001b[0m             X\u001b[39m=\u001b[39mmodality,\n\u001b[1;32m    219\u001b[0m             y\u001b[39m=\u001b[39my,\n\u001b[1;32m    220\u001b[0m             base_predictors\u001b[39m=\u001b[39mbase_predictors,\n\u001b[1;32m    221\u001b[0m             modality_name\u001b[39m=\u001b[39mmodality_name,\n\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_base(\n\u001b[1;32m    225\u001b[0m         X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, base_predictors\u001b[39m=\u001b[39;49mbase_predictors, modality_name\u001b[39m=\u001b[39;49mmodality_name\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/_testing.py:188\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    187\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategory)\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/eipy/eipy/ei.py:372\u001b[0m, in \u001b[0;36mEnsembleIntegration._train_base\u001b[0;34m(self, X, y, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names[modality_name] \u001b[39m=\u001b[39m feature_names\n\u001b[1;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_per_modality\u001b[39m.\u001b[39mappend(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 372\u001b[0m meta_training_data_modality \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_base_inner(\n\u001b[1;32m    373\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    374\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    375\u001b[0m     cv_outer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv_outer,\n\u001b[1;32m    376\u001b[0m     cv_inner\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv_inner,\n\u001b[1;32m    377\u001b[0m     base_predictors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_predictors,\n\u001b[1;32m    378\u001b[0m     modality_name\u001b[39m=\u001b[39;49mmodality_name,\n\u001b[1;32m    379\u001b[0m )\n\u001b[1;32m    381\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_training_data \u001b[39m=\u001b[39m append_modality(\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_training_data, meta_training_data_modality\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m meta_test_data_modality \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_base_outer(\n\u001b[1;32m    386\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    387\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     modality_name\u001b[39m=\u001b[39mmodality_name,\n\u001b[1;32m    391\u001b[0m )\n",
      "File \u001b[0;32m~/eipy/eipy/ei.py:455\u001b[0m, in \u001b[0;36mEnsembleIntegration._train_base_inner\u001b[0;34m(self, X, y, cv_outer, cv_inner, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39m# define joblib Parallel function\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mwith\u001b[39;00m Parallel(\n\u001b[1;32m    453\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, backend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_backend\n\u001b[1;32m    454\u001b[0m ) \u001b[39mas\u001b[39;00m parallel:\n\u001b[0;32m--> 455\u001b[0m     \u001b[39mfor\u001b[39;00m _outer_fold_id, (train_index_outer, _test_index_outer) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m    456\u001b[0m         tqdm(\n\u001b[1;32m    457\u001b[0m             cv_outer\u001b[39m.\u001b[39msplit(X, y),\n\u001b[1;32m    458\u001b[0m             total\u001b[39m=\u001b[39mcv_outer\u001b[39m.\u001b[39mn_splits,\n\u001b[1;32m    459\u001b[0m             desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating meta training data\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m             bar_format\u001b[39m=\u001b[39mbar_format,\n\u001b[1;32m    461\u001b[0m         )\n\u001b[1;32m    462\u001b[0m     ):\n\u001b[1;32m    463\u001b[0m         X_train_outer \u001b[39m=\u001b[39m X[train_index_outer]\n\u001b[1;32m    464\u001b[0m         y_train_outer \u001b[39m=\u001b[39m y[train_index_outer]\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/model_selection/_split.py:342\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m        The testing set indices for that split.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    343\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m>\u001b[39m n_samples:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [720, 112]"
     ]
    }
   ],
   "source": [
    "for name, modality in data_train.items():\n",
    "    EI.train_base(modality, y_train, modality_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[modality       Modality_0                                                \\\n",
       " base predictor        XGB   DT    RF  KNN        LR        NB       MLP   \n",
       " sample                  0    0     0    0         0         0         0   \n",
       " 0                0.044526  0.0  0.10  0.0  0.495549  0.423774  0.549981   \n",
       " 1                1.757155  2.0  1.18  1.2  0.600471  0.511809  0.701635   \n",
       " 2                1.378124  2.0  1.30  1.2  1.211018  1.346906  1.170763   \n",
       " 3                1.088317  1.0  1.17  0.8  1.318650  1.494532  1.346982   \n",
       " 4                1.535636  0.0  1.06  1.2  1.076944  0.927887  0.941663   \n",
       " ..                    ...  ...   ...  ...       ...       ...       ...   \n",
       " 571              0.200107  0.0  0.28  0.4  0.359004  0.473228  0.559008   \n",
       " 572              1.268022  0.0  0.37  0.4  0.938294  0.679345  0.797289   \n",
       " 573              1.095236  1.0  1.29  1.2  1.171297  1.181220  1.230057   \n",
       " 574              0.016178  0.0  0.32  0.4  0.457635  0.685845  0.644829   \n",
       " 575              1.039414  1.0  1.19  1.2  1.178274  1.212520  1.223301   \n",
       " \n",
       " modality       Modality_1             ...                     Modality_2       \\\n",
       " base predictor        XGB   DT    RF  ...        NB       MLP        XGB   DT   \n",
       " sample                  0    0     0  ...         0         0          0    0   \n",
       " 0                0.679300  1.0  0.45  ...  0.294772  0.261542   1.918100  2.0   \n",
       " 1                0.861120  1.0  0.68  ...  0.269601  0.371603   0.939812  1.0   \n",
       " 2                1.993842  2.0  1.97  ...  1.780098  1.790380   0.331310  1.0   \n",
       " 3                1.997459  2.0  1.96  ...  1.780628  1.779909   1.982537  2.0   \n",
       " 4                0.131799  0.0  0.20  ...  0.261187  0.341476   1.212622  2.0   \n",
       " ..                    ...  ...   ...  ...       ...       ...        ...  ...   \n",
       " 571              0.200235  0.0  0.26  ...  0.251558  0.399700   0.311472  0.0   \n",
       " 572              0.201025  0.0  0.27  ...  0.266151  0.337410   0.845066  0.0   \n",
       " 573              1.988163  2.0  1.91  ...  1.792257  1.761787   1.949401  2.0   \n",
       " 574              0.627723  0.0  0.56  ...  0.474593  0.330625   0.824364  1.0   \n",
       " 575              1.239446  2.0  1.53  ...  1.016077  0.971436   1.616497  2.0   \n",
       " \n",
       " modality                                                labels  \n",
       " base predictor    RF  KNN        LR        NB       MLP         \n",
       " sample             0    0         0         0         0         \n",
       " 0               1.51  1.2  1.088294  1.406070  1.298738      0  \n",
       " 1               0.73  0.8  0.708506  0.730440  0.675458      0  \n",
       " 2               0.40  0.6  0.741962  0.747175  0.662919      1  \n",
       " 3               1.81  1.6  1.278027  1.535725  1.365072      2  \n",
       " 4               0.98  1.6  1.273077  1.526033  1.356107      0  \n",
       " ..               ...  ...       ...       ...       ...    ...  \n",
       " 571             0.32  0.4  0.674767  0.687689  0.676980      0  \n",
       " 572             0.57  0.6  0.754814  0.721792  0.672704      0  \n",
       " 573             1.59  1.6  1.415584  1.551677  1.409011      2  \n",
       " 574             0.76  0.8  0.674120  0.656219  0.674216      0  \n",
       " 575             1.38  1.6  1.238299  1.509836  1.314947      2  \n",
       " \n",
       " [576 rows x 22 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor        XGB   DT    RF  KNN        LR        NB       MLP   \n",
       " sample                  0    0     0    0         0         0         0   \n",
       " 0                1.961282  2.0  1.69  1.4  1.269104  1.380538  1.269711   \n",
       " 1                1.960305  2.0  1.67  1.4  1.130505  1.299093  1.200222   \n",
       " 2                1.912226  2.0  1.36  0.8  0.445477  0.469482  0.631444   \n",
       " 3                1.399315  2.0  0.78  0.4  1.189260  1.181006  1.139296   \n",
       " 4                0.306105  0.0  0.64  0.8  0.414216  0.503822  0.606330   \n",
       " ..                    ...  ...   ...  ...       ...       ...       ...   \n",
       " 571              0.211578  0.0  0.18  0.8  0.431426  0.575619  0.682759   \n",
       " 572              1.075029  1.0  1.08  1.2  1.269604  1.231989  1.275159   \n",
       " 573              1.000926  1.0  1.06  1.0  1.193481  1.201342  1.225871   \n",
       " 574              1.020639  1.0  1.34  1.4  1.154047  1.218420  1.219883   \n",
       " 575              1.403477  1.0  1.24  1.2  1.175103  1.207633  1.227759   \n",
       " \n",
       " modality       Modality_1             ...                     Modality_2       \\\n",
       " base predictor        XGB   DT    RF  ...        NB       MLP        XGB   DT   \n",
       " sample                  0    0     0  ...         0         0          0    0   \n",
       " 0                1.642483  2.0  1.60  ...  1.745399  1.646550   0.962276  0.0   \n",
       " 1                0.030376  0.0  0.12  ...  0.229725  0.341186   0.081169  0.0   \n",
       " 2                0.007352  0.0  0.09  ...  0.224379  0.324968   0.512208  0.0   \n",
       " 3                0.112972  1.0  1.50  ...  0.939558  0.919486   0.906936  0.0   \n",
       " 4                0.229255  0.0  0.19  ...  0.314411  0.443194   1.996882  2.0   \n",
       " ..                    ...  ...   ...  ...       ...       ...        ...  ...   \n",
       " 571              0.185162  0.0  0.26  ...  0.265562  0.395417   0.700252  1.0   \n",
       " 572              0.027553  1.0  0.36  ...  0.321212  0.481653   0.983941  1.0   \n",
       " 573              1.979634  2.0  1.97  ...  1.791809  1.727058   0.611824  2.0   \n",
       " 574              0.668575  0.0  0.58  ...  0.233722  0.330784   0.966878  1.0   \n",
       " 575              1.731282  2.0  1.64  ...  1.044228  0.990077   1.879419  2.0   \n",
       " \n",
       " modality                                                labels  \n",
       " base predictor    RF  KNN        LR        NB       MLP         \n",
       " sample             0    0         0         0         0         \n",
       " 0               0.65  0.6  0.782731  0.634346  0.771495      1  \n",
       " 1               0.40  0.6  0.686704  0.556181  0.640768      1  \n",
       " 2               0.42  0.8  1.545139  1.441614  1.455970      0  \n",
       " 3               0.90  1.2  0.901997  0.940559  1.031282      2  \n",
       " 4               1.93  2.0  1.428606  1.630814  1.452146      0  \n",
       " ..               ...  ...       ...       ...       ...    ...  \n",
       " 571             0.54  0.8  0.700749  0.691380  0.672520      0  \n",
       " 572             0.94  1.0  0.691321  0.646287  0.667056      1  \n",
       " 573             1.24  1.6  1.383905  1.492944  1.444999      2  \n",
       " 574             0.84  0.6  0.701507  0.613203  0.678933      1  \n",
       " 575             1.68  1.6  1.230671  1.449661  1.355601      2  \n",
       " \n",
       " [576 rows x 22 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor        XGB   DT    RF  KNN        LR        NB       MLP   \n",
       " sample                  0    0     0    0         0         0         0   \n",
       " 0                0.170053  0.0  0.54  0.4  0.563187  0.486593  0.649697   \n",
       " 1                1.616934  0.0  0.96  1.2  0.614777  0.539462  0.634695   \n",
       " 2                0.963995  0.0  0.52  0.6  1.199640  1.220881  1.153484   \n",
       " 3                1.241043  2.0  1.25  0.8  1.076137  0.905096  0.850501   \n",
       " 4                0.637119  0.0  0.72  0.8  0.939582  0.651757  0.739522   \n",
       " ..                    ...  ...   ...  ...       ...       ...       ...   \n",
       " 571              0.015611  0.0  0.33  0.2  1.137343  1.190266  1.033077   \n",
       " 572              0.213024  2.0  0.54  0.0  0.560393  0.419564  0.606041   \n",
       " 573              0.968866  0.0  0.50  0.4  0.646624  0.544017  0.695950   \n",
       " 574              0.298357  0.0  0.66  0.4  0.432012  0.652913  0.614979   \n",
       " 575              1.191236  0.0  0.48  0.0  0.338373  0.469853  0.557885   \n",
       " \n",
       " modality       Modality_1             ...                     Modality_2       \\\n",
       " base predictor        XGB   DT    RF  ...        NB       MLP        XGB   DT   \n",
       " sample                  0    0     0  ...         0         0          0    0   \n",
       " 0                0.001517  1.0  0.22  ...  0.223685  0.186611   1.879354  0.0   \n",
       " 1                0.281293  1.0  0.37  ...  0.298100  0.407150   0.892096  1.0   \n",
       " 2                0.448324  2.0  1.84  ...  0.937997  0.916269   1.693319  0.0   \n",
       " 3                0.082630  0.0  0.16  ...  0.275138  0.354164   1.976717  2.0   \n",
       " 4                1.859272  2.0  1.84  ...  1.763060  1.706411   1.653496  2.0   \n",
       " ..                    ...  ...   ...  ...       ...       ...        ...  ...   \n",
       " 571              0.242460  0.0  0.34  ...  0.244633  0.342743   0.175367  0.0   \n",
       " 572              0.364255  1.0  0.45  ...  0.283893  0.312074   1.722891  0.0   \n",
       " 573              1.892973  2.0  1.77  ...  1.739444  1.630326   1.818629  2.0   \n",
       " 574              0.719967  1.0  0.47  ...  0.399606  0.279472   0.936871  1.0   \n",
       " 575              1.936610  2.0  1.57  ...  1.787718  1.698744   1.442117  0.0   \n",
       " \n",
       " modality                                                labels  \n",
       " base predictor    RF  KNN        LR        NB       MLP         \n",
       " sample             0    0         0         0         0         \n",
       " 0               1.68  0.8  1.066789  1.379764  1.250984      0  \n",
       " 1               0.90  0.8  0.694132  0.688323  0.638992      0  \n",
       " 2               1.38  1.6  0.873189  0.943930  1.074587      2  \n",
       " 3               1.38  1.6  1.242794  1.495466  1.324600      0  \n",
       " 4               1.42  1.2  1.083100  1.389445  1.271850      2  \n",
       " ..               ...  ...       ...       ...       ...    ...  \n",
       " 571             1.28  1.2  1.555567  1.428855  1.419597      0  \n",
       " 572             0.72  1.6  1.558825  1.468260  1.428520      0  \n",
       " 573             1.46  1.6  1.160577  1.439238  1.324141      2  \n",
       " 574             0.90  0.8  0.714592  0.693341  0.701580      0  \n",
       " 575             1.75  1.2  1.384720  1.478368  1.336502      2  \n",
       " \n",
       " [576 rows x 22 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor        XGB   DT    RF  KNN        LR        NB       MLP   \n",
       " sample                  0    0     0    0         0         0         0   \n",
       " 0                0.327015  0.0  0.54  0.8  0.528481  0.452470  0.635117   \n",
       " 1                0.270400  0.0  0.33  0.8  1.060593  0.841301  0.949182   \n",
       " 2                0.161500  0.0  0.37  0.0  1.011627  0.838828  0.797938   \n",
       " 3                1.966029  2.0  1.69  1.8  1.271053  1.276837  1.370677   \n",
       " 4                0.044797  0.0  0.65  0.4  1.244907  1.281243  1.224765   \n",
       " ..                    ...  ...   ...  ...       ...       ...       ...   \n",
       " 571              0.075461  0.0  0.26  0.8  1.110851  1.096939  1.012368   \n",
       " 572              0.335619  2.0  0.74  0.0  0.587171  0.460671  0.634001   \n",
       " 573              1.012562  1.0  1.06  1.0  1.161987  1.168906  1.193821   \n",
       " 574              0.161638  0.0  0.74  0.0  0.457284  0.641272  0.610081   \n",
       " 575              0.090807  0.0  0.28  0.0  0.372522  0.518787  0.529171   \n",
       " \n",
       " modality       Modality_1             ...                     Modality_2       \\\n",
       " base predictor        XGB   DT    RF  ...        NB       MLP        XGB   DT   \n",
       " sample                  0    0     0  ...         0         0          0    0   \n",
       " 0                0.002450  0.0  0.10  ...  0.296674  0.253308   1.967054  2.0   \n",
       " 1                0.122595  1.0  0.51  ...  0.259373  0.282123   1.819784  2.0   \n",
       " 2                1.036112  2.0  1.32  ...  1.031334  1.029485   1.863377  0.0   \n",
       " 3                0.074242  0.0  0.51  ...  0.323588  0.474486   0.199371  0.0   \n",
       " 4                0.090888  1.0  1.08  ...  0.894501  0.876726   1.611712  0.0   \n",
       " ..                    ...  ...   ...  ...       ...       ...        ...  ...   \n",
       " 571              0.258439  0.0  0.54  ...  0.269298  0.441425   0.499069  0.0   \n",
       " 572              0.506974  1.0  0.41  ...  0.267666  0.262289   0.069774  0.0   \n",
       " 573              1.902965  2.0  1.75  ...  1.786331  1.744453   1.937812  2.0   \n",
       " 574              0.092457  0.0  0.61  ...  0.353097  0.209073   0.877985  1.0   \n",
       " 575              1.968522  2.0  1.94  ...  1.752659  1.677988   1.728517  2.0   \n",
       " \n",
       " modality                                                labels  \n",
       " base predictor    RF  KNN        LR        NB       MLP         \n",
       " sample             0    0         0         0         0         \n",
       " 0               1.92  1.6  1.119746  1.423149  1.299609      0  \n",
       " 1               0.96  1.6  1.649766  1.463586  1.477210      0  \n",
       " 2               1.17  1.2  1.427199  1.576792  1.401493      2  \n",
       " 3               0.42  0.4  0.763486  0.749232  0.677876      1  \n",
       " 4               0.68  0.8  0.860649  0.891133  0.989711      2  \n",
       " ..               ...  ...       ...       ...       ...    ...  \n",
       " 571             0.78  0.8  1.634997  1.511595  1.540792      0  \n",
       " 572             0.54  0.8  1.610228  1.493968  1.525835      0  \n",
       " 573             1.72  1.2  1.360809  1.511408  1.382403      2  \n",
       " 574             0.83  0.6  0.666316  0.626831  0.638765      0  \n",
       " 575             1.66  1.2  1.375355  1.502476  1.373928      2  \n",
       " \n",
       " [576 rows x 22 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor        XGB   DT    RF  KNN        LR        NB       MLP   \n",
       " sample                  0    0     0    0         0         0         0   \n",
       " 0                0.270623  0.0  0.52  0.4  0.568229  0.479652  0.616400   \n",
       " 1                0.989175  0.0  0.82  0.8  0.642121  0.524438  0.703994   \n",
       " 2                1.613568  2.0  0.56  0.0  1.073256  0.907493  0.900654   \n",
       " 3                1.723828  2.0  1.37  1.2  1.252326  1.244473  1.322529   \n",
       " 4                0.853231  0.0  0.78  0.4  1.229726  1.281903  1.186809   \n",
       " ..                    ...  ...   ...  ...       ...       ...       ...   \n",
       " 571              1.164888  2.0  0.89  0.6  1.167087  1.248405  1.108510   \n",
       " 572              0.120841  0.0  0.63  0.4  0.914444  0.618801  0.794747   \n",
       " 573              1.124954  1.0  1.33  1.0  1.307668  1.476038  1.289933   \n",
       " 574              1.988787  0.0  1.20  1.2  1.188901  1.302886  1.150828   \n",
       " 575              1.750497  1.0  1.46  1.4  1.205490  1.210688  1.268176   \n",
       " \n",
       " modality       Modality_1             ...                     Modality_2       \\\n",
       " base predictor        XGB   DT    RF  ...        NB       MLP        XGB   DT   \n",
       " sample                  0    0     0  ...         0         0          0    0   \n",
       " 0                0.006452  0.0  0.14  ...  0.328198  0.322247   1.998386  2.0   \n",
       " 1                0.827748  1.0  0.72  ...  0.263524  0.303045   0.712425  1.0   \n",
       " 2                1.268925  1.0  1.26  ...  0.990009  1.013519   1.815369  0.0   \n",
       " 3                0.079034  0.0  0.32  ...  0.307488  0.459838   0.890989  1.0   \n",
       " 4                0.043274  2.0  1.00  ...  0.856309  0.858618   1.488257  2.0   \n",
       " ..                    ...  ...   ...  ...       ...       ...        ...  ...   \n",
       " 571              0.433278  0.0  0.51  ...  0.225389  0.326624   0.876953  0.0   \n",
       " 572              0.634351  1.0  0.42  ...  0.253349  0.325780   0.573946  0.0   \n",
       " 573              1.721320  2.0  1.70  ...  1.696162  1.688556   1.640514  0.0   \n",
       " 574              0.174586  0.0  0.14  ...  0.490866  0.569373   1.931040  2.0   \n",
       " 575              1.289226  2.0  1.45  ...  1.007935  0.983136   1.944671  2.0   \n",
       " \n",
       " modality                                                labels  \n",
       " base predictor    RF  KNN        LR        NB       MLP         \n",
       " sample             0    0         0         0         0         \n",
       " 0               1.83  1.2  1.073767  1.393860  1.290314      0  \n",
       " 1               0.76  0.6  0.684575  0.684110  0.629749      0  \n",
       " 2               1.33  1.2  1.358368  1.534205  1.372826      2  \n",
       " 3               0.70  0.6  0.764514  0.724097  0.648519      1  \n",
       " 4               0.82  0.8  0.879484  0.925153  1.038140      2  \n",
       " ..               ...  ...       ...       ...       ...    ...  \n",
       " 571             1.17  1.2  1.519965  1.353444  1.350804      0  \n",
       " 572             0.54  0.6  0.783155  0.735701  0.663532      0  \n",
       " 573             1.50  1.2  0.975942  1.173954  1.234741      2  \n",
       " 574             1.61  2.0  1.358843  1.529272  1.365611      0  \n",
       " 575             1.82  2.0  1.165373  1.476238  1.245877      2  \n",
       " \n",
       " [576 rows x 22 columns]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00981237, 0.0276197 , 0.96256793],\n",
       "        [0.00948382, 0.98086462, 0.00965155],\n",
       "        [0.96882308, 0.0189461 , 0.01223082],\n",
       "        [0.01033915, 0.00398004, 0.98568081],\n",
       "        [0.96210977, 0.02622078, 0.01166945]]),\n",
       " array([0.0276197 , 0.98086462, 0.0189461 , 0.00398004, 0.02622078]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}\n",
    "model = base_predictors[\"SVM\"]\n",
    "model.fit(X_train,y_train)\n",
    "y_pred  = model.predict_proba(X_test)\n",
    "y_pred[:5],y_pred[:, 1][:5]\n",
    "\n",
    "#print(y_pred[:5])\n",
    "#y_pred = [max(range(len(prob)), key=lambda i: prob[i]) for prob in y_pred] #change all probability vectors to predictions for scoring\n",
    "#print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m precision_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
