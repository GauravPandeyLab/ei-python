{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "import eipy.utils as ut\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is multi-class, run a check on the allowable base and meta models.\n",
    "\n",
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor filtering base predictors by whether or not they rely on heursitics for multiclass extension\\n\\nnatively_multi_class_predictors = [\"XGBClassifier\",\\n\"BernoulliNB\",\\n\"DecisionTreeClassifier\",\\n\"ExtraTreeClassifier\",\\n\"GaussianNB\",\\n\"KNeighborsClassifier\",\\n\"LabelPropagation\",\\n\"LabelSpreading\",\\n\"LinearDiscriminantAnalysis\",\\n\"LinearSVC\", #(setting multi_class=”crammer_singer”)\\n\"LogisticRegression\", #(setting multi_class=”multinomial”)\\n\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\\n\"MLPClassifier\",\\n\"NearestCentroid\",\\n\"QuadraticDiscriminantAnalysis\",\\n\"RadiusNeighborsClassifier\",\\n\"RandomForestClassifier\",\\n\"RidgeClassifier\",\\n\"RidgeClassifierCV\"]\\n\\nbase_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "For filtering base predictors by whether or not they rely on heursitics for multiclass extension\n",
    "\n",
    "natively_multi_class_predictors = [\"XGBClassifier\",\n",
    "\"BernoulliNB\",\n",
    "\"DecisionTreeClassifier\",\n",
    "\"ExtraTreeClassifier\",\n",
    "\"GaussianNB\",\n",
    "\"KNeighborsClassifier\",\n",
    "\"LabelPropagation\",\n",
    "\"LabelSpreading\",\n",
    "\"LinearDiscriminantAnalysis\",\n",
    "\"LinearSVC\", #(setting multi_class=”crammer_singer”)\n",
    "\"LogisticRegression\", #(setting multi_class=”multinomial”)\n",
    "\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\n",
    "\"MLPClassifier\",\n",
    "\"NearestCentroid\",\n",
    "\"QuadraticDiscriminantAnalysis\",\n",
    "\"RadiusNeighborsClassifier\",\n",
    "\"RandomForestClassifier\",\n",
    "\"RidgeClassifier\",\n",
    "\"RidgeClassifierCV\"]\n",
    "\n",
    "base_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "multi modal multi-class toy data generation\"\"\"\n",
    "\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "modality_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "modality_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "modality_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "X = np.concatenate([modality_0,modality_1,modality_2], axis=1)\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test = X_train[:, 0:2], X_test[:, 0:2]\n",
    "X_1_train, X_1_test = X_train[:, 2:4], X_test[:, 2:4]\n",
    "X_2_train, X_2_test = X_train[:, 4:], X_test[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on None...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EI.train_base(X=data_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': modality       Modality_0                                                    \\\n",
       " base predictor       ADAB        DT        GB       KNN        LR       MLP   \n",
       " precision        0.525585  0.525310  0.554165  0.518227  0.565432  0.561388   \n",
       " recall           0.663835  0.525739  0.602771  0.565332  0.592944  0.629683   \n",
       " f1               0.533093  0.525519  0.566932  0.534460  0.575164  0.568177   \n",
       " \n",
       " modality                                               Modality_1            \\\n",
       " base predictor        NB        RF       SVM       XGB       ADAB        DT   \n",
       " precision       0.560510  0.534797  0.544832  0.543818   0.441781  0.557991   \n",
       " recall          0.622572  0.572382  0.622702  0.563717   0.666667  0.552616   \n",
       " f1              0.569864  0.548096  0.556542  0.552061   0.531397  0.555141   \n",
       " \n",
       " modality                                                                    \\\n",
       " base predictor        GB       KNN        LR       MLP        NB        RF   \n",
       " precision       0.555493  0.552677  0.544718  0.516430  0.522522  0.546730   \n",
       " recall          0.599758  0.590046  0.567101  0.624773  0.601722  0.577469   \n",
       " f1              0.568018  0.563863  0.553786  0.537811  0.542195  0.558053   \n",
       " \n",
       " modality                           Modality_2                                \\\n",
       " base predictor       SVM       XGB       ADAB        DT        GB       KNN   \n",
       " precision       0.545695  0.556619   0.616729  0.539454  0.572977  0.568208   \n",
       " recall          0.636942  0.562837   0.666795  0.523191  0.612580  0.607025   \n",
       " f1              0.552313  0.559478   0.544306  0.530273  0.583384  0.578981   \n",
       " \n",
       " modality                                                                    \n",
       " base predictor        LR       MLP        NB        RF       SVM       XGB  \n",
       " precision       0.565899  0.569519  0.563805  0.562732  0.565701  0.552216  \n",
       " recall          0.583024  0.636288  0.621521  0.594866  0.630861  0.569086  \n",
       " f1              0.572987  0.573362  0.573873  0.573541  0.572536  0.559365  ,\n",
       " 'thresholds': modality       Modality_0                                                 \\\n",
       " base predictor       ADAB     DT        GB       KNN        LR       MLP   \n",
       " precision        0.661111  0.525  0.601389  0.563889  0.591667  0.627778   \n",
       " recall           0.661111  0.525  0.601389  0.563889  0.591667  0.627778   \n",
       " f1               0.661111  0.525  0.601389  0.563889  0.591667  0.627778   \n",
       " \n",
       " modality                                             Modality_1            \\\n",
       " base predictor        NB        RF       SVM     XGB       ADAB        DT   \n",
       " precision       0.620833  0.570833  0.620833  0.5625     0.6625  0.551389   \n",
       " recall          0.620833  0.570833  0.620833  0.5625     0.6625  0.551389   \n",
       " f1              0.620833  0.570833  0.620833  0.5625     0.6625  0.551389   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor        GB     KNN        LR       MLP        NB     RF   \n",
       " precision       0.597222  0.5875  0.565278  0.620833  0.598611  0.575   \n",
       " recall          0.597222  0.5875  0.565278  0.620833  0.598611  0.575   \n",
       " f1              0.597222  0.5875  0.565278  0.620833  0.598611  0.575   \n",
       " \n",
       " modality                           Modality_2                             \\\n",
       " base predictor       SVM       XGB       ADAB     DT        GB       KNN   \n",
       " precision       0.633333  0.561111   0.673611  0.525  0.616667  0.611111   \n",
       " recall          0.633333  0.561111   0.673611  0.525  0.616667  0.611111   \n",
       " f1              0.633333  0.561111   0.673611  0.525  0.616667  0.611111   \n",
       " \n",
       " modality                                                                    \n",
       " base predictor        LR       MLP        NB        RF       SVM       XGB  \n",
       " precision       0.586111  0.641667  0.626389  0.598611  0.636111  0.572222  \n",
       " recall          0.586111  0.641667  0.626389  0.598611  0.636111  0.572222  \n",
       " f1              0.586111  0.641667  0.626389  0.598611  0.636111  0.572222  }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_0</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_1</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.030195e-01</td>\n",
       "      <td>2.222401e-16</td>\n",
       "      <td>0.496980</td>\n",
       "      <td>0.484714</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.514602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.409006</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.586223</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.721130</td>\n",
       "      <td>0.031602</td>\n",
       "      <td>0.247268</td>\n",
       "      <td>0.805465</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.194389</td>\n",
       "      <td>0.717909</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.275930</td>\n",
       "      <td>0.695547</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.298462</td>\n",
       "      <td>5.035328e-01</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>2.223108e-16</td>\n",
       "      <td>0.213391</td>\n",
       "      <td>0.785733</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.650757</td>\n",
       "      <td>0.342503</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797229</td>\n",
       "      <td>0.192462</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.675195</td>\n",
       "      <td>0.324791</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.700685</td>\n",
       "      <td>0.295151</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.685856</td>\n",
       "      <td>0.305368</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>0.495806</td>\n",
       "      <td>5.041936e-01</td>\n",
       "      <td>2.224167e-16</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.995806</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.104903</td>\n",
       "      <td>0.891624</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383272</td>\n",
       "      <td>0.499935</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>0.327217</td>\n",
       "      <td>0.653934</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.247105</td>\n",
       "      <td>0.712563</td>\n",
       "      <td>0.040333</td>\n",
       "      <td>0.236559</td>\n",
       "      <td>0.754778</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.223461e-16</td>\n",
       "      <td>5.037648e-01</td>\n",
       "      <td>0.496235</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.996938</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.758107</td>\n",
       "      <td>0.232212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137229</td>\n",
       "      <td>0.396308</td>\n",
       "      <td>0.466464</td>\n",
       "      <td>0.035621</td>\n",
       "      <td>0.526522</td>\n",
       "      <td>0.437858</td>\n",
       "      <td>0.098913</td>\n",
       "      <td>0.490241</td>\n",
       "      <td>0.410846</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>0.594349</td>\n",
       "      <td>0.386195</td>\n",
       "      <td>2.222698e-16</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>5.032448e-01</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.076523</td>\n",
       "      <td>0.922492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.258560</td>\n",
       "      <td>0.736563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.018039</td>\n",
       "      <td>0.208020</td>\n",
       "      <td>0.773941</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.259888</td>\n",
       "      <td>0.739997</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.302475</td>\n",
       "      <td>0.695146</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.312267</td>\n",
       "      <td>0.683639</td>\n",
       "      <td>0.496877</td>\n",
       "      <td>2.222535e-16</td>\n",
       "      <td>5.031229e-01</td>\n",
       "      <td>0.024270</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.975492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.163425</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.833777</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.299646</td>\n",
       "      <td>0.032553</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.253231</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.746117</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.660226</td>\n",
       "      <td>0.298987</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.698725</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.030195e-01</td>\n",
       "      <td>2.222401e-16</td>\n",
       "      <td>0.496980</td>\n",
       "      <td>0.188556</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.913515</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.205876</td>\n",
       "      <td>0.245101</td>\n",
       "      <td>0.549022</td>\n",
       "      <td>0.152868</td>\n",
       "      <td>0.171413</td>\n",
       "      <td>0.675719</td>\n",
       "      <td>0.178818</td>\n",
       "      <td>0.280640</td>\n",
       "      <td>0.540543</td>\n",
       "      <td>0.195511</td>\n",
       "      <td>0.253426</td>\n",
       "      <td>0.551063</td>\n",
       "      <td>2.222698e-16</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>5.032448e-01</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>0.964828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.238293</td>\n",
       "      <td>0.747114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.213275</td>\n",
       "      <td>0.459031</td>\n",
       "      <td>0.327694</td>\n",
       "      <td>0.131340</td>\n",
       "      <td>0.453101</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.177695</td>\n",
       "      <td>0.433174</td>\n",
       "      <td>0.389131</td>\n",
       "      <td>0.069253</td>\n",
       "      <td>0.442537</td>\n",
       "      <td>0.488210</td>\n",
       "      <td>0.496877</td>\n",
       "      <td>2.222535e-16</td>\n",
       "      <td>5.031229e-01</td>\n",
       "      <td>0.570341</td>\n",
       "      <td>0.006727</td>\n",
       "      <td>0.422932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.562777</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.418872</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.449444</td>\n",
       "      <td>0.278344</td>\n",
       "      <td>0.272212</td>\n",
       "      <td>0.480379</td>\n",
       "      <td>0.247577</td>\n",
       "      <td>0.272044</td>\n",
       "      <td>0.418021</td>\n",
       "      <td>0.306827</td>\n",
       "      <td>0.275152</td>\n",
       "      <td>0.486638</td>\n",
       "      <td>0.172321</td>\n",
       "      <td>0.341042</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.223461e-16</td>\n",
       "      <td>5.037648e-01</td>\n",
       "      <td>0.496235</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.986222</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.861940</td>\n",
       "      <td>0.132696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030080</td>\n",
       "      <td>0.648603</td>\n",
       "      <td>0.321317</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.762409</td>\n",
       "      <td>0.237363</td>\n",
       "      <td>0.019703</td>\n",
       "      <td>0.646094</td>\n",
       "      <td>0.334204</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.720182</td>\n",
       "      <td>0.276399</td>\n",
       "      <td>2.222698e-16</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>5.032448e-01</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.462935</td>\n",
       "      <td>0.536579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.269705</td>\n",
       "      <td>0.726580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.468855</td>\n",
       "      <td>0.357086</td>\n",
       "      <td>0.091953</td>\n",
       "      <td>0.450819</td>\n",
       "      <td>0.457228</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.430699</td>\n",
       "      <td>0.434765</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.369548</td>\n",
       "      <td>0.604351</td>\n",
       "      <td>0.495806</td>\n",
       "      <td>5.041936e-01</td>\n",
       "      <td>2.224167e-16</td>\n",
       "      <td>0.831189</td>\n",
       "      <td>0.166820</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.427963</td>\n",
       "      <td>0.559257</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310019</td>\n",
       "      <td>0.632428</td>\n",
       "      <td>0.057553</td>\n",
       "      <td>0.234461</td>\n",
       "      <td>0.764028</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.253061</td>\n",
       "      <td>0.732241</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>0.214669</td>\n",
       "      <td>0.782990</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.030195e-01</td>\n",
       "      <td>2.222401e-16</td>\n",
       "      <td>0.496980</td>\n",
       "      <td>0.973815</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.785019</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.206548</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.743277</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.236109</td>\n",
       "      <td>0.777549</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.222405</td>\n",
       "      <td>0.745957</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>0.249361</td>\n",
       "      <td>0.683677</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.312113</td>\n",
       "      <td>5.035328e-01</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>2.223108e-16</td>\n",
       "      <td>0.996593</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.877430</td>\n",
       "      <td>0.116987</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459854</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.127680</td>\n",
       "      <td>0.592550</td>\n",
       "      <td>0.372636</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>0.582689</td>\n",
       "      <td>0.340399</td>\n",
       "      <td>0.076912</td>\n",
       "      <td>0.693241</td>\n",
       "      <td>0.299957</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.495806</td>\n",
       "      <td>5.041936e-01</td>\n",
       "      <td>2.224167e-16</td>\n",
       "      <td>0.159148</td>\n",
       "      <td>0.840254</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.311234</td>\n",
       "      <td>0.677631</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256564</td>\n",
       "      <td>0.714123</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>0.230640</td>\n",
       "      <td>0.769225</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.297724</td>\n",
       "      <td>0.694510</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.279328</td>\n",
       "      <td>0.717675</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2.223057e-16</td>\n",
       "      <td>5.034980e-01</td>\n",
       "      <td>0.496502</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.029771</td>\n",
       "      <td>0.969457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.712334</td>\n",
       "      <td>0.281738</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.242135</td>\n",
       "      <td>0.294048</td>\n",
       "      <td>0.463817</td>\n",
       "      <td>0.174188</td>\n",
       "      <td>0.262971</td>\n",
       "      <td>0.562841</td>\n",
       "      <td>0.252650</td>\n",
       "      <td>0.305457</td>\n",
       "      <td>0.441893</td>\n",
       "      <td>0.202332</td>\n",
       "      <td>0.278453</td>\n",
       "      <td>0.519214</td>\n",
       "      <td>5.035328e-01</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>2.223478e-16</td>\n",
       "      <td>0.610171</td>\n",
       "      <td>0.388793</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.207030</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315730</td>\n",
       "      <td>0.489924</td>\n",
       "      <td>0.194346</td>\n",
       "      <td>0.364929</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>0.132366</td>\n",
       "      <td>0.433263</td>\n",
       "      <td>0.399316</td>\n",
       "      <td>0.167421</td>\n",
       "      <td>0.525109</td>\n",
       "      <td>0.425192</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.496316</td>\n",
       "      <td>5.036842e-01</td>\n",
       "      <td>2.223579e-16</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>0.979872</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.183483</td>\n",
       "      <td>0.806244</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250595</td>\n",
       "      <td>0.723974</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>0.234221</td>\n",
       "      <td>0.765676</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.294559</td>\n",
       "      <td>0.700795</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.320506</td>\n",
       "      <td>0.676903</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2.223057e-16</td>\n",
       "      <td>5.034980e-01</td>\n",
       "      <td>0.496502</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.451275</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.836332</td>\n",
       "      <td>0.153036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>0.303238</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.799386</td>\n",
       "      <td>0.200555</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.684635</td>\n",
       "      <td>0.303305</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.727412</td>\n",
       "      <td>0.269837</td>\n",
       "      <td>2.222806e-16</td>\n",
       "      <td>0.496630</td>\n",
       "      <td>5.033698e-01</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>0.141358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.619433</td>\n",
       "      <td>0.375126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.084044</td>\n",
       "      <td>0.395449</td>\n",
       "      <td>0.520507</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.290306</td>\n",
       "      <td>0.703012</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>0.373064</td>\n",
       "      <td>0.604365</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.318645</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.496316</td>\n",
       "      <td>5.036842e-01</td>\n",
       "      <td>2.223579e-16</td>\n",
       "      <td>0.836526</td>\n",
       "      <td>0.158907</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.505827</td>\n",
       "      <td>0.482817</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361604</td>\n",
       "      <td>0.562634</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.250399</td>\n",
       "      <td>0.745785</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.654553</td>\n",
       "      <td>0.027147</td>\n",
       "      <td>0.296688</td>\n",
       "      <td>0.700398</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2.223057e-16</td>\n",
       "      <td>5.034980e-01</td>\n",
       "      <td>0.496502</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.788019</td>\n",
       "      <td>0.204287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>0.590646</td>\n",
       "      <td>0.374371</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.745742</td>\n",
       "      <td>0.254128</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.623985</td>\n",
       "      <td>0.362351</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.713757</td>\n",
       "      <td>0.283506</td>\n",
       "      <td>2.222806e-16</td>\n",
       "      <td>0.496630</td>\n",
       "      <td>5.033698e-01</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.081954</td>\n",
       "      <td>0.913910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.320414</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.317613</td>\n",
       "      <td>0.639007</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.250848</td>\n",
       "      <td>0.748271</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.324946</td>\n",
       "      <td>0.668988</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.310308</td>\n",
       "      <td>0.684970</td>\n",
       "      <td>0.496316</td>\n",
       "      <td>5.036842e-01</td>\n",
       "      <td>2.223579e-16</td>\n",
       "      <td>0.037843</td>\n",
       "      <td>0.962050</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.136444</td>\n",
       "      <td>0.855010</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259011</td>\n",
       "      <td>0.716193</td>\n",
       "      <td>0.024797</td>\n",
       "      <td>0.265322</td>\n",
       "      <td>0.734567</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.336251</td>\n",
       "      <td>0.659889</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.692617</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2.223057e-16</td>\n",
       "      <td>5.034980e-01</td>\n",
       "      <td>0.496502</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.573228</td>\n",
       "      <td>0.420936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>0.831022</td>\n",
       "      <td>0.155824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>0.329729</td>\n",
       "      <td>0.535845</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.428924</td>\n",
       "      <td>0.542414</td>\n",
       "      <td>0.076956</td>\n",
       "      <td>0.452999</td>\n",
       "      <td>0.470045</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.485104</td>\n",
       "      <td>0.496263</td>\n",
       "      <td>5.035328e-01</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>2.223478e-16</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.699411</td>\n",
       "      <td>0.293505</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.275364</td>\n",
       "      <td>0.460226</td>\n",
       "      <td>0.264410</td>\n",
       "      <td>0.280768</td>\n",
       "      <td>0.497197</td>\n",
       "      <td>0.222035</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.422209</td>\n",
       "      <td>0.262334</td>\n",
       "      <td>0.219272</td>\n",
       "      <td>0.523001</td>\n",
       "      <td>0.257727</td>\n",
       "      <td>0.496437</td>\n",
       "      <td>2.223071e-16</td>\n",
       "      <td>5.035634e-01</td>\n",
       "      <td>0.055441</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.943562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.210404</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.784313</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.435198</td>\n",
       "      <td>0.166057</td>\n",
       "      <td>0.398745</td>\n",
       "      <td>0.406644</td>\n",
       "      <td>0.071456</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.366918</td>\n",
       "      <td>0.098371</td>\n",
       "      <td>0.534711</td>\n",
       "      <td>0.391784</td>\n",
       "      <td>0.021362</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>5.033028e-01</td>\n",
       "      <td>2.222778e-16</td>\n",
       "      <td>0.496697</td>\n",
       "      <td>0.851118</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.147149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.535095</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>0.455576</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.394456</td>\n",
       "      <td>0.129577</td>\n",
       "      <td>0.475967</td>\n",
       "      <td>0.546714</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.435334</td>\n",
       "      <td>0.473157</td>\n",
       "      <td>0.087181</td>\n",
       "      <td>0.439661</td>\n",
       "      <td>0.549008</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.436218</td>\n",
       "      <td>5.035328e-01</td>\n",
       "      <td>0.496467</td>\n",
       "      <td>2.223478e-16</td>\n",
       "      <td>0.825720</td>\n",
       "      <td>0.172914</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.783170</td>\n",
       "      <td>0.210290</td>\n",
       "      <td>0.006539</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825902</td>\n",
       "      <td>0.164840</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.335289</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.753891</td>\n",
       "      <td>0.243427</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.694827</td>\n",
       "      <td>0.298355</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.496316</td>\n",
       "      <td>5.036842e-01</td>\n",
       "      <td>2.223579e-16</td>\n",
       "      <td>0.251387</td>\n",
       "      <td>0.745544</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271307</td>\n",
       "      <td>0.723470</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475110</td>\n",
       "      <td>0.313371</td>\n",
       "      <td>0.211519</td>\n",
       "      <td>0.504567</td>\n",
       "      <td>0.354159</td>\n",
       "      <td>0.141274</td>\n",
       "      <td>0.428864</td>\n",
       "      <td>0.397675</td>\n",
       "      <td>0.173460</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>0.389514</td>\n",
       "      <td>0.111406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality          Modality_0                                              \\\n",
       "base predictor          ADAB                               XGB             \n",
       "sample                     0                                 0             \n",
       "class                      0             1         2         0         1   \n",
       "0               5.030195e-01  2.222401e-16  0.496980  0.484714  0.000684   \n",
       "1               2.223461e-16  5.037648e-01  0.496235  0.000010  0.996938   \n",
       "2               5.030195e-01  2.222401e-16  0.496980  0.188556  0.001075   \n",
       "3               2.223461e-16  5.037648e-01  0.496235  0.000255  0.986222   \n",
       "4               5.030195e-01  2.222401e-16  0.496980  0.973815  0.001691   \n",
       "..                       ...           ...       ...       ...       ...   \n",
       "571             2.223057e-16  5.034980e-01  0.496502  0.000772  0.029771   \n",
       "572             2.223057e-16  5.034980e-01  0.496502  0.000891  0.451275   \n",
       "573             2.223057e-16  5.034980e-01  0.496502  0.000244  0.930683   \n",
       "574             2.223057e-16  5.034980e-01  0.496502  0.005836  0.573228   \n",
       "575             5.033028e-01  2.222778e-16  0.496697  0.851118  0.001734   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.514602  1.0  0.0  0.0  0.43  0.00  0.57  0.409006  0.004771   \n",
       "1               0.003051  0.0  1.0  0.0  0.00  0.94  0.06  0.009681  0.758107   \n",
       "2               0.810369  1.0  0.0  0.0  0.43  0.07  0.50  0.081958  0.004527   \n",
       "3               0.013523  0.0  1.0  0.0  0.00  0.98  0.02  0.005364  0.861940   \n",
       "4               0.024494  1.0  0.0  0.0  0.89  0.00  0.11  0.785019  0.008433   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "571             0.969457  0.0  0.0  1.0  0.07  0.36  0.57  0.005927  0.712334   \n",
       "572             0.547833  0.0  0.0  1.0  0.02  0.33  0.65  0.010632  0.836332   \n",
       "573             0.069073  0.0  1.0  0.0  0.00  0.94  0.06  0.007694  0.788019   \n",
       "574             0.420936  0.0  1.0  0.0  0.00  0.51  0.49  0.013155  0.831022   \n",
       "575             0.147149  0.0  0.0  1.0  0.72  0.01  0.27  0.535095  0.009329   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.586223  0.6  0.0  0.4  0.721130  0.031602  0.247268   \n",
       "1               0.232212  0.0  1.0  0.0  0.137229  0.396308  0.466464   \n",
       "2               0.913515  0.4  0.2  0.4  0.205876  0.245101  0.549022   \n",
       "3               0.132696  0.0  1.0  0.0  0.030080  0.648603  0.321317   \n",
       "4               0.206548  0.6  0.0  0.4  0.743277  0.020614  0.236109   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "571             0.281738  0.4  0.2  0.4  0.242135  0.294048  0.463817   \n",
       "572             0.153036  0.0  0.6  0.4  0.029223  0.667539  0.303238   \n",
       "573             0.204287  0.0  1.0  0.0  0.034983  0.590646  0.374371   \n",
       "574             0.155824  0.0  0.6  0.4  0.134426  0.329729  0.535845   \n",
       "575             0.455576  0.8  0.0  0.2  0.394456  0.129577  0.475967   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.805465  0.000146  0.194389  0.717909  0.006161  0.275930   \n",
       "1               0.035621  0.526522  0.437858  0.098913  0.490241  0.410846   \n",
       "2               0.152868  0.171413  0.675719  0.178818  0.280640  0.540543   \n",
       "3               0.000228  0.762409  0.237363  0.019703  0.646094  0.334204   \n",
       "4               0.777549  0.000046  0.222405  0.745957  0.004681  0.249361   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.174188  0.262971  0.562841  0.252650  0.305457  0.441893   \n",
       "572             0.000059  0.799386  0.200555  0.012060  0.684635  0.303305   \n",
       "573             0.000131  0.745742  0.254128  0.013664  0.623985  0.362351   \n",
       "574             0.028662  0.428924  0.542414  0.076956  0.452999  0.470045   \n",
       "575             0.546714  0.017952  0.435334  0.473157  0.087181  0.439661   \n",
       "\n",
       "modality                                        Modality_1            \\\n",
       "base predictor       SVM                              ADAB             \n",
       "sample                 0                                 0             \n",
       "class                  0         1         2             0         1   \n",
       "0               0.695547  0.005991  0.298462  5.035328e-01  0.496467   \n",
       "1               0.019456  0.594349  0.386195  2.222698e-16  0.496755   \n",
       "2               0.195511  0.253426  0.551063  2.222698e-16  0.496755   \n",
       "3               0.003419  0.720182  0.276399  2.222698e-16  0.496755   \n",
       "4               0.683677  0.004210  0.312113  5.035328e-01  0.496467   \n",
       "..                   ...       ...       ...           ...       ...   \n",
       "571             0.202332  0.278453  0.519214  5.035328e-01  0.496467   \n",
       "572             0.002751  0.727412  0.269837  2.222806e-16  0.496630   \n",
       "573             0.002738  0.713757  0.283506  2.222806e-16  0.496630   \n",
       "574             0.018633  0.485104  0.496263  5.035328e-01  0.496467   \n",
       "575             0.549008  0.014774  0.436218  5.035328e-01  0.496467   \n",
       "\n",
       "modality                                                                   \\\n",
       "base predictor                     XGB                       DT             \n",
       "sample                               0                        0             \n",
       "class                      2         0         1         2    0    1    2   \n",
       "0               2.223108e-16  0.213391  0.785733  0.000876  0.0  1.0  0.0   \n",
       "1               5.032448e-01  0.000985  0.076523  0.922492  0.0  0.0  1.0   \n",
       "2               5.032448e-01  0.000459  0.034713  0.964828  0.0  0.0  1.0   \n",
       "3               5.032448e-01  0.000486  0.462935  0.536579  0.0  0.0  1.0   \n",
       "4               2.223108e-16  0.996593  0.003182  0.000225  1.0  0.0  0.0   \n",
       "..                       ...       ...       ...       ...  ...  ...  ...   \n",
       "571             2.223478e-16  0.610171  0.388793  0.001035  1.0  0.0  0.0   \n",
       "572             5.033698e-01  0.000916  0.857726  0.141358  0.0  1.0  0.0   \n",
       "573             5.033698e-01  0.004135  0.081954  0.913910  0.0  0.0  1.0   \n",
       "574             2.223478e-16  0.001448  0.996829  0.001723  0.0  1.0  0.0   \n",
       "575             2.223478e-16  0.825720  0.172914  0.001365  1.0  0.0  0.0   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor    RF                    GB                      KNN             \n",
       "sample             0                     0                        0             \n",
       "class              0     1     2         0         1         2    0    1    2   \n",
       "0               0.65  0.34  0.01  0.650757  0.342503  0.006740  1.0  0.0  0.0   \n",
       "1               0.00  0.25  0.75  0.004877  0.258560  0.736563  0.0  0.4  0.6   \n",
       "2               0.00  0.23  0.77  0.014593  0.238293  0.747114  0.0  0.2  0.8   \n",
       "3               0.00  0.17  0.83  0.003715  0.269705  0.726580  0.0  0.0  1.0   \n",
       "4               0.89  0.11  0.00  0.877430  0.116987  0.005582  0.8  0.2  0.0   \n",
       "..               ...   ...   ...       ...       ...       ...  ...  ...  ...   \n",
       "571             0.74  0.26  0.00  0.787149  0.207030  0.005820  0.6  0.4  0.0   \n",
       "572             0.00  0.86  0.14  0.005442  0.619433  0.375126  0.0  0.8  0.2   \n",
       "573             0.00  0.32  0.68  0.007987  0.320414  0.671600  0.0  0.4  0.6   \n",
       "574             0.43  0.52  0.05  0.699411  0.293505  0.007083  0.2  0.6  0.2   \n",
       "575             0.73  0.27  0.00  0.783170  0.210290  0.006539  0.8  0.2  0.0   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        LR                            NB                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.797229  0.192462  0.010309  0.675195  0.324791  0.000014   \n",
       "1               0.018039  0.208020  0.773941  0.000114  0.259888  0.739997   \n",
       "2               0.213275  0.459031  0.327694  0.131340  0.453101  0.415558   \n",
       "3               0.174059  0.468855  0.357086  0.091953  0.450819  0.457228   \n",
       "4               0.459854  0.412466  0.127680  0.592550  0.372636  0.034814   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.315730  0.489924  0.194346  0.364929  0.502705  0.132366   \n",
       "572             0.084044  0.395449  0.520507  0.006682  0.290306  0.703012   \n",
       "573             0.043379  0.317613  0.639007  0.000882  0.250848  0.748271   \n",
       "574             0.275364  0.460226  0.264410  0.280768  0.497197  0.222035   \n",
       "575             0.825902  0.164840  0.009258  0.664706  0.335289  0.000005   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor       MLP                           SVM                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.700685  0.295151  0.004164  0.685856  0.305368  0.008776   \n",
       "1               0.002379  0.302475  0.695146  0.004094  0.312267  0.683639   \n",
       "2               0.177695  0.433174  0.389131  0.069253  0.442537  0.488210   \n",
       "3               0.134536  0.430699  0.434765  0.026101  0.369548  0.604351   \n",
       "4               0.582689  0.340399  0.076912  0.693241  0.299957  0.006803   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.433263  0.399316  0.167421  0.525109  0.425192  0.049699   \n",
       "572             0.022571  0.373064  0.604365  0.005587  0.318645  0.675768   \n",
       "573             0.006066  0.324946  0.668988  0.004722  0.310308  0.684970   \n",
       "574             0.315457  0.422209  0.262334  0.219272  0.523001  0.257727   \n",
       "575             0.753891  0.243427  0.002681  0.694827  0.298355  0.006818   \n",
       "\n",
       "modality       Modality_2                                                  \\\n",
       "base predictor       ADAB                                   XGB             \n",
       "sample                  0                                     0             \n",
       "class                   0             1             2         0         1   \n",
       "0                0.495806  5.041936e-01  2.224167e-16  0.004174  0.995806   \n",
       "1                0.496877  2.222535e-16  5.031229e-01  0.024270  0.000238   \n",
       "2                0.496877  2.222535e-16  5.031229e-01  0.570341  0.006727   \n",
       "3                0.495806  5.041936e-01  2.224167e-16  0.831189  0.166820   \n",
       "4                0.495806  5.041936e-01  2.224167e-16  0.159148  0.840254   \n",
       "..                    ...           ...           ...       ...       ...   \n",
       "571              0.496316  5.036842e-01  2.223579e-16  0.019945  0.979872   \n",
       "572              0.496316  5.036842e-01  2.223579e-16  0.836526  0.158907   \n",
       "573              0.496316  5.036842e-01  2.223579e-16  0.037843  0.962050   \n",
       "574              0.496437  2.223071e-16  5.035634e-01  0.055441  0.000996   \n",
       "575              0.496316  5.036842e-01  2.223579e-16  0.251387  0.745544   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.000020  0.0  1.0  0.0  0.01  0.99  0.00  0.104903  0.891624   \n",
       "1               0.975492  0.0  0.0  1.0  0.06  0.01  0.93  0.163425  0.002798   \n",
       "2               0.422932  0.0  0.0  1.0  0.48  0.06  0.46  0.562777  0.018351   \n",
       "3               0.001991  1.0  0.0  0.0  0.69  0.30  0.01  0.427963  0.559257   \n",
       "4               0.000598  0.0  1.0  0.0  0.32  0.68  0.00  0.311234  0.677631   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "571             0.000182  0.0  1.0  0.0  0.06  0.94  0.00  0.183483  0.806244   \n",
       "572             0.004567  1.0  0.0  0.0  0.66  0.34  0.00  0.505827  0.482817   \n",
       "573             0.000107  0.0  1.0  0.0  0.12  0.88  0.00  0.136444  0.855010   \n",
       "574             0.943562  0.0  0.0  1.0  0.22  0.00  0.78  0.210404  0.005283   \n",
       "575             0.003069  0.0  1.0  0.0  0.16  0.84  0.00  0.271307  0.723470   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.003473  0.0  1.0  0.0  0.383272  0.499935  0.116793   \n",
       "1               0.833777  0.4  0.0  0.6  0.299646  0.032553  0.667801   \n",
       "2               0.418872  0.4  0.4  0.2  0.449444  0.278344  0.272212   \n",
       "3               0.012780  0.4  0.6  0.0  0.310019  0.632428  0.057553   \n",
       "4               0.011134  0.4  0.6  0.0  0.256564  0.714123  0.029313   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "571             0.010272  0.4  0.6  0.0  0.250595  0.723974  0.025431   \n",
       "572             0.011356  0.4  0.6  0.0  0.361604  0.562634  0.075761   \n",
       "573             0.008545  0.2  0.8  0.0  0.259011  0.716193  0.024797   \n",
       "574             0.784313  0.4  0.0  0.6  0.435198  0.166057  0.398745   \n",
       "575             0.005223  0.6  0.4  0.0  0.475110  0.313371  0.211519   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.327217  0.653934  0.018849  0.247105  0.712563  0.040333   \n",
       "1               0.253231  0.000652  0.746117  0.331831  0.007943  0.660226   \n",
       "2               0.480379  0.247577  0.272044  0.418021  0.306827  0.275152   \n",
       "3               0.234461  0.764028  0.001511  0.253061  0.732241  0.014697   \n",
       "4               0.230640  0.769225  0.000135  0.297724  0.694510  0.007766   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.234221  0.765676  0.000103  0.294559  0.700795  0.004645   \n",
       "572             0.250399  0.745785  0.003816  0.318300  0.654553  0.027147   \n",
       "573             0.265322  0.734567  0.000111  0.336251  0.659889  0.003860   \n",
       "574             0.406644  0.071456  0.521900  0.366918  0.098371  0.534711   \n",
       "575             0.504567  0.354159  0.141274  0.428864  0.397675  0.173460   \n",
       "\n",
       "modality                                     labels  \n",
       "base predictor       SVM                             \n",
       "sample                 0                             \n",
       "class                  0         1         2         \n",
       "0               0.236559  0.754778  0.008663      0  \n",
       "1               0.298987  0.002287  0.698725      2  \n",
       "2               0.486638  0.172321  0.341042      2  \n",
       "3               0.214669  0.782990  0.002340      1  \n",
       "4               0.279328  0.717675  0.002997      0  \n",
       "..                   ...       ...       ...    ...  \n",
       "571             0.320506  0.676903  0.002591      1  \n",
       "572             0.296688  0.700398  0.002914      1  \n",
       "573             0.304264  0.692617  0.003119      1  \n",
       "574             0.391784  0.021362  0.586854      2  \n",
       "575             0.499081  0.389514  0.111406      0  \n",
       "\n",
       "[576 rows x 91 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<eipy.ei.EnsembleIntegration at 0x7fc8a831bd30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.379134</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.222994</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.355449</td>\n",
       "      <td>0.251544</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.298480</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.379443</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.331134</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.349724</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>0.299372</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.379208</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.263965</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.325664</td>\n",
       "      <td>0.280447</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.269546</td>\n",
       "      <td>0.326469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADAB       XGB        DT        RF        GB       KNN  \\\n",
       "precision  0.112500  0.379134  0.112500  0.222994  0.112500  0.355449   \n",
       "recall     0.333333  0.379443  0.333333  0.331134  0.333333  0.349724   \n",
       "f1         0.168224  0.379208  0.168224  0.263965  0.168224  0.325664   \n",
       "\n",
       "                 LR        NB       MLP       SVM  \n",
       "precision  0.251544  0.222222  0.298480  0.333333  \n",
       "recall     0.373494  0.334986  0.299372  0.333334  \n",
       "f1         0.280447  0.264200  0.269546  0.326469  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferred_meta_model = EI.meta_summary[\"metrics\"].loc[\"precision\"].idxmax()\n",
    "y_pred = EI.predict(X_dict=data_test, meta_model_key=preferred_meta_model)\n",
    "y_pred = [np.argmax(np.array(y)) for y in y_pred]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 2, 0, 0, 2, 1, 0, 2, 2,\n",
       "       0, 1, 2, 0, 1, 1, 1, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 1, 1, 2, 0,\n",
       "       2, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 0, 1, 2, 2, 1, 2,\n",
       "       2, 1, 2, 1, 0, 1, 1, 2, 1, 2, 2, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 0, 2, 1, 1, 1, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1,\n",
       "       0, 0, 0, 1, 1, 2, 2, 0, 1, 2, 0, 2, 2, 0, 1, 0, 2, 1, 2, 2, 2, 1,\n",
       "       1, 1, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 2, 2,\n",
       "       1, 0, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3388888888888889"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred))])/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "X = np.concatenate([modality_0,modality_1,modality_2], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y)\n",
    "\n",
    "model = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        60\n",
      "           1       0.89      0.92      0.90        60\n",
      "           2       0.94      0.85      0.89        60\n",
      "\n",
      "    accuracy                           0.92       180\n",
      "   macro avg       0.92      0.92      0.92       180\n",
      "weighted avg       0.92      0.92      0.92       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "Modality_a = X[:, 0:2]\n",
    "Modality_b = X[:, 2:4]\n",
    "\n",
    "X_a_train, X_a_test, y_train, y_test = train_test_split(Modality_a, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_b_train, X_b_test, _,_ = train_test_split(Modality_b, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_train = {\n",
    "                \"Modality_a\": X_a_train,\n",
    "                \"Modality_b\": X_b_train\n",
    "                }\n",
    "\n",
    "iris_data_test = {\n",
    "                \"Modality_a\": X_a_test,\n",
    "                \"Modality_b\": X_b_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=0,\n",
    "                        project_name=\"iris\",\n",
    "                        model_building=True,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_a...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_b...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, modality in iris_data_train.items():\n",
    "    EI_iris.train_base(modality, y_train, modality_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[modality          Modality_a                                              \\\n",
       " base predictor          ADAB                               XGB             \n",
       " sample                     0                                 0             \n",
       " class                      0         1             2         0         1   \n",
       " 0               4.700114e-01  0.529988  3.032480e-07  0.062144  0.930889   \n",
       " 1               3.618822e-07  0.498631  5.013683e-01  0.000280  0.996896   \n",
       " 2               3.618822e-07  0.498631  5.013683e-01  0.001002  0.029516   \n",
       " 3               3.618822e-07  0.498631  5.013683e-01  0.002396  0.023360   \n",
       " 4               4.700114e-01  0.529988  3.032480e-07  0.995907  0.002983   \n",
       " ..                       ...       ...           ...       ...       ...   \n",
       " 91              2.142084e-12  0.000414  9.995858e-01  0.000806  0.126304   \n",
       " 92              1.406017e-05  0.524571  4.754154e-01  0.004578  0.968059   \n",
       " 93              9.872006e-01  0.012759  4.027025e-05  0.997407  0.001570   \n",
       " 94              9.872006e-01  0.012759  4.027025e-05  0.997407  0.001570   \n",
       " 95              9.872006e-01  0.012759  4.027025e-05  0.997407  0.001570   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor             DT              RF                    GB             \n",
       " sample                      0               0                     0             \n",
       " class                  2    0    1    2     0     1     2         0         1   \n",
       " 0               0.006968  0.0  1.0  0.0  0.30  0.70  0.00  0.000038  0.997153   \n",
       " 1               0.002824  0.0  1.0  0.0  0.00  0.97  0.03  0.000030  0.999136   \n",
       " 2               0.969482  0.0  0.0  1.0  0.00  0.13  0.87  0.000039  0.027989   \n",
       " 3               0.974244  0.0  0.0  1.0  0.00  0.11  0.89  0.000040  0.007575   \n",
       " 4               0.001110  1.0  0.0  0.0  0.99  0.00  0.01  0.999874  0.000117   \n",
       " ..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       " 91              0.872890  0.0  0.0  1.0  0.00  0.24  0.76  0.000095  0.224160   \n",
       " 92              0.027363  0.0  0.0  1.0  0.00  0.56  0.44  0.000161  0.547937   \n",
       " 93              0.001023  1.0  0.0  0.0  1.00  0.00  0.00  0.999939  0.000040   \n",
       " 94              0.001023  1.0  0.0  0.0  1.00  0.00  0.00  0.999883  0.000097   \n",
       " 95              0.001023  1.0  0.0  0.0  0.95  0.00  0.05  0.999883  0.000097   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor            KNN                  LR                       \n",
       " sample                      0                   0                       \n",
       " class                  2    0    1    2         0         1         2   \n",
       " 0               0.002809  0.6  0.4  0.0  0.341026  0.635756  0.023218   \n",
       " 1               0.000834  0.0  1.0  0.0  0.009954  0.821467  0.168578   \n",
       " 2               0.971973  0.0  0.2  0.8  0.012403  0.288322  0.699275   \n",
       " 3               0.992385  0.0  0.2  0.8  0.008652  0.166049  0.825299   \n",
       " 4               0.000008  1.0  0.0  0.0  0.932395  0.060116  0.007489   \n",
       " ..                   ...  ...  ...  ...       ...       ...       ...   \n",
       " 91              0.775745  0.0  0.4  0.6  0.013031  0.503284  0.483685   \n",
       " 92              0.451902  0.0  0.8  0.2  0.074480  0.692171  0.233349   \n",
       " 93              0.000021  1.0  0.0  0.0  0.979587  0.016171  0.004242   \n",
       " 94              0.000019  1.0  0.0  0.0  0.888925  0.082272  0.028803   \n",
       " 95              0.000019  1.0  0.0  0.0  0.954443  0.027654  0.017904   \n",
       " \n",
       " modality                                                                    \\\n",
       " base predictor        NB                           MLP                       \n",
       " sample                 0                             0                       \n",
       " class                  0         1         2         0         1         2   \n",
       " 0               0.482329  0.512156  0.005515  0.261517  0.403694  0.334789   \n",
       " 1               0.002997  0.940830  0.056173  0.036098  0.419467  0.544435   \n",
       " 2               0.000076  0.182793  0.817131  0.084493  0.404413  0.511094   \n",
       " 3               0.000014  0.040070  0.959915  0.099776  0.394533  0.505692   \n",
       " 4               0.993493  0.005182  0.001325  0.781078  0.133423  0.085499   \n",
       " ..                   ...       ...       ...       ...       ...       ...   \n",
       " 91              0.000144  0.637093  0.362763  0.058958  0.419248  0.521794   \n",
       " 92              0.021969  0.852109  0.125922  0.121367  0.433605  0.445029   \n",
       " 93              0.997672  0.000194  0.002135  0.890446  0.067147  0.042406   \n",
       " 94              0.978633  0.006729  0.014638  0.739426  0.150215  0.110359   \n",
       " 95              0.998222  0.000048  0.001730  0.867122  0.077853  0.055024   \n",
       " \n",
       " modality                                        Modality_b                \\\n",
       " base predictor       SVM                              ADAB                 \n",
       " sample                 0                                 0                 \n",
       " class                  0         1         2             0             1   \n",
       " 0               0.386732  0.566825  0.046443  3.422728e-13  6.563576e-01   \n",
       " 1               0.004901  0.796133  0.198966  1.125016e-10  9.981009e-01   \n",
       " 2               0.006123  0.222264  0.771612  1.125016e-10  9.981009e-01   \n",
       " 3               0.006755  0.122216  0.871029  3.147239e-16  6.060861e-05   \n",
       " 4               0.982118  0.008778  0.009104  9.999884e-01  1.161683e-05   \n",
       " ..                   ...       ...       ...           ...           ...   \n",
       " 91              0.003447  0.503688  0.492865  3.138965e-16  1.488947e-08   \n",
       " 92              0.018163  0.738569  0.243269  5.903110e-11  9.993977e-01   \n",
       " 93              0.991740  0.001571  0.006689  9.999947e-01  5.318417e-06   \n",
       " 94              0.952322  0.020882  0.026796  9.999947e-01  5.318417e-06   \n",
       " 95              0.977795  0.006798  0.015407  9.999947e-01  5.318417e-06   \n",
       " \n",
       " modality                                                                   \\\n",
       " base predictor                     XGB                       DT             \n",
       " sample                               0                        0             \n",
       " class                      2         0         1         2    0    1    2   \n",
       " 0               3.436424e-01  0.005267  0.991783  0.002949  0.0  1.0  0.0   \n",
       " 1               1.899097e-03  0.008558  0.986651  0.004792  0.0  1.0  0.0   \n",
       " 2               1.899097e-03  0.007203  0.988763  0.004033  0.0  1.0  0.0   \n",
       " 3               9.999394e-01  0.004873  0.004529  0.990597  0.0  0.0  1.0   \n",
       " 4               2.210346e-08  0.985329  0.010703  0.003968  1.0  0.0  0.0   \n",
       " ..                       ...       ...       ...       ...  ...  ...  ...   \n",
       " 91              1.000000e+00  0.003736  0.003490  0.992775  0.0  0.0  1.0   \n",
       " 92              6.023369e-04  0.011472  0.981067  0.007461  0.0  1.0  0.0   \n",
       " 93              3.202896e-09  0.983979  0.011413  0.004609  1.0  0.0  0.0   \n",
       " 94              3.202896e-09  0.983979  0.011413  0.004609  1.0  0.0  0.0   \n",
       " 95              3.202896e-09  0.983979  0.011413  0.004609  1.0  0.0  0.0   \n",
       " \n",
       " modality                                                                   \\\n",
       " base predictor   RF                        GB                               \n",
       " sample            0                         0                               \n",
       " class             0     1     2             0             1             2   \n",
       " 0               0.0  0.86  0.14  1.849195e-06  9.999964e-01  1.776098e-06   \n",
       " 1               0.0  1.00  0.00  6.662538e-07  9.999987e-01  6.474139e-07   \n",
       " 2               0.0  1.00  0.00  6.662538e-07  9.999987e-01  6.474139e-07   \n",
       " 3               0.0  0.00  1.00  6.573787e-07  6.369428e-07  9.999987e-01   \n",
       " 4               1.0  0.00  0.00  9.999987e-01  6.324959e-07  6.324959e-07   \n",
       " ..              ...   ...   ...           ...           ...           ...   \n",
       " 91              0.0  0.00  1.00  6.468994e-07  6.284485e-07  9.999987e-01   \n",
       " 92              0.0  1.00  0.00  6.530903e-07  9.999987e-01  6.530903e-07   \n",
       " 93              1.0  0.00  0.00  9.999987e-01  6.284485e-07  6.468994e-07   \n",
       " 94              1.0  0.00  0.00  9.999987e-01  6.284485e-07  6.468994e-07   \n",
       " 95              1.0  0.00  0.00  9.999987e-01  6.284485e-07  6.468994e-07   \n",
       " \n",
       " modality                                                         \\\n",
       " base predictor  KNN                  LR                           \n",
       " sample            0                   0                           \n",
       " class             0    1    2         0         1             2   \n",
       " 0               0.0  1.0  0.0  0.007823  0.727664  2.645130e-01   \n",
       " 1               0.0  1.0  0.0  0.043278  0.931775  2.494721e-02   \n",
       " 2               0.0  1.0  0.0  0.013222  0.854985  1.317921e-01   \n",
       " 3               0.0  0.0  1.0  0.000010  0.031263  9.687263e-01   \n",
       " 4               1.0  0.0  0.0  0.943695  0.056303  1.194454e-06   \n",
       " ..              ...  ...  ...       ...       ...           ...   \n",
       " 91              0.0  0.0  1.0  0.000428  0.193814  8.057582e-01   \n",
       " 92              0.0  1.0  0.0  0.158558  0.832585  8.857536e-03   \n",
       " 93              1.0  0.0  0.0  0.988613  0.011387  9.039792e-08   \n",
       " 94              1.0  0.0  0.0  0.963165  0.036834  8.381809e-07   \n",
       " 95              1.0  0.0  0.0  0.953636  0.046363  1.302329e-06   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor             NB                                   MLP             \n",
       " sample                      0                                     0             \n",
       " class                       0             1             2         0         1   \n",
       " 0               1.492635e-109  8.459273e-01  1.540727e-01  0.011724  0.401944   \n",
       " 1                3.324428e-60  9.999955e-01  4.484344e-06  0.098481  0.695245   \n",
       " 2                1.232459e-91  9.986641e-01  1.335928e-03  0.028737  0.568403   \n",
       " 3               1.133377e-228  3.383311e-09  1.000000e+00  0.000602  0.180106   \n",
       " 4                1.000000e+00  7.031998e-16  4.265120e-25  0.854161  0.131374   \n",
       " ..                        ...           ...           ...       ...       ...   \n",
       " 91              1.708570e-144  8.927733e-06  9.999911e-01  0.004488  0.315564   \n",
       " 92               1.177195e-35  9.999942e-01  5.804007e-06  0.166308  0.610030   \n",
       " 93               1.000000e+00  2.495411e-30  2.906804e-26  0.882425  0.100874   \n",
       " 94               1.000000e+00  3.869020e-27  1.141587e-24  0.866026  0.119440   \n",
       " 95               1.000000e+00  3.621705e-26  5.767369e-24  0.854367  0.130464   \n",
       " \n",
       " modality                                               labels  \n",
       " base predictor                 SVM                             \n",
       " sample                           0                             \n",
       " class                  2         0         1         2         \n",
       " 0               0.586333  0.015554  0.849990  0.134457      2  \n",
       " 1               0.206273  0.018584  0.973152  0.008264      1  \n",
       " 2               0.402860  0.013677  0.946272  0.040051      1  \n",
       " 3               0.819293  0.018133  0.008489  0.973377      2  \n",
       " 4               0.014464  0.934829  0.045567  0.019605      0  \n",
       " ..                   ...       ...       ...       ...    ...  \n",
       " 91              0.679948  0.016125  0.062902  0.920973      2  \n",
       " 92              0.223662  0.071126  0.908366  0.020508      1  \n",
       " 93              0.016702  0.948704  0.024142  0.027153      0  \n",
       " 94              0.014534  0.946514  0.032473  0.021013      0  \n",
       " 95              0.015168  0.941537  0.037673  0.020790      0  \n",
       " \n",
       " [96 rows x 61 columns],\n",
       " modality          Modality_a                                                  \\\n",
       " base predictor          ADAB                                   XGB             \n",
       " sample                     0                                     0             \n",
       " class                      0             1             2         0         1   \n",
       " 0               3.589007e-07  4.995866e-01  5.004130e-01  0.009796  0.621221   \n",
       " 1               1.000000e+00  3.761699e-10  2.227069e-16  0.994692  0.003763   \n",
       " 2               4.713187e-01  5.286810e-01  3.128983e-07  0.922928  0.068653   \n",
       " 3               3.589007e-07  4.995866e-01  5.004130e-01  0.000791  0.967833   \n",
       " 4               4.713187e-01  5.286810e-01  3.128983e-07  0.876796  0.109746   \n",
       " ..                       ...           ...           ...       ...       ...   \n",
       " 91              3.524140e-07  4.993905e-01  5.006091e-01  0.002139  0.383966   \n",
       " 92              4.715067e-01  5.284929e-01  3.148302e-07  0.011235  0.986587   \n",
       " 93              9.990548e-01  4.719397e-04  4.732437e-04  0.905023  0.088826   \n",
       " 94              3.524140e-07  4.993905e-01  5.006091e-01  0.000969  0.011966   \n",
       " 95              3.524140e-07  4.993905e-01  5.006091e-01  0.001026  0.987656   \n",
       " \n",
       " modality                                                                     \\\n",
       " base predictor             DT              RF                            GB   \n",
       " sample                      0               0                             0   \n",
       " class                  2    0    1    2     0         1         2         0   \n",
       " 0               0.368983  0.0  0.5  0.5  0.00  0.652000  0.348000  0.000248   \n",
       " 1               0.001545  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999720   \n",
       " 2               0.008419  1.0  0.0  0.0  0.86  0.140000  0.000000  0.999685   \n",
       " 3               0.031376  0.0  1.0  0.0  0.00  0.755667  0.244333  0.000023   \n",
       " 4               0.013458  1.0  0.0  0.0  0.80  0.200000  0.000000  0.995083   \n",
       " ..                   ...  ...  ...  ...   ...       ...       ...       ...   \n",
       " 91              0.613895  0.0  0.0  1.0  0.00  0.430000  0.570000  0.000412   \n",
       " 92              0.002179  0.0  1.0  0.0  0.21  0.700000  0.090000  0.000132   \n",
       " 93              0.006151  1.0  0.0  0.0  0.91  0.090000  0.000000  0.999408   \n",
       " 94              0.987064  0.0  0.0  1.0  0.00  0.190000  0.810000  0.000029   \n",
       " 95              0.011318  0.0  1.0  0.0  0.00  0.990000  0.010000  0.000042   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor                      KNN                  LR             \n",
       " sample                                0                   0             \n",
       " class                  1         2    0    1    2         0         1   \n",
       " 0               0.593692  0.406060  0.0  0.6  0.4  0.092472  0.539985   \n",
       " 1               0.000272  0.000008  1.0  0.0  0.0  0.907537  0.053723   \n",
       " 2               0.000303  0.000012  1.0  0.0  0.0  0.910677  0.086869   \n",
       " 3               0.961735  0.038241  0.0  0.6  0.4  0.027767  0.475024   \n",
       " 4               0.004883  0.000034  1.0  0.0  0.0  0.635532  0.329921   \n",
       " ..                   ...       ...  ...  ...  ...       ...       ...   \n",
       " 91              0.575221  0.424367  0.0  0.0  1.0  0.000299  0.107390   \n",
       " 92              0.973307  0.026561  0.2  0.8  0.0  0.303243  0.597412   \n",
       " 93              0.000589  0.000004  1.0  0.0  0.0  0.928645  0.024814   \n",
       " 94              0.004015  0.995956  0.0  0.4  0.6  0.018000  0.377114   \n",
       " 95              0.996589  0.003370  0.0  1.0  0.0  0.068735  0.767874   \n",
       " \n",
       " modality                                                                  \\\n",
       " base predictor                      NB                               MLP   \n",
       " sample                               0                                 0   \n",
       " class                  2             0         1             2         0   \n",
       " 0               0.367543  7.570535e-03  0.635421  3.570086e-01  0.171879   \n",
       " 1               0.038739  9.998031e-01  0.000152  4.522553e-05  0.817294   \n",
       " 2               0.002454  9.408901e-01  0.053094  6.015862e-03  0.718851   \n",
       " 3               0.497209  3.067103e-04  0.492609  5.070840e-01  0.093682   \n",
       " 4               0.034547  7.279827e-01  0.244807  2.721061e-02  0.478812   \n",
       " ..                   ...           ...       ...           ...       ...   \n",
       " 91              0.892311  1.730396e-14  0.014523  9.854770e-01  0.016925   \n",
       " 92              0.099346  1.466139e-01  0.801188  5.219772e-02  0.256181   \n",
       " 93              0.046541  9.999234e-01  0.000077  4.011654e-08  0.916602   \n",
       " 94              0.604886  4.554779e-06  0.278306  7.216892e-01  0.081211   \n",
       " 95              0.163391  4.074124e-03  0.971696  2.422938e-02  0.092362   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor                           SVM                       \n",
       " sample                                     0                       \n",
       " class                  1         2         0         1         2   \n",
       " 0               0.420662  0.407459  0.024500  0.624625  0.350875   \n",
       " 1               0.114995  0.067711  0.942912  0.026181  0.030906   \n",
       " 2               0.181404  0.099745  0.977529  0.012155  0.010316   \n",
       " 3               0.430214  0.476104  0.008294  0.476046  0.515660   \n",
       " 4               0.307744  0.213444  0.758999  0.189323  0.051677   \n",
       " ..                   ...       ...       ...       ...       ...   \n",
       " 91              0.355344  0.627731  0.005245  0.104408  0.890347   \n",
       " 92              0.400960  0.342859  0.181160  0.715550  0.103290   \n",
       " 93              0.053091  0.030307  0.923688  0.038020  0.038292   \n",
       " 94              0.417571  0.501218  0.006512  0.344354  0.649134   \n",
       " 95              0.452049  0.455590  0.015109  0.814435  0.170456   \n",
       " \n",
       " modality          Modality_b                                                  \\\n",
       " base predictor          ADAB                                   XGB             \n",
       " sample                     0                                     0             \n",
       " class                      0             1             2         0         1   \n",
       " 0               8.600989e-16  5.000000e-01  5.000000e-01  0.030207  0.430728   \n",
       " 1               1.000000e+00  3.108469e-10  1.055076e-13  0.983990  0.011463   \n",
       " 2               1.000000e+00  3.108469e-10  1.055076e-13  0.983990  0.011463   \n",
       " 3               2.810619e-16  3.223068e-01  6.776932e-01  0.005970  0.005626   \n",
       " 4               1.000000e+00  3.108469e-10  1.055076e-13  0.983990  0.011463   \n",
       " ..                       ...           ...           ...       ...       ...   \n",
       " 91              3.214958e-16  4.884218e-05  9.999512e-01  0.007065  0.009999   \n",
       " 92              4.586509e-11  9.947837e-01  5.216257e-03  0.009579  0.980979   \n",
       " 93              9.999932e-01  6.810809e-06  3.571322e-08  0.981652  0.011423   \n",
       " 94              4.586509e-11  9.947837e-01  5.216257e-03  0.003982  0.992093   \n",
       " 95              4.586509e-11  9.947837e-01  5.216257e-03  0.010909  0.978336   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor             DT             RF                       \n",
       " sample                      0              0                       \n",
       " class                  2    0    1    2    0         1         2   \n",
       " 0               0.539065  0.0  0.5  0.5  0.0  0.416667  0.583333   \n",
       " 1               0.004548  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 2               0.004548  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 3               0.988404  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 4               0.004548  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " ..                   ...  ...  ...  ...  ...       ...       ...   \n",
       " 91              0.982936  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 92              0.009443  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 93              0.006924  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 94              0.003925  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 95              0.010754  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " \n",
       " modality                                                                 \\\n",
       " base predictor            GB                              KNN             \n",
       " sample                     0                                0             \n",
       " class                      0             1             2    0    1    2   \n",
       " 0               2.579070e-04  4.998711e-01  4.998710e-01  0.0  0.4  0.6   \n",
       " 1               9.999987e-01  6.572807e-07  6.386604e-07  1.0  0.0  0.0   \n",
       " 2               9.999987e-01  6.572807e-07  6.386604e-07  1.0  0.0  0.0   \n",
       " 3               6.386603e-07  6.572807e-07  9.999987e-01  0.0  0.0  1.0   \n",
       " 4               9.999987e-01  6.572807e-07  6.386604e-07  1.0  0.0  0.0   \n",
       " ..                       ...           ...           ...  ...  ...  ...   \n",
       " 91              6.274117e-07  6.513675e-07  9.999987e-01  0.0  0.0  1.0   \n",
       " 92              6.284485e-07  9.999987e-01  6.468994e-07  0.0  1.0  0.0   \n",
       " 93              9.999987e-01  6.530903e-07  6.530903e-07  1.0  0.0  0.0   \n",
       " 94              6.284485e-07  9.999987e-01  6.468994e-07  0.0  1.0  0.0   \n",
       " 95              6.284485e-07  9.999987e-01  6.468994e-07  0.0  1.0  0.0   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor        LR                                     NB                 \n",
       " sample                 0                                      0                 \n",
       " class                  0         1             2              0             1   \n",
       " 0               0.002925  0.496192  5.008832e-01  2.078679e-152  1.515041e-01   \n",
       " 1               0.972137  0.027863  6.116139e-07   1.000000e+00  8.868067e-17   \n",
       " 2               0.984051  0.015949  1.120721e-07   1.000000e+00  4.582340e-22   \n",
       " 3               0.000139  0.154580  8.452810e-01  3.166347e-203  1.099902e-03   \n",
       " 4               0.948581  0.051418  1.318976e-06   1.000000e+00  1.804502e-18   \n",
       " ..                   ...       ...           ...            ...           ...   \n",
       " 91              0.000008  0.031014  9.689785e-01  8.235246e-159  4.484913e-06   \n",
       " 92              0.047105  0.894827  5.806809e-02   3.990266e-52  9.997863e-01   \n",
       " 93              0.954429  0.045570  1.170111e-06   1.000000e+00  1.049651e-14   \n",
       " 94              0.018470  0.871796  1.097334e-01   6.720845e-61  9.994961e-01   \n",
       " 95              0.086507  0.899342  1.415146e-02   3.875111e-35  9.999990e-01   \n",
       " \n",
       " modality                                                              \\\n",
       " base predictor                     MLP                           SVM   \n",
       " sample                               0                             0   \n",
       " class                      2         0         1         2         0   \n",
       " 0               8.484959e-01  0.007058  0.375105  0.617836  0.019820   \n",
       " 1               1.235068e-22  0.837571  0.137962  0.024467  0.948318   \n",
       " 2               3.538886e-27  0.893921  0.094553  0.011527  0.952094   \n",
       " 3               9.989001e-01  0.004194  0.435088  0.560718  0.016348   \n",
       " 4               1.539532e-24  0.858216  0.128405  0.013378  0.936564   \n",
       " ..                       ...       ...       ...       ...       ...   \n",
       " 91              9.999955e-01  0.001949  0.385852  0.612199  0.018652   \n",
       " 92              2.136588e-04  0.042610  0.521265  0.436125  0.017732   \n",
       " 93              4.170980e-26  0.819994  0.152851  0.027154  0.942726   \n",
       " 94              5.039105e-04  0.039572  0.612261  0.348167  0.014658   \n",
       " 95              1.027388e-06  0.127677  0.660540  0.211783  0.031420   \n",
       " \n",
       " modality                           labels  \n",
       " base predictor                             \n",
       " sample                                     \n",
       " class                  1         2         \n",
       " 0               0.467590  0.512590      2  \n",
       " 1               0.030477  0.021205      0  \n",
       " 2               0.023953  0.023953      0  \n",
       " 3               0.053689  0.929963      2  \n",
       " 4               0.042644  0.020792      0  \n",
       " ..                   ...       ...    ...  \n",
       " 91              0.006983  0.974365      2  \n",
       " 92              0.971694  0.010574      1  \n",
       " 93              0.038048  0.019226      0  \n",
       " 94              0.962807  0.022535      1  \n",
       " 95              0.960175  0.008405      1  \n",
       " \n",
       " [96 rows x 61 columns],\n",
       " modality       Modality_a                                              \\\n",
       " base predictor       ADAB                               XGB             \n",
       " sample                  0                                 0             \n",
       " class                   0             1         2         0         1   \n",
       " 0                0.454504  2.985943e-06  0.545493  0.974416  0.011156   \n",
       " 1                0.000004  5.004149e-01  0.499581  0.000176  0.992876   \n",
       " 2                0.000004  5.004149e-01  0.499581  0.001670  0.104554   \n",
       " 3                0.454504  2.985943e-06  0.545493  0.994404  0.002964   \n",
       " 4                0.000004  5.004149e-01  0.499581  0.001983  0.900288   \n",
       " ..                    ...           ...       ...       ...       ...   \n",
       " 91               0.000004  5.006372e-01  0.499359  0.011313  0.270524   \n",
       " 92               0.000004  5.006372e-01  0.499359  0.001318  0.126390   \n",
       " 93               0.000004  5.006372e-01  0.499359  0.003524  0.067233   \n",
       " 94               0.999991  2.227468e-16  0.000009  0.996901  0.002075   \n",
       " 95               0.000004  5.006372e-01  0.499359  0.000805  0.044464   \n",
       " \n",
       " modality                                                                     \\\n",
       " base predictor             DT              RF                            GB   \n",
       " sample                      0               0                             0   \n",
       " class                  2    0    1    2     0         1         2         0   \n",
       " 0               0.014427  1.0  0.0  0.0  0.99  0.000000  0.010000  0.999711   \n",
       " 1               0.006948  0.0  1.0  0.0  0.00  0.950000  0.050000  0.000062   \n",
       " 2               0.893776  0.0  0.0  1.0  0.00  0.170000  0.830000  0.000134   \n",
       " 3               0.002632  1.0  0.0  0.0  0.95  0.000000  0.050000  0.999706   \n",
       " 4               0.097729  0.0  0.0  1.0  0.00  0.560000  0.440000  0.000215   \n",
       " ..                   ...  ...  ...  ...   ...       ...       ...       ...   \n",
       " 91              0.718163  0.0  0.0  1.0  0.00  0.368333  0.631667  0.000232   \n",
       " 92              0.872292  0.0  0.0  1.0  0.00  0.415000  0.585000  0.000120   \n",
       " 93              0.929243  0.0  0.0  1.0  0.00  0.132500  0.867500  0.000143   \n",
       " 94              0.001024  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999926   \n",
       " 95              0.954731  0.0  0.0  1.0  0.00  0.160000  0.840000  0.000119   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor                      KNN                  LR             \n",
       " sample                                0                   0             \n",
       " class                  1         2    0    1    2         0         1   \n",
       " 0               0.000244  0.000045  1.0  0.0  0.0  0.787413  0.184474   \n",
       " 1               0.936976  0.062962  0.0  0.8  0.2  0.009665  0.751231   \n",
       " 2               0.065607  0.934259  0.0  0.4  0.6  0.012499  0.342243   \n",
       " 3               0.000270  0.000024  1.0  0.0  0.0  0.791767  0.173946   \n",
       " 4               0.902755  0.097030  0.0  0.4  0.6  0.002451  0.452504   \n",
       " ..                   ...       ...  ...  ...  ...       ...       ...   \n",
       " 91              0.229922  0.769846  0.0  0.4  0.6  0.023508  0.273874   \n",
       " 92              0.039898  0.959982  0.0  0.4  0.6  0.000983  0.212946   \n",
       " 93              0.054318  0.945540  0.0  0.2  0.8  0.036056  0.339769   \n",
       " 94              0.000047  0.000027  1.0  0.0  0.0  0.953915  0.029167   \n",
       " 95              0.027815  0.972066  0.0  0.2  0.8  0.022773  0.436703   \n",
       " \n",
       " modality                                                              \\\n",
       " base predictor                      NB                           MLP   \n",
       " sample                               0                             0   \n",
       " class                  2             0         1         2         0   \n",
       " 0               0.028113  9.148268e-01  0.058389  0.026784  0.570304   \n",
       " 1               0.239103  6.287575e-05  0.594140  0.405797  0.031510   \n",
       " 2               0.645258  1.073855e-07  0.326268  0.673732  0.073271   \n",
       " 3               0.034288  9.391916e-01  0.037057  0.023751  0.593122   \n",
       " 4               0.545045  1.969255e-09  0.388378  0.611622  0.022858   \n",
       " ..                   ...           ...       ...       ...       ...   \n",
       " 91              0.702618  3.242877e-06  0.142988  0.857008  0.145629   \n",
       " 92              0.786071  9.887855e-12  0.052443  0.947557  0.026469   \n",
       " 93              0.624175  4.257666e-05  0.291680  0.708278  0.153072   \n",
       " 94              0.016918  9.948015e-01  0.000438  0.004760  0.867621   \n",
       " 95              0.540524  3.839570e-05  0.541837  0.458124  0.091472   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor                           SVM                       \n",
       " sample                                     0                       \n",
       " class                  1         2         0         1         2   \n",
       " 0               0.241948  0.187748  0.900006  0.055716  0.044278   \n",
       " 1               0.417332  0.551159  0.006141  0.668586  0.325273   \n",
       " 2               0.409614  0.517115  0.005962  0.278777  0.715261   \n",
       " 3               0.228368  0.178510  0.894161  0.060536  0.045303   \n",
       " 4               0.388438  0.588704  0.003116  0.297283  0.699601   \n",
       " ..                   ...       ...       ...       ...       ...   \n",
       " 91              0.381228  0.473143  0.008609  0.321692  0.669699   \n",
       " 92              0.395698  0.577833  0.002551  0.230350  0.767098   \n",
       " 93              0.385882  0.461046  0.010537  0.380122  0.609341   \n",
       " 94              0.070693  0.061686  0.973888  0.009989  0.016123   \n",
       " 95              0.416154  0.492374  0.006190  0.430455  0.563355   \n",
       " \n",
       " modality          Modality_b                                              \\\n",
       " base predictor          ADAB                               XGB             \n",
       " sample                     0                                 0             \n",
       " class                      0         1             2         0         1   \n",
       " 0               9.999947e-01  0.000005  2.332917e-08  0.986143  0.009991   \n",
       " 1               5.881039e-11  0.995629  4.370881e-03  0.010413  0.983834   \n",
       " 2               5.881039e-11  0.995629  4.370881e-03  0.009991  0.984080   \n",
       " 3               9.999947e-01  0.000005  2.332917e-08  0.986143  0.009991   \n",
       " 4               3.196104e-16  0.000080  9.999202e-01  0.001772  0.005413   \n",
       " ..                       ...       ...           ...       ...       ...   \n",
       " 91              3.195960e-16  0.000080  9.999203e-01  0.002479  0.006687   \n",
       " 92              3.195960e-16  0.000080  9.999203e-01  0.002479  0.006687   \n",
       " 93              3.195960e-16  0.000080  9.999203e-01  0.002479  0.006687   \n",
       " 94              9.999947e-01  0.000005  2.322033e-08  0.985976  0.009193   \n",
       " 95              5.885753e-11  0.995646  4.353977e-03  0.011499  0.980551   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor             DT             RF                       \n",
       " sample                      0              0                       \n",
       " class                  2    0    1    2    0         1         2   \n",
       " 0               0.003866  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 1               0.005753  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 2               0.005930  0.0  1.0  0.0  0.0  0.990000  0.010000   \n",
       " 3               0.003866  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 4               0.992814  0.0  0.0  1.0  0.0  0.005833  0.994167   \n",
       " ..                   ...  ...  ...  ...  ...       ...       ...   \n",
       " 91              0.990834  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 92              0.990834  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 93              0.990834  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 94              0.004830  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 95              0.007950  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " \n",
       " modality                                                                 \\\n",
       " base predictor            GB                              KNN             \n",
       " sample                     0                                0             \n",
       " class                      0             1             2    0    1    2   \n",
       " 0               9.999983e-01  1.051736e-06  6.570449e-07  1.0  0.0  0.0   \n",
       " 1               2.149200e-06  9.999956e-01  2.210800e-06  0.0  1.0  0.0   \n",
       " 2               2.149200e-06  9.999956e-01  2.210800e-06  0.0  1.0  0.0   \n",
       " 3               9.999983e-01  1.051736e-06  6.570449e-07  1.0  0.0  0.0   \n",
       " 4               6.318678e-07  8.015254e-07  9.999986e-01  0.0  0.0  1.0   \n",
       " ..                       ...           ...           ...  ...  ...  ...   \n",
       " 91              6.463479e-07  8.199696e-07  9.999985e-01  0.0  0.0  1.0   \n",
       " 92              6.463479e-07  8.199696e-07  9.999985e-01  0.0  0.0  1.0   \n",
       " 93              6.463471e-07  9.585531e-07  9.999984e-01  0.0  0.0  1.0   \n",
       " 94              9.999966e-01  2.774445e-06  6.468355e-07  1.0  0.0  0.0   \n",
       " 95              2.842388e-06  9.999943e-01  2.840386e-06  0.0  1.0  0.0   \n",
       " \n",
       " modality                                                                   \\\n",
       " base predictor        LR                                 NB                 \n",
       " sample                 0                                  0                 \n",
       " class                  0         1         2              0             1   \n",
       " 0               0.972761  0.027237  0.000001   1.000000e+00  9.820462e-24   \n",
       " 1               0.054649  0.909673  0.035678   2.976543e-67  9.999798e-01   \n",
       " 2               0.017894  0.794310  0.187796   1.592979e-99  9.968245e-01   \n",
       " 3               0.965411  0.034588  0.000002   1.000000e+00  1.940601e-24   \n",
       " 4               0.000072  0.099905  0.900023  1.366363e-210  5.266335e-06   \n",
       " ..                   ...       ...       ...            ...           ...   \n",
       " 91              0.000063  0.064453  0.935484  1.810574e-278  1.051981e-06   \n",
       " 92              0.000010  0.048135  0.951855   0.000000e+00  8.404616e-07   \n",
       " 93              0.000900  0.211169  0.787932  7.652130e-214  6.695934e-04   \n",
       " 94              0.909930  0.090055  0.000015   1.000000e+00  1.213645e-12   \n",
       " 95              0.024901  0.856867  0.118232  2.428149e-117  9.984630e-01   \n",
       " \n",
       " modality                                                              \\\n",
       " base predictor                     MLP                           SVM   \n",
       " sample                               0                             0   \n",
       " class                      2         0         1         2         0   \n",
       " 0               8.982384e-23  0.860233  0.120416  0.019351  0.946989   \n",
       " 1               2.022935e-05  0.101493  0.703919  0.194588  0.028464   \n",
       " 2               3.175494e-03  0.032288  0.555886  0.411826  0.016352   \n",
       " 3               1.445531e-23  0.865838  0.119813  0.014349  0.944665   \n",
       " 4               9.999947e-01  0.003869  0.436839  0.559292  0.016121   \n",
       " ..                       ...       ...       ...       ...       ...   \n",
       " 91              9.999989e-01  0.001872  0.246452  0.751677  0.015339   \n",
       " 92              9.999992e-01  0.002821  0.484599  0.512580  0.020531   \n",
       " 93              9.993304e-01  0.003935  0.251796  0.744270  0.016748   \n",
       " 94              1.239317e-14  0.752061  0.210664  0.037275  0.899258   \n",
       " 95              1.536985e-03  0.046368  0.594180  0.359453  0.015881   \n",
       " \n",
       " modality                           labels  \n",
       " base predictor                             \n",
       " sample                                     \n",
       " class                  1         2         \n",
       " 0               0.033214  0.019797      0  \n",
       " 1               0.958234  0.013302      1  \n",
       " 2               0.903616  0.080032      1  \n",
       " 3               0.035829  0.019505      0  \n",
       " 4               0.022581  0.961298      2  \n",
       " ..                   ...       ...    ...  \n",
       " 91              0.012932  0.971729      2  \n",
       " 92              0.011156  0.968313      2  \n",
       " 93              0.099896  0.883355      2  \n",
       " 94              0.077572  0.023170      0  \n",
       " 95              0.948913  0.035206      1  \n",
       " \n",
       " [96 rows x 61 columns],\n",
       " modality          Modality_a                                          \\\n",
       " base predictor          ADAB                           XGB             \n",
       " sample                     0                             0             \n",
       " class                      0         1         2         0         1   \n",
       " 0               2.145718e-06  0.508045  0.491952  0.042323  0.895240   \n",
       " 1               2.261372e-16  0.000010  0.999990  0.001543  0.952912   \n",
       " 2               2.959013e-06  0.546081  0.453916  0.001263  0.011190   \n",
       " 3               5.107919e-01  0.489204  0.000004  0.753157  0.244566   \n",
       " 4               2.261372e-16  0.000010  0.999990  0.003649  0.665093   \n",
       " ..                       ...       ...       ...       ...       ...   \n",
       " 91              1.988193e-06  0.500755  0.499243  0.000526  0.982531   \n",
       " 92              7.957891e-01  0.204087  0.000124  0.929916  0.059241   \n",
       " 93              8.993527e-01  0.100607  0.000040  0.996260  0.001428   \n",
       " 94              1.417161e-06  0.558871  0.441128  0.000894  0.195238   \n",
       " 95              8.993527e-01  0.100607  0.000040  0.997226  0.001430   \n",
       " \n",
       " modality                                                                     \\\n",
       " base predictor             DT              RF                            GB   \n",
       " sample                      0               0                             0   \n",
       " class                  2    0    1    2     0         1         2         0   \n",
       " 0               0.062436  0.0  1.0  0.0  0.25  0.750000  0.000000  0.001621   \n",
       " 1               0.045545  0.0  1.0  0.0  0.00  0.910000  0.090000  0.000022   \n",
       " 2               0.987547  0.0  0.0  1.0  0.00  0.160000  0.840000  0.000149   \n",
       " 3               0.002277  1.0  0.0  0.0  0.88  0.120000  0.000000  0.995469   \n",
       " 4               0.331258  0.0  1.0  0.0  0.00  0.650000  0.350000  0.000553   \n",
       " ..                   ...  ...  ...  ...   ...       ...       ...       ...   \n",
       " 91              0.016944  0.0  1.0  0.0  0.00  0.951667  0.048333  0.000034   \n",
       " 92              0.010843  1.0  0.0  0.0  0.91  0.070000  0.020000  0.999701   \n",
       " 93              0.002312  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999873   \n",
       " 94              0.803868  0.0  0.0  1.0  0.00  0.230000  0.770000  0.000190   \n",
       " 95              0.001345  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999874   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor                      KNN                  LR             \n",
       " sample                                0                   0             \n",
       " class                  1         2    0    1    2         0         1   \n",
       " 0               0.992857  0.005521  0.4  0.6  0.0  0.268590  0.704497   \n",
       " 1               0.981320  0.018658  0.0  0.8  0.2  0.009303  0.829589   \n",
       " 2               0.018315  0.981536  0.0  0.4  0.6  0.017453  0.276688   \n",
       " 3               0.004450  0.000081  1.0  0.0  0.0  0.647240  0.317356   \n",
       " 4               0.826595  0.172853  0.0  0.6  0.4  0.003321  0.434886   \n",
       " ..                   ...       ...  ...  ...  ...       ...       ...   \n",
       " 91              0.998487  0.001479  0.0  1.0  0.0  0.066280  0.723183   \n",
       " 92              0.000296  0.000003  1.0  0.0  0.0  0.962996  0.015152   \n",
       " 93              0.000122  0.000004  1.0  0.0  0.0  0.979673  0.017732   \n",
       " 94              0.103156  0.896655  0.0  0.2  0.8  0.031174  0.452959   \n",
       " 95              0.000122  0.000003  1.0  0.0  0.0  0.897684  0.083699   \n",
       " \n",
       " modality                                                                    \\\n",
       " base predictor                  NB                           MLP             \n",
       " sample                           0                             0             \n",
       " class                  2         0         1         2         0         1   \n",
       " 0               0.026913  0.204851  0.786649  0.008500  0.256248  0.417650   \n",
       " 1               0.161109  0.000568  0.948052  0.051381  0.033638  0.437644   \n",
       " 2               0.705859  0.000048  0.156585  0.843366  0.084721  0.402515   \n",
       " 3               0.035404  0.776598  0.206283  0.017118  0.509663  0.279394   \n",
       " 4               0.561794  0.000003  0.458380  0.541617  0.025208  0.394947   \n",
       " ..                   ...       ...       ...       ...       ...       ...   \n",
       " 91              0.210537  0.001878  0.887829  0.110292  0.109278  0.432440   \n",
       " 92              0.021852  0.985052  0.000061  0.014887  0.920525  0.051538   \n",
       " 93              0.002595  0.998651  0.000536  0.000813  0.893114  0.071333   \n",
       " 94              0.515867  0.000074  0.524110  0.475816  0.102628  0.406530   \n",
       " 95              0.018617  0.988556  0.006924  0.004520  0.759385  0.147778   \n",
       " \n",
       " modality                                                  Modality_b  \\\n",
       " base predictor                 SVM                              ADAB   \n",
       " sample                           0                                 0   \n",
       " class                  2         0         1         2             0   \n",
       " 0               0.326102  0.177799  0.780464  0.041737  4.837809e-12   \n",
       " 1               0.528718  0.003673  0.823317  0.173010  5.903019e-11   \n",
       " 2               0.512764  0.010141  0.237272  0.752588  5.903019e-11   \n",
       " 3               0.210942  0.700684  0.255233  0.044083  9.999947e-01   \n",
       " 4               0.579845  0.003133  0.342438  0.654429  3.140185e-16   \n",
       " ..                   ...       ...       ...       ...           ...   \n",
       " 91              0.458282  0.017506  0.783059  0.199436  3.138965e-16   \n",
       " 92              0.027938  0.964050  0.013761  0.022189  9.999947e-01   \n",
       " 93              0.035553  0.992065  0.002276  0.005659  9.999947e-01   \n",
       " 94              0.490842  0.009364  0.479041  0.511595  5.902997e-11   \n",
       " 95              0.092838  0.960472  0.020982  0.018546  9.999947e-01   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor                                   XGB                       DT   \n",
       " sample                                             0                        0   \n",
       " class                      1             2         0         1         2    0   \n",
       " 0               3.395603e-03  9.966044e-01  0.004995  0.990519  0.004486  0.0   \n",
       " 1               9.993848e-01  6.151661e-04  0.010276  0.980496  0.009228  0.0   \n",
       " 2               9.993848e-01  6.151661e-04  0.004995  0.990519  0.004486  0.0   \n",
       " 3               5.316325e-06  3.272435e-09  0.982464  0.011217  0.006319  1.0   \n",
       " 4               1.490116e-08  1.000000e+00  0.005672  0.006104  0.988225  0.0   \n",
       " ..                       ...           ...       ...       ...       ...  ...   \n",
       " 91              1.488947e-08  1.000000e+00  0.003347  0.003344  0.993309  0.0   \n",
       " 92              5.318417e-06  3.304374e-09  0.984950  0.010315  0.004735  1.0   \n",
       " 93              5.318417e-06  3.304374e-09  0.984950  0.010315  0.004735  1.0   \n",
       " 94              9.993786e-01  6.214089e-04  0.008210  0.986263  0.005527  0.0   \n",
       " 95              5.318417e-06  3.304374e-09  0.984950  0.010315  0.004735  1.0   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor             RF                        GB                 \n",
       " sample                      0                         0                 \n",
       " class             1    2    0     1     2             0             1   \n",
       " 0               0.0  1.0  0.0  0.54  0.46  6.572807e-07  6.386603e-07   \n",
       " 1               1.0  0.0  0.0  1.00  0.00  6.572807e-07  9.999987e-01   \n",
       " 2               1.0  0.0  0.0  1.00  0.00  6.572807e-07  9.999987e-01   \n",
       " 3               0.0  0.0  1.0  0.00  0.00  9.999987e-01  6.324959e-07   \n",
       " 4               0.0  1.0  0.0  0.00  1.00  6.572807e-07  6.386603e-07   \n",
       " ..              ...  ...  ...   ...   ...           ...           ...   \n",
       " 91              0.0  1.0  0.0  0.01  0.99  6.468994e-07  6.284485e-07   \n",
       " 92              0.0  0.0  1.0  0.00  0.00  9.999987e-01  6.284485e-07   \n",
       " 93              0.0  0.0  1.0  0.00  0.00  9.999987e-01  6.284485e-07   \n",
       " 94              1.0  0.0  0.0  1.00  0.00  6.530903e-07  9.999987e-01   \n",
       " 95              0.0  0.0  1.0  0.00  0.00  9.999987e-01  6.284485e-07   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor                KNN                  LR                           \n",
       " sample                          0                   0                           \n",
       " class                      2    0    1    2         0         1             2   \n",
       " 0               9.999987e-01  0.0  0.8  0.2  0.007379  0.632033  3.605887e-01   \n",
       " 1               6.386604e-07  0.0  1.0  0.0  0.040258  0.925392  3.435023e-02   \n",
       " 2               6.386604e-07  0.0  1.0  0.0  0.012607  0.808010  1.793832e-01   \n",
       " 3               6.324959e-07  1.0  0.0  0.0  0.939783  0.060214  2.596987e-06   \n",
       " 4               9.999987e-01  0.0  0.0  1.0  0.000048  0.093517  9.064349e-01   \n",
       " ..                       ...  ...  ...  ...       ...       ...           ...   \n",
       " 91              9.999987e-01  0.0  0.0  1.0  0.000990  0.249586  7.494243e-01   \n",
       " 92              6.468994e-07  1.0  0.0  0.0  0.956457  0.043540  2.654698e-06   \n",
       " 93              6.468994e-07  1.0  0.0  0.0  0.986811  0.013189  1.839050e-07   \n",
       " 94              6.530903e-07  0.0  1.0  0.0  0.020635  0.859312  1.200534e-01   \n",
       " 95              6.468994e-07  1.0  0.0  0.0  0.958112  0.041886  1.584641e-06   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor             NB                                   MLP             \n",
       " sample                      0                                     0             \n",
       " class                       0             1             2         0         1   \n",
       " 0               2.357829e-122  4.374058e-01  5.625942e-01  0.010696  0.369581   \n",
       " 1                7.184524e-70  9.999913e-01  8.678233e-06  0.088558  0.696406   \n",
       " 2               5.473310e-104  9.966593e-01  3.340713e-03  0.026028  0.546778   \n",
       " 3                1.000000e+00  3.454898e-18  2.613924e-23  0.844962  0.139683   \n",
       " 4               8.952188e-215  3.948852e-05  9.999605e-01  0.002858  0.396591   \n",
       " ..                        ...           ...           ...       ...       ...   \n",
       " 91              4.637336e-154  1.851805e-04  9.998148e-01  0.003195  0.249374   \n",
       " 92               1.000000e+00  2.871687e-16  3.101941e-19  0.820009  0.151548   \n",
       " 93               1.000000e+00  1.743145e-21  1.531280e-22  0.886444  0.097273   \n",
       " 94               2.964093e-86  9.988409e-01  1.159112e-03  0.040477  0.572677   \n",
       " 95               1.000000e+00  9.348523e-20  7.299274e-22  0.870835  0.114290   \n",
       " \n",
       " modality                                               labels  \n",
       " base predictor                 SVM                             \n",
       " sample                           0                             \n",
       " class                  2         0         1         2         \n",
       " 0               0.619723  0.020224  0.697981  0.281794      2  \n",
       " 1               0.215036  0.020130  0.969793  0.010077      1  \n",
       " 2               0.427194  0.015396  0.907225  0.077379      1  \n",
       " 3               0.015354  0.930638  0.049818  0.019544      0  \n",
       " 4               0.600550  0.017123  0.015238  0.967640      2  \n",
       " ..                   ...       ...       ...       ...    ...  \n",
       " 91              0.747431  0.018117  0.122029  0.859854      2  \n",
       " 92              0.028443  0.937794  0.041742  0.020464      0  \n",
       " 93              0.016283  0.953990  0.022536  0.023474      0  \n",
       " 94              0.386846  0.014468  0.937896  0.047636      1  \n",
       " 95              0.014876  0.941683  0.037723  0.020594      0  \n",
       " \n",
       " [96 rows x 61 columns],\n",
       " modality          Modality_a                                          \\\n",
       " base predictor          ADAB                           XGB             \n",
       " sample                     0                             0             \n",
       " class                      0         1         2         0         1   \n",
       " 0               4.782995e-06  0.502551  0.497444  0.005577  0.532207   \n",
       " 1               4.782995e-06  0.502551  0.497444  0.000269  0.981526   \n",
       " 2               4.782995e-06  0.502551  0.497444  0.002479  0.722272   \n",
       " 3               4.782995e-06  0.502551  0.497444  0.003451  0.301250   \n",
       " 4               5.257783e-01  0.000003  0.474219  0.996197  0.002701   \n",
       " ..                       ...       ...       ...       ...       ...   \n",
       " 91              2.191947e-12  0.000425  0.999575  0.000673  0.032373   \n",
       " 92              2.206602e-05  0.555056  0.444922  0.001321  0.010321   \n",
       " 93              9.226584e-01  0.077156  0.000185  0.997723  0.001541   \n",
       " 94              9.865897e-01  0.013367  0.000043  0.997323  0.001519   \n",
       " 95              9.865897e-01  0.013367  0.000043  0.997745  0.001519   \n",
       " \n",
       " modality                                                                     \\\n",
       " base predictor             DT              RF                            GB   \n",
       " sample                      0               0                             0   \n",
       " class                  2    0    1    2     0         1         2         0   \n",
       " 0               0.462216  0.0  0.5  0.5  0.00  0.600167  0.399833  0.000269   \n",
       " 1               0.018204  0.0  1.0  0.0  0.00  0.965000  0.035000  0.000009   \n",
       " 2               0.275249  0.0  1.0  0.0  0.00  0.620000  0.380000  0.000021   \n",
       " 3               0.695299  0.0  0.0  1.0  0.00  0.180000  0.820000  0.000029   \n",
       " 4               0.001102  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999859   \n",
       " ..                   ...  ...  ...  ...   ...       ...       ...       ...   \n",
       " 91              0.966954  0.0  0.0  1.0  0.00  0.190000  0.810000  0.000032   \n",
       " 92              0.988358  0.0  0.0  1.0  0.00  0.080000  0.920000  0.000066   \n",
       " 93              0.000736  1.0  0.0  0.0  0.99  0.010000  0.000000  0.999898   \n",
       " 94              0.001158  1.0  0.0  0.0  0.99  0.000000  0.010000  0.999901   \n",
       " 95              0.000736  1.0  0.0  0.0  1.00  0.000000  0.000000  0.999898   \n",
       " \n",
       " modality                                                               \\\n",
       " base predictor                      KNN                  LR             \n",
       " sample                                0                   0             \n",
       " class                  1         2    0    1    2         0         1   \n",
       " 0               0.551722  0.448008  0.0  0.6  0.4  0.085465  0.496135   \n",
       " 1               0.994470  0.005521  0.0  1.0  0.0  0.008241  0.794753   \n",
       " 2               0.979795  0.020185  0.0  0.8  0.2  0.114936  0.656430   \n",
       " 3               0.733480  0.266491  0.0  0.2  0.8  0.015293  0.568232   \n",
       " 4               0.000127  0.000014  1.0  0.0  0.0  0.826967  0.097507   \n",
       " ..                   ...       ...  ...  ...  ...       ...       ...   \n",
       " 91              0.005162  0.994806  0.0  0.2  0.8  0.000617  0.169245   \n",
       " 92              0.013705  0.986229  0.0  0.2  0.8  0.007541  0.172162   \n",
       " 93              0.000085  0.000016  1.0  0.0  0.0  0.893787  0.065575   \n",
       " 94              0.000085  0.000014  1.0  0.0  0.0  0.979902  0.014654   \n",
       " 95              0.000085  0.000016  1.0  0.0  0.0  0.888922  0.074797   \n",
       " \n",
       " modality                                                              \\\n",
       " base predictor                      NB                           MLP   \n",
       " sample                               0                             0   \n",
       " class                  2             0         1         2         0   \n",
       " 0               0.418399  1.326050e-03  0.628634  0.370040  0.166810   \n",
       " 1               0.197006  1.056715e-06  0.906551  0.093448  0.027893   \n",
       " 2               0.228634  5.956370e-03  0.851271  0.142773  0.150290   \n",
       " 3               0.416475  2.696543e-06  0.716934  0.283063  0.054627   \n",
       " 4               0.075526  9.631820e-01  0.009905  0.026913  0.719420   \n",
       " ..                   ...           ...       ...       ...       ...   \n",
       " 91              0.830138  1.059463e-10  0.027682  0.972318  0.019371   \n",
       " 92              0.820296  4.887623e-07  0.038055  0.961945  0.077240   \n",
       " 93              0.040637  9.861299e-01  0.005563  0.008307  0.753408   \n",
       " 94              0.005444  9.980113e-01  0.000698  0.001290  0.885136   \n",
       " 95              0.036281  9.794971e-01  0.009548  0.010955  0.734337   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor                           SVM                       \n",
       " sample                                     0                       \n",
       " class                  1         2         0         1         2   \n",
       " 0               0.404188  0.429002  0.018609  0.546790  0.434601   \n",
       " 1               0.494200  0.477908  0.002595  0.712042  0.285363   \n",
       " 2               0.431670  0.418040  0.034529  0.709298  0.256172   \n",
       " 3               0.460795  0.484578  0.003066  0.522205  0.474729   \n",
       " 4               0.138389  0.142191  0.879541  0.064248  0.056211   \n",
       " ..                   ...       ...       ...       ...       ...   \n",
       " 91              0.383885  0.596744  0.002221  0.203040  0.794739   \n",
       " 92              0.392326  0.530433  0.004227  0.191353  0.804419   \n",
       " 93              0.129678  0.116914  0.957668  0.019936  0.022396   \n",
       " 94              0.064072  0.050792  0.993978  0.002026  0.003997   \n",
       " 95              0.140913  0.124751  0.956806  0.021663  0.021531   \n",
       " \n",
       " modality          Modality_b                                                  \\\n",
       " base predictor          ADAB                                   XGB             \n",
       " sample                     0                                     0             \n",
       " class                      0             1             2         0         1   \n",
       " 0               1.312137e-13  4.930690e-01  5.069310e-01  0.015252  0.385479   \n",
       " 1               5.885734e-11  9.956453e-01  4.354652e-03  0.011954  0.980443   \n",
       " 2               5.885734e-11  9.956453e-01  4.354652e-03  0.011954  0.980443   \n",
       " 3               1.312137e-13  4.930690e-01  5.069310e-01  0.004489  0.030970   \n",
       " 4               9.999947e-01  5.311986e-06  2.323302e-08  0.986233  0.009322   \n",
       " ..                       ...           ...           ...       ...       ...   \n",
       " 91              3.138965e-16  1.488947e-08  1.000000e+00  0.003772  0.003550   \n",
       " 92              5.902975e-11  9.993748e-01  6.251975e-04  0.003704  0.993587   \n",
       " 93              9.999947e-01  5.318417e-06  3.324532e-09  0.984221  0.010667   \n",
       " 94              9.999947e-01  5.318417e-06  3.324532e-09  0.984221  0.010667   \n",
       " 95              9.999947e-01  5.318417e-06  3.324532e-09  0.984221  0.010667   \n",
       " \n",
       " modality                                                          \\\n",
       " base predictor             DT             RF                       \n",
       " sample                      0              0                       \n",
       " class                  2    0    1    2    0         1         2   \n",
       " 0               0.599269  0.0  0.5  0.5  0.0  0.419667  0.580333   \n",
       " 1               0.007603  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 2               0.007603  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 3               0.964541  0.0  0.0  1.0  0.0  0.139000  0.861000   \n",
       " 4               0.004445  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " ..                   ...  ...  ...  ...  ...       ...       ...   \n",
       " 91              0.992678  0.0  0.0  1.0  0.0  0.000000  1.000000   \n",
       " 92              0.002709  0.0  1.0  0.0  0.0  1.000000  0.000000   \n",
       " 93              0.005112  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 94              0.005112  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " 95              0.005112  1.0  0.0  0.0  1.0  0.000000  0.000000   \n",
       " \n",
       " modality                                                                 \\\n",
       " base predictor            GB                              KNN             \n",
       " sample                     0                                0             \n",
       " class                      0             1             2    0    1    2   \n",
       " 0               3.469322e-04  4.997210e-01  4.999321e-01  0.0  0.2  0.8   \n",
       " 1               7.491663e-06  9.999852e-01  7.278680e-06  0.0  1.0  0.0   \n",
       " 2               7.491663e-06  9.999852e-01  7.278680e-06  0.0  1.0  0.0   \n",
       " 3               1.934148e-05  9.522254e-05  9.998854e-01  0.0  0.2  0.8   \n",
       " 4               9.999921e-01  7.251110e-06  6.323993e-07  1.0  0.0  0.0   \n",
       " ..                       ...           ...           ...  ...  ...  ...   \n",
       " 91              6.468994e-07  6.284485e-07  9.999987e-01  0.0  0.0  1.0   \n",
       " 92              6.530903e-07  9.999987e-01  6.530903e-07  0.0  1.0  0.0   \n",
       " 93              9.999987e-01  6.284485e-07  6.468994e-07  1.0  0.0  0.0   \n",
       " 94              9.999987e-01  6.284485e-07  6.468994e-07  1.0  0.0  0.0   \n",
       " 95              9.999987e-01  6.284485e-07  6.468994e-07  1.0  0.0  0.0   \n",
       " \n",
       " modality                                                                       \\\n",
       " base predictor        LR                                     NB                 \n",
       " sample                 0                                      0                 \n",
       " class                  0         1             2              0             1   \n",
       " 0               0.002981  0.465738  5.312815e-01  6.512194e-139  1.322323e-01   \n",
       " 1               0.046876  0.920208  3.291601e-02   4.180699e-57  9.999758e-01   \n",
       " 2               0.026082  0.878383  9.553508e-02   7.151222e-80  9.994982e-01   \n",
       " 3               0.002120  0.420275  5.776058e-01  2.392857e-143  8.679076e-02   \n",
       " 4               0.958762  0.041236  1.947943e-06   1.000000e+00  3.273125e-18   \n",
       " ..                   ...       ...           ...            ...           ...   \n",
       " 91              0.000007  0.041085  9.589077e-01  2.744288e-212  3.055404e-06   \n",
       " 92              0.004164  0.665115  3.307217e-01  2.629138e-103  9.573906e-01   \n",
       " 93              0.966810  0.033187  2.334264e-06   1.000000e+00  1.218825e-14   \n",
       " 94              0.987758  0.012241  3.212631e-07   1.000000e+00  8.266557e-17   \n",
       " 95              0.958330  0.041667  2.690378e-06   1.000000e+00  1.760650e-15   \n",
       " \n",
       " modality                                                              \\\n",
       " base predictor                     MLP                           SVM   \n",
       " sample                               0                             0   \n",
       " class                      2         0         1         2         0   \n",
       " 0               8.677677e-01  0.007510  0.358955  0.633535  0.018239   \n",
       " 1               2.416856e-05  0.100228  0.706597  0.193175  0.022907   \n",
       " 2               5.017653e-04  0.045143  0.609136  0.345721  0.016175   \n",
       " 3               9.132092e-01  0.006990  0.368161  0.624850  0.018275   \n",
       " 4               4.229975e-23  0.871226  0.114990  0.013784  0.942875   \n",
       " ..                       ...       ...       ...       ...       ...   \n",
       " 91              9.999969e-01  0.001683  0.408912  0.589405  0.019227   \n",
       " 92              4.260938e-02  0.020115  0.599235  0.380650  0.016841   \n",
       " 93              3.319252e-22  0.859775  0.120501  0.019724  0.947558   \n",
       " 94              2.439787e-24  0.886135  0.096703  0.017162  0.952958   \n",
       " 95              9.983987e-23  0.864467  0.120849  0.014684  0.945158   \n",
       " \n",
       " modality                           labels  \n",
       " base predictor                             \n",
       " sample                                     \n",
       " class                  1         2         \n",
       " 0               0.492370  0.489392      2  \n",
       " 1               0.965831  0.011262      1  \n",
       " 2               0.957430  0.026395      1  \n",
       " 3               0.407102  0.574623      2  \n",
       " 4               0.037394  0.019731      0  \n",
       " ..                   ...       ...    ...  \n",
       " 91              0.011092  0.969681      2  \n",
       " 92              0.695226  0.287933      1  \n",
       " 93              0.032626  0.019816      0  \n",
       " 94              0.022632  0.024410      0  \n",
       " 95              0.035420  0.019422      0  \n",
       " \n",
       " [96 rows x 61 columns]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_iris.meta_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<eipy.ei.EnsembleIntegration at 0x7fc898822d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_iris.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.264069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADAB       XGB        DT        RF        GB       KNN  \\\n",
       "precision  0.111111  0.333333  0.111111  0.333333  0.111111  0.333333   \n",
       "recall     0.333333  0.333333  0.333333  0.333333  0.333333  0.333333   \n",
       "f1         0.166667  0.325758  0.166667  0.309524  0.166667  0.325758   \n",
       "\n",
       "                 LR        NB       MLP       SVM  \n",
       "precision  0.111111  0.222222  0.111111  0.222222  \n",
       "recall     0.333333  0.333333  0.333333  0.333333  \n",
       "f1         0.166667  0.240196  0.166667  0.264069  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_iris.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferred_meta_model = EI_iris.meta_summary[\"metrics\"].loc[\"precision\"].idxmax()\n",
    "y_pred_iris = EI_iris.predict(X_dict=iris_data_test, meta_model_key=preferred_meta_model)\n",
    "y_pred_iris = [np.argmax(np.array(y)) for y in y_pred_iris]\n",
    "y_pred_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred_iris))])/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[19:33:13] /workspace/src/data/data.cc:501: Check failed: this->labels.Size() % this->num_row_ == 0 (120 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x3581ea) [0x7fc7c6e991ea]\n  [bt] (1) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x389457) [0x7fc7c6eca457]\n  [bt] (2) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x38a4b1) [0x7fc7c6ecb4b1]\n  [bt] (3) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7fc7c6c9f210]\n  [bt] (4) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc8b46ba17e]\n  [bt] (5) /lib64/libffi.so.6(ffi_call+0x36f) [0x7fc8b46b9b2f]\n  [bt] (6) /usr/lib64/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x1375d) [0x7fc8b48d075d]\n  [bt] (7) /usr/lib64/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x13db5) [0x7fc8b48d0db5]\n  [bt] (8) /lib64/libpython3.9.so.1.0(_PyObject_MakeTpCall+0x2ab) [0x7fc8b6a0364b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 29\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m xgb_model \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m xgb_model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m accuracy\u001b[39m=\u001b[39maccuracy_score(y_test,y_pred)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/sklearn.py:1496\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[0;32m-> 1496\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1499\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1500\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1501\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1502\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1503\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1504\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1505\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1506\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1507\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1508\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1509\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1510\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1511\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[1;32m   1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1516\u001b[0m     params,\n\u001b[1;32m   1517\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1527\u001b[0m )\n\u001b[1;32m   1529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/sklearn.py:534\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    515\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    516\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    535\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    536\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    537\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    538\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    539\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    540\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    541\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    542\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    543\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    544\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    545\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    546\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    550\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/sklearn.py:954\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m _can_use_qdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    953\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m    955\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, ref\u001b[39m=\u001b[39;49mref, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, max_bin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bin\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    957\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:1528\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1509\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m     ):\n\u001b[1;32m   1523\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1524\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m   1529\u001b[0m     data,\n\u001b[1;32m   1530\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[1;32m   1531\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   1532\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m   1533\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1534\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1535\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m   1536\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m   1537\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m   1538\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1539\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m   1540\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m   1541\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m   1542\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:1587\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1575\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[1;32m   1576\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[1;32m   1577\u001b[0m )\n\u001b[1;32m   1578\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1579\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1580\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[1;32m   1586\u001b[0m )\n\u001b[0;32m-> 1587\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1588\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:556\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[1;32m    557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:640\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n\u001b[1;32m    639\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/data.py:1260\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1260\u001b[0m input_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:632\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n\u001b[1;32m    631\u001b[0m dispatch_proxy_set_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy, new, cat_codes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_host)\n\u001b[0;32m--> 632\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy\u001b[39m.\u001b[39;49mset_info(\n\u001b[1;32m    633\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    634\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    635\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    636\u001b[0m )\n\u001b[1;32m    637\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:931\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:1069\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \n\u001b[1;32m   1062\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[39m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m-> 1069\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, label, \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/data.py:1198\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy_array(data):\n\u001b[0;32m-> 1198\u001b[0m     _meta_from_numpy(data, name, dtype, handle)\n\u001b[1;32m   1199\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/data.py:1139\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMasked array is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1138\u001b[0m interface_str \u001b[39m=\u001b[39m _array_interface(data)\n\u001b[0;32m-> 1139\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/xgboost/core.py:281\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [19:33:13] /workspace/src/data/data.cc:501: Check failed: this->labels.Size() % this->num_row_ == 0 (120 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x3581ea) [0x7fc7c6e991ea]\n  [bt] (1) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x389457) [0x7fc7c6eca457]\n  [bt] (2) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(+0x38a4b1) [0x7fc7c6ecb4b1]\n  [bt] (3) /home/opc/.venv/lib64/python3.9/site-packages/xgboost/lib/libxgboost.so(XGDMatrixSetInfoFromInterface+0xb0) [0x7fc7c6c9f210]\n  [bt] (4) /lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc8b46ba17e]\n  [bt] (5) /lib64/libffi.so.6(ffi_call+0x36f) [0x7fc8b46b9b2f]\n  [bt] (6) /usr/lib64/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x1375d) [0x7fc8b48d075d]\n  [bt] (7) /usr/lib64/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x13db5) [0x7fc8b48d0db5]\n  [bt] (8) /lib64/libpython3.9.so.1.0(_PyObject_MakeTpCall+0x2ab) [0x7fc8b6a0364b]\n\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train,y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
