{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "import eipy.utils as ut\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is multi-class, run a check on the allowable base and meta models.\n",
    "\n",
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\"),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor filtering base predictors by whether or not they rely on heursitics for multiclass extension\\n\\nnatively_multi_class_predictors = [\"XGBClassifier\",\\n\"BernoulliNB\",\\n\"DecisionTreeClassifier\",\\n\"ExtraTreeClassifier\",\\n\"GaussianNB\",\\n\"KNeighborsClassifier\",\\n\"LabelPropagation\",\\n\"LabelSpreading\",\\n\"LinearDiscriminantAnalysis\",\\n\"LinearSVC\", #(setting multi_class=”crammer_singer”)\\n\"LogisticRegression\", #(setting multi_class=”multinomial”)\\n\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\\n\"MLPClassifier\",\\n\"NearestCentroid\",\\n\"QuadraticDiscriminantAnalysis\",\\n\"RadiusNeighborsClassifier\",\\n\"RandomForestClassifier\",\\n\"RidgeClassifier\",\\n\"RidgeClassifierCV\"]\\n\\nbase_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "For filtering base predictors by whether or not they rely on heursitics for multiclass extension\n",
    "\n",
    "natively_multi_class_predictors = [\"XGBClassifier\",\n",
    "\"BernoulliNB\",\n",
    "\"DecisionTreeClassifier\",\n",
    "\"ExtraTreeClassifier\",\n",
    "\"GaussianNB\",\n",
    "\"KNeighborsClassifier\",\n",
    "\"LabelPropagation\",\n",
    "\"LabelSpreading\",\n",
    "\"LinearDiscriminantAnalysis\",\n",
    "\"LinearSVC\", #(setting multi_class=”crammer_singer”)\n",
    "\"LogisticRegression\", #(setting multi_class=”multinomial”)\n",
    "\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\n",
    "\"MLPClassifier\",\n",
    "\"NearestCentroid\",\n",
    "\"QuadraticDiscriminantAnalysis\",\n",
    "\"RadiusNeighborsClassifier\",\n",
    "\"RandomForestClassifier\",\n",
    "\"RidgeClassifier\",\n",
    "\"RidgeClassifierCV\"]\n",
    "\n",
    "base_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "multi modal multi-class toy data generation\"\"\"\n",
    "\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "modality_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "modality_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "modality_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_train, y_test = train_test_split(modality_0, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_1_train, X_1_test, _,_ = train_test_split(modality_1, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_2_train, X_2_test, _,_ = train_test_split(modality_2, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        sampling_aggregation=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EI.fit_base(X=data_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': modality       Modality_0                                                    \\\n",
       " base predictor       ADAB        DT        GB       KNN        LR       MLP   \n",
       " precision        0.611520  0.533296  0.537513  0.530066  0.559550  0.554041   \n",
       " recall           0.666667  0.529167  0.597222  0.579167  0.584722  0.629167   \n",
       " f1               0.535912  0.531102  0.553553  0.545643  0.569060  0.562239   \n",
       " \n",
       " modality                                               Modality_1            \\\n",
       " base predictor        NB        RF       SVM       XGB       ADAB        DT   \n",
       " precision       0.544751  0.523247  0.527670  0.525531   0.443835  0.548634   \n",
       " recall          0.608333  0.562500  0.615278  0.540278   0.665278  0.550000   \n",
       " f1              0.559038  0.537778  0.545892  0.532115   0.532352  0.549286   \n",
       " \n",
       " modality                                                                    \\\n",
       " base predictor        GB       KNN        LR       MLP        NB        RF   \n",
       " precision       0.573138  0.535516  0.547415  0.531728  0.531348  0.545990   \n",
       " recall          0.618056  0.579167  0.573611  0.615278  0.602778  0.580556   \n",
       " f1              0.582336  0.548949  0.557566  0.548632  0.548937  0.558017   \n",
       " \n",
       " modality                           Modality_2                                \\\n",
       " base predictor       SVM       XGB       ADAB        DT        GB       KNN   \n",
       " precision       0.560214  0.538452   0.713298  0.543009  0.550352  0.515316   \n",
       " recall          0.643056  0.552778   0.670833  0.538889  0.600000  0.562500   \n",
       " f1              0.559927  0.544690   0.545340  0.540856  0.563539  0.531808   \n",
       " \n",
       " modality                                                                    \n",
       " base predictor        LR       MLP        NB        RF       SVM       XGB  \n",
       " precision       0.543307  0.550029  0.558338  0.546901  0.560872  0.536921  \n",
       " recall          0.568056  0.629167  0.619444  0.572222  0.633333  0.552778  \n",
       " f1              0.553147  0.559191  0.569015  0.556679  0.566391  0.543601  ,\n",
       " 'thresholds': modality       Modality_0                                                    \\\n",
       " base predictor       ADAB        DT        GB       KNN        LR       MLP   \n",
       " precision        0.666667  0.529167  0.597222  0.579167  0.584722  0.629167   \n",
       " recall           0.666667  0.529167  0.597222  0.579167  0.584722  0.629167   \n",
       " f1               0.666667  0.529167  0.597222  0.579167  0.584722  0.629167   \n",
       " \n",
       " modality                                             Modality_1        \\\n",
       " base predictor        NB      RF       SVM       XGB       ADAB    DT   \n",
       " precision       0.608333  0.5625  0.615278  0.540278   0.665278  0.55   \n",
       " recall          0.608333  0.5625  0.615278  0.540278   0.665278  0.55   \n",
       " f1              0.608333  0.5625  0.615278  0.540278   0.665278  0.55   \n",
       " \n",
       " modality                                                                    \\\n",
       " base predictor        GB       KNN        LR       MLP        NB        RF   \n",
       " precision       0.618056  0.579167  0.573611  0.615278  0.602778  0.580556   \n",
       " recall          0.618056  0.579167  0.573611  0.615278  0.602778  0.580556   \n",
       " f1              0.618056  0.579167  0.573611  0.615278  0.602778  0.580556   \n",
       " \n",
       " modality                           Modality_2                         \\\n",
       " base predictor       SVM       XGB       ADAB        DT   GB     KNN   \n",
       " precision       0.643056  0.552778   0.670833  0.538889  0.6  0.5625   \n",
       " recall          0.643056  0.552778   0.670833  0.538889  0.6  0.5625   \n",
       " f1              0.643056  0.552778   0.670833  0.538889  0.6  0.5625   \n",
       " \n",
       " modality                                                                    \n",
       " base predictor        LR       MLP        NB        RF       SVM       XGB  \n",
       " precision       0.568056  0.629167  0.619444  0.572222  0.633333  0.552778  \n",
       " recall          0.568056  0.629167  0.619444  0.572222  0.633333  0.552778  \n",
       " f1              0.568056  0.629167  0.619444  0.572222  0.633333  0.552778  }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_0</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_1</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.873335</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.120604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741568</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.787548</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.212370</td>\n",
       "      <td>0.734722</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>0.694402</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.302783</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.461601</td>\n",
       "      <td>0.537134</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.446751</td>\n",
       "      <td>0.542124</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812660</td>\n",
       "      <td>0.179730</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.705237</td>\n",
       "      <td>0.294760</td>\n",
       "      <td>3.893088e-06</td>\n",
       "      <td>0.757580</td>\n",
       "      <td>0.238677</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.704742</td>\n",
       "      <td>0.286515</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.190731</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.803881</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>0.113573</td>\n",
       "      <td>0.484108</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.692139</td>\n",
       "      <td>0.344770</td>\n",
       "      <td>0.058037</td>\n",
       "      <td>0.597193</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.082868</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.305751</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.688637</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.285826</td>\n",
       "      <td>0.743124</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.661490</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>0.328193</td>\n",
       "      <td>0.685259</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.308217</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>0.877135</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.205477</td>\n",
       "      <td>0.780552</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643465</td>\n",
       "      <td>0.320709</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.728743</td>\n",
       "      <td>0.270921</td>\n",
       "      <td>3.361942e-04</td>\n",
       "      <td>0.651904</td>\n",
       "      <td>0.333255</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.636935</td>\n",
       "      <td>0.355380</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.496820</td>\n",
       "      <td>5.031799e-01</td>\n",
       "      <td>2.222557e-16</td>\n",
       "      <td>0.130016</td>\n",
       "      <td>0.868783</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>0.379187</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381799</td>\n",
       "      <td>0.527239</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.725416</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.356892</td>\n",
       "      <td>0.614702</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.314243</td>\n",
       "      <td>0.683171</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.223397e-16</td>\n",
       "      <td>5.036501e-01</td>\n",
       "      <td>0.496350</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.492612</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.491289</td>\n",
       "      <td>0.495962</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.260780</td>\n",
       "      <td>0.271721</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>0.270495</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>0.315407</td>\n",
       "      <td>0.241999</td>\n",
       "      <td>0.442594</td>\n",
       "      <td>0.252198</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.559330</td>\n",
       "      <td>2.222529e-16</td>\n",
       "      <td>0.496881</td>\n",
       "      <td>5.031186e-01</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.994307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.080650</td>\n",
       "      <td>0.914909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.182152</td>\n",
       "      <td>0.801596</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.219851</td>\n",
       "      <td>7.801217e-01</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.205562</td>\n",
       "      <td>0.792153</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.318134</td>\n",
       "      <td>0.676815</td>\n",
       "      <td>0.496820</td>\n",
       "      <td>5.031799e-01</td>\n",
       "      <td>2.222557e-16</td>\n",
       "      <td>0.678152</td>\n",
       "      <td>0.319825</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.427438</td>\n",
       "      <td>0.565553</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303977</td>\n",
       "      <td>0.650942</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.746303</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.651430</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.335281</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.223397e-16</td>\n",
       "      <td>5.036501e-01</td>\n",
       "      <td>0.496350</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.178437</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.530523</td>\n",
       "      <td>0.158370</td>\n",
       "      <td>0.199676</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.171173</td>\n",
       "      <td>0.328954</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.396572</td>\n",
       "      <td>0.458250</td>\n",
       "      <td>2.222529e-16</td>\n",
       "      <td>0.496881</td>\n",
       "      <td>5.031186e-01</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.107689</td>\n",
       "      <td>0.889078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.188231</td>\n",
       "      <td>0.794377</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.219310</td>\n",
       "      <td>7.806570e-01</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.215564</td>\n",
       "      <td>0.781898</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.319830</td>\n",
       "      <td>0.676011</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.076960</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.920648</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.328162</td>\n",
       "      <td>0.063236</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.766259</td>\n",
       "      <td>0.322704</td>\n",
       "      <td>0.029860</td>\n",
       "      <td>0.647435</td>\n",
       "      <td>0.191561</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.806101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.205049</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.792652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.495245</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>0.494704</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.389640</td>\n",
       "      <td>0.149040</td>\n",
       "      <td>0.461319</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>0.040081</td>\n",
       "      <td>0.437819</td>\n",
       "      <td>0.513466</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>0.389706</td>\n",
       "      <td>0.514961</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.729893</td>\n",
       "      <td>0.269725</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.337153</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689093</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>0.025567</td>\n",
       "      <td>0.737586</td>\n",
       "      <td>0.262294</td>\n",
       "      <td>1.199098e-04</td>\n",
       "      <td>0.676987</td>\n",
       "      <td>0.312717</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>0.632066</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.559073</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.438637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.256467</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.736677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.334040</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.601797</td>\n",
       "      <td>0.238629</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.334455</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.638505</td>\n",
       "      <td>0.235444</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.762752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.730658</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.268450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.326098</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.663420</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.813545</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>0.763151</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.236831</td>\n",
       "      <td>0.737883</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.258307</td>\n",
       "      <td>0.674201</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.771925</td>\n",
       "      <td>0.227552</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.832982</td>\n",
       "      <td>0.158148</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583089</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.751509</td>\n",
       "      <td>0.247555</td>\n",
       "      <td>9.359377e-04</td>\n",
       "      <td>0.629503</td>\n",
       "      <td>0.345457</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.759947</td>\n",
       "      <td>0.236493</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.588948</td>\n",
       "      <td>0.409782</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.523892</td>\n",
       "      <td>0.470108</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410048</td>\n",
       "      <td>0.507348</td>\n",
       "      <td>0.082605</td>\n",
       "      <td>0.319283</td>\n",
       "      <td>0.676623</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.366665</td>\n",
       "      <td>0.608913</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.286633</td>\n",
       "      <td>0.711375</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.741070</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.255368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.234676</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.491131</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.655889</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.339265</td>\n",
       "      <td>0.592587</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>0.361386</td>\n",
       "      <td>0.672380</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.321674</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.709526</td>\n",
       "      <td>0.287658</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.758846</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744517</td>\n",
       "      <td>0.242041</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.266279</td>\n",
       "      <td>1.542590e-05</td>\n",
       "      <td>0.670398</td>\n",
       "      <td>0.321818</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.710672</td>\n",
       "      <td>0.284397</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.105804</td>\n",
       "      <td>0.893397</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.243999</td>\n",
       "      <td>0.750289</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>0.711016</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.278899</td>\n",
       "      <td>0.721085</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.341974</td>\n",
       "      <td>0.653626</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.324069</td>\n",
       "      <td>0.671813</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2.223192e-16</td>\n",
       "      <td>5.035152e-01</td>\n",
       "      <td>0.496485</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.920323</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.919627</td>\n",
       "      <td>0.076515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.779247</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.819810</td>\n",
       "      <td>0.180093</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.766037</td>\n",
       "      <td>0.224534</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.701820</td>\n",
       "      <td>0.292919</td>\n",
       "      <td>2.222572e-16</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>5.031511e-01</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.452824</td>\n",
       "      <td>0.543666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.207135</td>\n",
       "      <td>0.767142</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>7.942068e-01</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.234306</td>\n",
       "      <td>0.762720</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.305228</td>\n",
       "      <td>0.693098</td>\n",
       "      <td>0.496066</td>\n",
       "      <td>2.223978e-16</td>\n",
       "      <td>5.039340e-01</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.975189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.119909</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.869431</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.270401</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.222018</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.777582</td>\n",
       "      <td>0.285722</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.696755</td>\n",
       "      <td>0.276874</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.719473</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.924327</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.761829</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.228195</td>\n",
       "      <td>0.653560</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.676873</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.317230</td>\n",
       "      <td>0.672044</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.317228</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.599464</td>\n",
       "      <td>0.391220</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.798176</td>\n",
       "      <td>0.192122</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.822668</td>\n",
       "      <td>0.171797</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.525422</td>\n",
       "      <td>0.474577</td>\n",
       "      <td>4.761566e-07</td>\n",
       "      <td>0.672010</td>\n",
       "      <td>0.325162</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.457654</td>\n",
       "      <td>0.519184</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.097810</td>\n",
       "      <td>0.902037</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.220555</td>\n",
       "      <td>0.774808</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428953</td>\n",
       "      <td>0.470013</td>\n",
       "      <td>0.101034</td>\n",
       "      <td>0.356938</td>\n",
       "      <td>0.632894</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.380057</td>\n",
       "      <td>0.586231</td>\n",
       "      <td>0.033712</td>\n",
       "      <td>0.292738</td>\n",
       "      <td>0.702961</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2.223192e-16</td>\n",
       "      <td>5.035152e-01</td>\n",
       "      <td>0.496485</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.915664</td>\n",
       "      <td>0.083608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.141524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.783810</td>\n",
       "      <td>0.196792</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.787540</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.780049</td>\n",
       "      <td>0.214964</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>0.293770</td>\n",
       "      <td>2.222572e-16</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>5.031511e-01</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.878685</td>\n",
       "      <td>0.120832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.328224</td>\n",
       "      <td>0.666778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.275193</td>\n",
       "      <td>0.483138</td>\n",
       "      <td>0.241670</td>\n",
       "      <td>0.222495</td>\n",
       "      <td>0.541858</td>\n",
       "      <td>2.356475e-01</td>\n",
       "      <td>0.307403</td>\n",
       "      <td>0.446939</td>\n",
       "      <td>0.245659</td>\n",
       "      <td>0.120573</td>\n",
       "      <td>0.528285</td>\n",
       "      <td>0.351142</td>\n",
       "      <td>0.496066</td>\n",
       "      <td>2.223978e-16</td>\n",
       "      <td>5.039340e-01</td>\n",
       "      <td>0.203063</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.795730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.313755</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.676339</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.343435</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.585666</td>\n",
       "      <td>0.241844</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.755897</td>\n",
       "      <td>0.324260</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.273303</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.722092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality          Modality_0                                              \\\n",
       "base predictor          ADAB                               XGB             \n",
       "sample                     0                                 0             \n",
       "class                      0             1         2         0         1   \n",
       "0               5.033375e-01  2.222770e-16  0.496663  0.990476  0.000190   \n",
       "1               5.033375e-01  2.222770e-16  0.496663  0.082868  0.000607   \n",
       "2               2.223397e-16  5.036501e-01  0.496350  0.008628  0.492612   \n",
       "3               2.223397e-16  5.036501e-01  0.496350  0.000314  0.914500   \n",
       "4               5.033375e-01  2.222770e-16  0.496663  0.205049  0.002299   \n",
       "..                       ...           ...       ...       ...       ...   \n",
       "571             5.034012e-01  2.222858e-16  0.496599  0.730658  0.000891   \n",
       "572             5.034012e-01  2.222858e-16  0.496599  0.741070  0.003562   \n",
       "573             2.223192e-16  5.035152e-01  0.496485  0.001255  0.920323   \n",
       "574             5.034012e-01  2.222858e-16  0.496599  0.988050  0.000777   \n",
       "575             2.223192e-16  5.035152e-01  0.496485  0.000728  0.915664   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.009334  1.0  0.0  0.0  0.91  0.00  0.09  0.873335  0.006062   \n",
       "1               0.916525  0.0  0.0  1.0  0.54  0.00  0.46  0.305751  0.005220   \n",
       "2               0.498759  0.0  0.0  1.0  0.04  0.63  0.33  0.012749  0.491289   \n",
       "3               0.085186  0.0  1.0  0.0  0.01  0.74  0.25  0.007984  0.813579   \n",
       "4               0.792652  1.0  0.0  0.0  0.52  0.01  0.47  0.495245  0.010051   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "571             0.268450  1.0  0.0  0.0  0.85  0.00  0.15  0.326098  0.010482   \n",
       "572             0.255368  0.0  0.0  1.0  0.73  0.00  0.27  0.758719  0.006605   \n",
       "573             0.078422  0.0  1.0  0.0  0.00  0.74  0.26  0.003857  0.919627   \n",
       "574             0.011173  1.0  0.0  0.0  0.87  0.00  0.13  0.924327  0.001435   \n",
       "575             0.083608  0.0  1.0  0.0  0.00  0.83  0.17  0.005214  0.853261   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.120604  1.0  0.0  0.0  0.741568  0.022422  0.236010   \n",
       "1               0.689029  0.4  0.0  0.6  0.688637  0.025537  0.285826   \n",
       "2               0.495962  0.2  0.4  0.4  0.260780  0.271721  0.467498   \n",
       "3               0.178437  0.4  0.4  0.2  0.217677  0.251799  0.530523   \n",
       "4               0.494704  0.4  0.0  0.6  0.389640  0.149040  0.461319   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "571             0.663420  0.8  0.0  0.2  0.813545  0.010634  0.175820   \n",
       "572             0.234676  0.8  0.0  0.2  0.491131  0.072969  0.435900   \n",
       "573             0.076515  0.0  0.8  0.2  0.025359  0.779247  0.195393   \n",
       "574             0.074238  0.8  0.0  0.2  0.761829  0.009976  0.228195   \n",
       "575             0.141524  0.0  0.8  0.2  0.019398  0.783810  0.196792   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.787548  0.000082  0.212370  0.734722  0.004587  0.260691   \n",
       "1               0.743124  0.000103  0.256774  0.661490  0.010317  0.328193   \n",
       "2               0.197136  0.270495  0.532369  0.315407  0.241999  0.442594   \n",
       "3               0.158370  0.199676  0.641954  0.171173  0.328954  0.499873   \n",
       "4               0.522100  0.040081  0.437819  0.513466  0.096828  0.389706   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.763151  0.000017  0.236831  0.737883  0.003810  0.258307   \n",
       "572             0.655889  0.004847  0.339265  0.592587  0.046026  0.361386   \n",
       "573             0.000097  0.819810  0.180093  0.009429  0.766037  0.224534   \n",
       "574             0.653560  0.000010  0.346429  0.676873  0.005897  0.317230   \n",
       "575             0.000051  0.787540  0.212409  0.004987  0.780049  0.214964   \n",
       "\n",
       "modality                                        Modality_1            \\\n",
       "base predictor       SVM                              ADAB             \n",
       "sample                 0                                 0             \n",
       "class                  0         1         2             0         1   \n",
       "0               0.694402  0.002815  0.302783  5.038713e-01  0.496129   \n",
       "1               0.685259  0.006523  0.308217  5.038713e-01  0.496129   \n",
       "2               0.252198  0.188472  0.559330  2.222529e-16  0.496881   \n",
       "3               0.145179  0.396572  0.458250  2.222529e-16  0.496881   \n",
       "4               0.514961  0.019730  0.465309  5.038713e-01  0.496129   \n",
       "..                   ...       ...       ...           ...       ...   \n",
       "571             0.674201  0.010199  0.315600  5.038713e-01  0.496129   \n",
       "572             0.672380  0.005945  0.321674  5.038713e-01  0.496129   \n",
       "573             0.005261  0.701820  0.292919  2.222572e-16  0.496849   \n",
       "574             0.672044  0.010727  0.317228  5.038713e-01  0.496129   \n",
       "575             0.002791  0.703439  0.293770  2.222572e-16  0.496849   \n",
       "\n",
       "modality                                                                   \\\n",
       "base predictor                     XGB                       DT             \n",
       "sample                               0                        0             \n",
       "class                      2         0         1         2    0    1    2   \n",
       "0               2.223630e-16  0.461601  0.537134  0.001266  0.0  1.0  0.0   \n",
       "1               2.223630e-16  0.120333  0.877135  0.002532  0.0  1.0  0.0   \n",
       "2               5.031186e-01  0.000192  0.005501  0.994307  0.0  0.0  1.0   \n",
       "3               5.031186e-01  0.000097  0.001815  0.998088  0.0  0.0  1.0   \n",
       "4               2.223630e-16  0.729893  0.269725  0.000383  1.0  0.0  0.0   \n",
       "..                       ...       ...       ...       ...  ...  ...  ...   \n",
       "571             2.223630e-16  0.771925  0.227552  0.000523  1.0  0.0  0.0   \n",
       "572             2.223630e-16  0.709526  0.287658  0.002815  1.0  0.0  0.0   \n",
       "573             5.031511e-01  0.000191  0.012208  0.987600  0.0  0.0  1.0   \n",
       "574             2.223630e-16  0.599464  0.391220  0.009316  1.0  0.0  0.0   \n",
       "575             5.031511e-01  0.000482  0.878685  0.120832  0.0  0.0  1.0   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor    RF                    GB                      KNN             \n",
       "sample             0                     0                        0             \n",
       "class              0     1     2         0         1         2    0    1    2   \n",
       "0               0.51  0.49  0.00  0.446751  0.542124  0.011125  0.8  0.2  0.0   \n",
       "1               0.35  0.65  0.00  0.205477  0.780552  0.013971  0.6  0.4  0.0   \n",
       "2               0.00  0.04  0.96  0.004441  0.080650  0.914909  0.0  0.0  1.0   \n",
       "3               0.00  0.01  0.99  0.003233  0.107689  0.889078  0.0  0.2  0.8   \n",
       "4               0.89  0.11  0.00  0.656200  0.337153  0.006647  0.8  0.2  0.0   \n",
       "..               ...   ...   ...       ...       ...       ...  ...  ...  ...   \n",
       "571             0.71  0.29  0.00  0.832982  0.158148  0.008870  0.6  0.4  0.0   \n",
       "572             0.69  0.31  0.00  0.758846  0.231045  0.010109  0.8  0.2  0.0   \n",
       "573             0.00  0.10  0.90  0.003511  0.452824  0.543666  0.0  0.2  0.8   \n",
       "574             0.44  0.56  0.00  0.798176  0.192122  0.009702  0.4  0.6  0.0   \n",
       "575             0.00  0.50  0.50  0.004998  0.328224  0.666778  0.0  0.6  0.4   \n",
       "\n",
       "modality                                                          \\\n",
       "base predictor        LR                            NB             \n",
       "sample                 0                             0             \n",
       "class                  0         1         2         0         1   \n",
       "0               0.812660  0.179730  0.007610  0.705237  0.294760   \n",
       "1               0.643465  0.320709  0.035826  0.728743  0.270921   \n",
       "2               0.016252  0.182152  0.801596  0.000027  0.219851   \n",
       "3               0.017392  0.188231  0.794377  0.000033  0.219310   \n",
       "4               0.689093  0.285340  0.025567  0.737586  0.262294   \n",
       "..                   ...       ...       ...       ...       ...   \n",
       "571             0.583089  0.367700  0.049211  0.751509  0.247555   \n",
       "572             0.744517  0.242041  0.013442  0.733706  0.266279   \n",
       "573             0.025723  0.207135  0.767142  0.000044  0.205749   \n",
       "574             0.822668  0.171797  0.005535  0.525422  0.474577   \n",
       "575             0.275193  0.483138  0.241670  0.222495  0.541858   \n",
       "\n",
       "modality                                                              \\\n",
       "base predictor                     MLP                           SVM   \n",
       "sample                               0                             0   \n",
       "class                      2         0         1         2         0   \n",
       "0               3.893088e-06  0.757580  0.238677  0.003743  0.704742   \n",
       "1               3.361942e-04  0.651904  0.333255  0.014840  0.636935   \n",
       "2               7.801217e-01  0.002285  0.205562  0.792153  0.005052   \n",
       "3               7.806570e-01  0.002537  0.215564  0.781898  0.004159   \n",
       "4               1.199098e-04  0.676987  0.312717  0.010295  0.632066   \n",
       "..                       ...       ...       ...       ...       ...   \n",
       "571             9.359377e-04  0.629503  0.345457  0.025041  0.759947   \n",
       "572             1.542590e-05  0.670398  0.321818  0.007784  0.710672   \n",
       "573             7.942068e-01  0.002974  0.234306  0.762720  0.001675   \n",
       "574             4.761566e-07  0.672010  0.325162  0.002828  0.457654   \n",
       "575             2.356475e-01  0.307403  0.446939  0.245659  0.120573   \n",
       "\n",
       "modality                           Modality_2                              \\\n",
       "base predictor                           ADAB                               \n",
       "sample                                      0                               \n",
       "class                  1         2          0             1             2   \n",
       "0               0.286515  0.008744   0.496191  2.223908e-16  5.038085e-01   \n",
       "1               0.355380  0.007685   0.496820  5.031799e-01  2.222557e-16   \n",
       "2               0.318134  0.676815   0.496820  5.031799e-01  2.222557e-16   \n",
       "3               0.319830  0.676011   0.496191  2.223908e-16  5.038085e-01   \n",
       "4               0.361283  0.006652   0.496191  2.223908e-16  5.038085e-01   \n",
       "..                   ...       ...        ...           ...           ...   \n",
       "571             0.236493  0.003560   0.496942  5.030579e-01  2.222392e-16   \n",
       "572             0.284397  0.004932   0.496942  5.030579e-01  2.222392e-16   \n",
       "573             0.305228  0.693098   0.496066  2.223978e-16  5.039340e-01   \n",
       "574             0.519184  0.023162   0.496942  5.030579e-01  2.222392e-16   \n",
       "575             0.528285  0.351142   0.496066  2.223978e-16  5.039340e-01   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor       XGB                       DT              RF               \n",
       "sample                 0                        0               0               \n",
       "class                  0         1         2    0    1    2     0     1     2   \n",
       "0               0.034906  0.000094  0.965000  0.0  0.0  1.0  0.19  0.00  0.81   \n",
       "1               0.130016  0.868783  0.001201  0.0  1.0  0.0  0.27  0.73  0.00   \n",
       "2               0.678152  0.319825  0.002023  0.0  1.0  0.0  0.56  0.44  0.00   \n",
       "3               0.006253  0.000095  0.993652  0.0  0.0  1.0  0.06  0.00  0.94   \n",
       "4               0.559073  0.002290  0.438637  1.0  0.0  0.0  0.60  0.00  0.40   \n",
       "..                   ...       ...       ...  ...  ...  ...   ...   ...   ...   \n",
       "571             0.588948  0.409782  0.001270  1.0  0.0  0.0  0.54  0.46  0.00   \n",
       "572             0.105804  0.893397  0.000799  1.0  0.0  0.0  0.44  0.56  0.00   \n",
       "573             0.023767  0.001044  0.975189  0.0  0.0  1.0  0.25  0.00  0.75   \n",
       "574             0.097810  0.902037  0.000153  0.0  1.0  0.0  0.19  0.81  0.00   \n",
       "575             0.203063  0.001206  0.795730  0.0  0.0  1.0  0.28  0.00  0.72   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor        GB                      KNN                  LR   \n",
       "sample                 0                        0                   0   \n",
       "class                  0         1         2    0    1    2         0   \n",
       "0               0.190731  0.005388  0.803881  0.4  0.0  0.6  0.402319   \n",
       "1               0.616100  0.379187  0.004714  0.2  0.8  0.0  0.381799   \n",
       "2               0.427438  0.565553  0.007009  0.4  0.6  0.0  0.303977   \n",
       "3               0.076960  0.002392  0.920648  0.2  0.0  0.8  0.328162   \n",
       "4               0.256467  0.006856  0.736677  0.2  0.0  0.8  0.334040   \n",
       "..                   ...       ...       ...  ...  ...  ...       ...   \n",
       "571             0.523892  0.470108  0.005999  0.6  0.4  0.0  0.410048   \n",
       "572             0.243999  0.750289  0.005711  0.4  0.6  0.0  0.267849   \n",
       "573             0.119909  0.010660  0.869431  0.2  0.0  0.8  0.270401   \n",
       "574             0.220555  0.774808  0.004636  0.2  0.8  0.0  0.428953   \n",
       "575             0.313755  0.009906  0.676339  0.2  0.0  0.8  0.343435   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor                            NB                           MLP   \n",
       "sample                                     0                             0   \n",
       "class                  1         2         0         1         2         0   \n",
       "0               0.113573  0.484108  0.293706  0.014156  0.692139  0.344770   \n",
       "1               0.527239  0.090961  0.271800  0.725416  0.002784  0.356892   \n",
       "2               0.650942  0.045081  0.253442  0.746303  0.000256  0.341900   \n",
       "3               0.063236  0.608602  0.230185  0.003556  0.766259  0.322704   \n",
       "4               0.064163  0.601797  0.238629  0.002247  0.759124  0.334455   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.507348  0.082605  0.319283  0.676623  0.004094  0.366665   \n",
       "572             0.711016  0.021135  0.278899  0.721085  0.000017  0.341974   \n",
       "573             0.039299  0.690299  0.222018  0.000400  0.777582  0.285722   \n",
       "574             0.470013  0.101034  0.356938  0.632894  0.010168  0.380057   \n",
       "575             0.070899  0.585666  0.241844  0.002259  0.755897  0.324260   \n",
       "\n",
       "modality                                                         labels  \n",
       "base predictor                           SVM                             \n",
       "sample                                     0                             \n",
       "class                  1         2         0         1         2         \n",
       "0               0.058037  0.597193  0.235021  0.003676  0.761303      0  \n",
       "1               0.614702  0.028406  0.314243  0.683171  0.002586      0  \n",
       "2               0.651430  0.006671  0.335281  0.662332  0.002388      1  \n",
       "3               0.029860  0.647435  0.191561  0.002338  0.806101      2  \n",
       "4               0.027040  0.638505  0.235444  0.001804  0.762752      0  \n",
       "..                   ...       ...       ...       ...       ...    ...  \n",
       "571             0.608913  0.024422  0.286633  0.711375  0.001992      0  \n",
       "572             0.653626  0.004401  0.324069  0.671813  0.004119      0  \n",
       "573             0.017523  0.696755  0.276874  0.003653  0.719473      2  \n",
       "574             0.586231  0.033712  0.292738  0.702961  0.004301      0  \n",
       "575             0.036452  0.639288  0.273303  0.004605  0.722092      2  \n",
       "\n",
       "[576 rows x 91 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"labels\" in list(EI.meta_training_data[0].columns.get_level_values(level=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Modality_0</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Modality_1</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Modality_2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>MLP</th>\n",
       "      <th>NB</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>XGB</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality       Modality_0                                Modality_1            \\\n",
       "base predictor       ADAB DT GB KNN LR MLP NB RF SVM XGB       ADAB DT GB KNN   \n",
       "sample                  0  0  0   0  0   0  0  0   0   0          0  0  0   0   \n",
       "0                       0  0  0   0  0   0  0  0   0   0          0  1  1   0   \n",
       "1                       0  2  2   2  0   0  0  0   0   2          0  1  1   0   \n",
       "2                       1  2  2   1  2   2  2  1   2   2          2  2  2   2   \n",
       "3                       1  1  1   0  2   2  2  1   2   1          2  2  2   2   \n",
       "4                       0  0  0   2  2   0  0  0   0   2          0  0  0   0   \n",
       "..                    ... .. ..  .. ..  .. .. ..  ..  ..        ... .. ..  ..   \n",
       "571                     0  0  2   0  0   0  0  0   0   0          0  0  0   0   \n",
       "572                     0  2  0   0  0   0  0  0   0   0          0  0  0   0   \n",
       "573                     1  1  1   1  1   1  1  1   1   1          2  2  2   2   \n",
       "574                     0  0  0   0  0   0  0  0   0   0          0  0  0   1   \n",
       "575                     1  1  1   1  1   1  1  1   1   1          2  2  2   1   \n",
       "\n",
       "modality                            Modality_2                                 \\\n",
       "base predictor LR MLP NB RF SVM XGB       ADAB DT GB KNN LR MLP NB RF SVM XGB   \n",
       "sample          0   0  0  0   0   0          0  0  0   0  0   0  0  0   0   0   \n",
       "0               0   0  0  0   0   1          2  2  2   2  2   2  2  2   2   2   \n",
       "1               0   0  0  1   0   1          1  1  0   1  1   1  1  1   1   1   \n",
       "2               2   2  2  2   2   2          1  1  1   1  1   1  1  0   1   0   \n",
       "3               2   2  2  2   2   2          2  2  2   2  2   2  2  2   2   2   \n",
       "4               0   0  0  0   0   0          2  0  2   2  2   2  2  0   2   0   \n",
       "..             ..  .. .. ..  ..  ..        ... .. ..  .. ..  .. .. ..  ..  ..   \n",
       "571             0   0  0  0   0   0          1  0  0   0  1   1  1  0   1   0   \n",
       "572             0   0  0  0   0   0          1  0  1   1  1   1  1  1   1   1   \n",
       "573             2   2  2  2   2   2          2  2  2   2  2   2  2  2   2   2   \n",
       "574             0   0  0  1   1   0          1  1  1   1  1   1  1  1   1   1   \n",
       "575             1   1  1  1   1   1          2  2  2   2  2   2  2  2   2   2   \n",
       "\n",
       "modality       labels  \n",
       "base predictor         \n",
       "sample                 \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   2  \n",
       "4                   0  \n",
       "..                ...  \n",
       "571                 0  \n",
       "572                 0  \n",
       "573                 2  \n",
       "574                 0  \n",
       "575                 2  \n",
       "\n",
       "[576 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.predictive_multiclass_data(EI.meta_training_data)\n",
    "EI.meta_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Modality_0', 'ADAB', 0): 0.6631944444444444,\n",
       " ('Modality_0', 'DT', 0): 0.5190972222222222,\n",
       " ('Modality_0', 'GB', 0): 0.5746527777777778,\n",
       " ('Modality_0', 'KNN', 0): 0.5763888888888888,\n",
       " ('Modality_0', 'LR', 0): 0.5798611111111112,\n",
       " ('Modality_0', 'MLP', 0): 0.6145833333333334,\n",
       " ('Modality_0', 'NB', 0): 0.6059027777777778,\n",
       " ('Modality_0', 'RF', 0): 0.5850694444444444,\n",
       " ('Modality_0', 'SVM', 0): 0.6163194444444444,\n",
       " ('Modality_0', 'XGB', 0): 0.5347222222222222,\n",
       " ('Modality_1', 'ADAB', 0): 0.6666666666666666,\n",
       " ('Modality_1', 'DT', 0): 0.5815972222222222,\n",
       " ('Modality_1', 'GB', 0): 0.6006944444444444,\n",
       " ('Modality_1', 'KNN', 0): 0.5868055555555556,\n",
       " ('Modality_1', 'LR', 0): 0.5711805555555556,\n",
       " ('Modality_1', 'MLP', 0): 0.6163194444444444,\n",
       " ('Modality_1', 'NB', 0): 0.6041666666666666,\n",
       " ('Modality_1', 'RF', 0): 0.5833333333333334,\n",
       " ('Modality_1', 'SVM', 0): 0.6232638888888888,\n",
       " ('Modality_1', 'XGB', 0): 0.5572916666666666,\n",
       " ('Modality_2', 'ADAB', 0): 0.6684027777777778,\n",
       " ('Modality_2', 'DT', 0): 0.5347222222222222,\n",
       " ('Modality_2', 'GB', 0): 0.5885416666666666,\n",
       " ('Modality_2', 'KNN', 0): 0.5885416666666666,\n",
       " ('Modality_2', 'LR', 0): 0.5815972222222222,\n",
       " ('Modality_2', 'MLP', 0): 0.6267361111111112,\n",
       " ('Modality_2', 'NB', 0): 0.6145833333333334,\n",
       " ('Modality_2', 'RF', 0): 0.5746527777777778,\n",
       " ('Modality_2', 'SVM', 0): 0.625,\n",
       " ('Modality_2', 'XGB', 0): 0.5520833333333334}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = EI.meta_training_data[0]\n",
    "model_cols = df.columns[:-1]\n",
    "\n",
    "accuracy_dict = {}\n",
    "for model in model_cols:\n",
    "    correct_predictions = (df[model] == df[\"labels\"]).sum()\n",
    "    total_predictions = len(df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    accuracy_dict[model] = accuracy\n",
    "\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<eipy.ei.EnsembleIntegration at 0x7f02ec0c5640>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.fit_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2.460906117643051e-06, 3.3159024045645574e-08...</td>\n",
       "      <td>[0.0006074096, 0.0018225338, 0.9975701]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.05, 0.95]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.8, 0.2]</td>\n",
       "      <td>[4.691470459764825e-05, 0.12661409660141879, 0...</td>\n",
       "      <td>[0.0, 8.03187518354799e-57, 1.0]</td>\n",
       "      <td>[5.7251503825122835e-05, 0.35460401666758673, ...</td>\n",
       "      <td>[0.0036033589406824595, 0.028779289216808664, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.815167722893416e-05, 1.6360453444818718e-09...</td>\n",
       "      <td>[0.0019455126, 0.0010757219, 0.99697876]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.01, 0.0, 0.99]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.2, 0.8]</td>\n",
       "      <td>[0.0075951906612649524, 0.0002104560301191247,...</td>\n",
       "      <td>[0.0, 7.036055772977667e-110, 1.0]</td>\n",
       "      <td>[0.006447763578538449, 3.204839741207864e-07, ...</td>\n",
       "      <td>[0.016705176901856304, 0.000610423649050003, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.9999993824788106, 3.8554166600920653e-10, 6...</td>\n",
       "      <td>[0.99828064, 0.00082038547, 0.0008990469]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.9999987143430977, 6.42828451411504e-07, 6.4...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.9986778213295513, 0.00014571350196340092, 0...</td>\n",
       "      <td>[1.0, 1.3507614681851935e-113, 0.0]</td>\n",
       "      <td>[0.9996176887533161, 2.7422688889596234e-08, 0...</td>\n",
       "      <td>[0.9941357485934554, 0.0004782279350967335, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.5398452760075055e-05, 1.4709960095830085e-0...</td>\n",
       "      <td>[0.0025355262, 0.0013113541, 0.99615306]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.18, 0.0, 0.82]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.6, 0.4]</td>\n",
       "      <td>[0.005517038521205276, 0.0026989846600619545, ...</td>\n",
       "      <td>[0.0, 4.713636813249683e-99, 1.0]</td>\n",
       "      <td>[0.0007476765786744228, 0.0005507859585771903,...</td>\n",
       "      <td>[0.04100041064911489, 0.0026026029568668417, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9999993824788106, 3.8554166600920653e-10, 6...</td>\n",
       "      <td>[0.998898, 0.0004618725, 0.0006401259]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.9999987143430977, 6.42828451411504e-07, 6.4...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.9993525375531593, 7.209852719193506e-06, 0....</td>\n",
       "      <td>[1.0, 4.954100637401223e-116, 0.0]</td>\n",
       "      <td>[0.9999999232608111, 9.969338684427184e-11, 7....</td>\n",
       "      <td>[0.9984679057927461, 0.0001512566232518741, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>[2.8989365873360156e-06, 1.7970745029638833e-0...</td>\n",
       "      <td>[0.0013767994, 0.0008409676, 0.9977823]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0013414917906367661, 4.424671823678826e-05,...</td>\n",
       "      <td>[0.0, 7.612106365737302e-104, 1.0]</td>\n",
       "      <td>[0.0007542149238046141, 1.609872146994478e-08,...</td>\n",
       "      <td>[4.19226892543794e-06, 2.0952284041446033e-06,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>[2.2864616605780478e-06, 1.620640516278768e-09...</td>\n",
       "      <td>[0.0007623872, 0.00078788225, 0.9984497]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.00045224658670595563, 4.0675894278186774e-0...</td>\n",
       "      <td>[0.0, 5.176371076298323e-100, 1.0]</td>\n",
       "      <td>[0.0017199734579424742, 5.203187748216963e-08,...</td>\n",
       "      <td>[0.002247455315579561, 0.00039247269167400626,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>[2.2864616605780478e-06, 1.620640516278768e-09...</td>\n",
       "      <td>[0.0010580685, 0.0010934509, 0.9978485]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[6.42828451411504e-07, 6.42828451411504e-07, 0...</td>\n",
       "      <td>[0.0, 0.4, 0.6]</td>\n",
       "      <td>[0.0012489269800181754, 0.0016403658236976847,...</td>\n",
       "      <td>[0.0, 1.8441954013805752e-91, 1.0]</td>\n",
       "      <td>[0.0012299241661890127, 5.790588841318818e-05,...</td>\n",
       "      <td>[0.006369716676155774, 0.0006548325657352242, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>[0.12540607846427176, 0.8745939215356358, 9.24...</td>\n",
       "      <td>[0.0017701975, 0.9975007, 0.00072910707]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[6.42828451411504e-07, 0.9999987143430977, 6.4...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.03171027691239693, 0.968240916645783, 4.880...</td>\n",
       "      <td>[3.567950622344031e-08, 0.9999999643204951, 0.0]</td>\n",
       "      <td>[0.007298861937401153, 0.9913371305092522, 0.0...</td>\n",
       "      <td>[0.008789272617844778, 0.9878856340761722, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>[0.9396980086371243, 0.06030199136276303, 1.12...</td>\n",
       "      <td>[0.9967891, 0.002573862, 0.00063711894]</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.99, 0.01, 0.0]</td>\n",
       "      <td>[0.9999987143430977, 6.42828451411504e-07, 6.4...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.9917311933591135, 0.008189964581597592, 7.8...</td>\n",
       "      <td>[1.0, 1.7968959207998214e-37, 0.0]</td>\n",
       "      <td>[0.9983116925414514, 0.0001918295596286649, 0....</td>\n",
       "      <td>[0.9962688973127314, 0.0018274035786032252, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ADAB  \\\n",
       "0    [2.460906117643051e-06, 3.3159024045645574e-08...   \n",
       "1    [1.815167722893416e-05, 1.6360453444818718e-09...   \n",
       "2    [0.9999993824788106, 3.8554166600920653e-10, 6...   \n",
       "3    [1.5398452760075055e-05, 1.4709960095830085e-0...   \n",
       "4    [0.9999993824788106, 3.8554166600920653e-10, 6...   \n",
       "..                                                 ...   \n",
       "715  [2.8989365873360156e-06, 1.7970745029638833e-0...   \n",
       "716  [2.2864616605780478e-06, 1.620640516278768e-09...   \n",
       "717  [2.2864616605780478e-06, 1.620640516278768e-09...   \n",
       "718  [0.12540607846427176, 0.8745939215356358, 9.24...   \n",
       "719  [0.9396980086371243, 0.06030199136276303, 1.12...   \n",
       "\n",
       "                                           XGB               DT  \\\n",
       "0      [0.0006074096, 0.0018225338, 0.9975701]  [0.0, 0.0, 1.0]   \n",
       "1     [0.0019455126, 0.0010757219, 0.99697876]  [0.0, 0.0, 1.0]   \n",
       "2    [0.99828064, 0.00082038547, 0.0008990469]  [1.0, 0.0, 0.0]   \n",
       "3     [0.0025355262, 0.0013113541, 0.99615306]  [0.0, 0.0, 1.0]   \n",
       "4       [0.998898, 0.0004618725, 0.0006401259]  [1.0, 0.0, 0.0]   \n",
       "..                                         ...              ...   \n",
       "715    [0.0013767994, 0.0008409676, 0.9977823]  [0.0, 0.0, 1.0]   \n",
       "716   [0.0007623872, 0.00078788225, 0.9984497]  [0.0, 0.0, 1.0]   \n",
       "717    [0.0010580685, 0.0010934509, 0.9978485]  [0.0, 0.0, 1.0]   \n",
       "718   [0.0017701975, 0.9975007, 0.00072910707]  [0.0, 1.0, 0.0]   \n",
       "719    [0.9967891, 0.002573862, 0.00063711894]  [1.0, 0.0, 0.0]   \n",
       "\n",
       "                    RF                                                 GB  \\\n",
       "0    [0.0, 0.05, 0.95]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "1    [0.01, 0.0, 0.99]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "2      [1.0, 0.0, 0.0]  [0.9999987143430977, 6.42828451411504e-07, 6.4...   \n",
       "3    [0.18, 0.0, 0.82]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "4      [1.0, 0.0, 0.0]  [0.9999987143430977, 6.42828451411504e-07, 6.4...   \n",
       "..                 ...                                                ...   \n",
       "715    [0.0, 0.0, 1.0]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "716    [0.0, 0.0, 1.0]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "717    [0.0, 0.0, 1.0]  [6.42828451411504e-07, 6.42828451411504e-07, 0...   \n",
       "718    [0.0, 1.0, 0.0]  [6.42828451411504e-07, 0.9999987143430977, 6.4...   \n",
       "719  [0.99, 0.01, 0.0]  [0.9999987143430977, 6.42828451411504e-07, 6.4...   \n",
       "\n",
       "                 KNN                                                 LR  \\\n",
       "0    [0.0, 0.8, 0.2]  [4.691470459764825e-05, 0.12661409660141879, 0...   \n",
       "1    [0.0, 0.2, 0.8]  [0.0075951906612649524, 0.0002104560301191247,...   \n",
       "2    [1.0, 0.0, 0.0]  [0.9986778213295513, 0.00014571350196340092, 0...   \n",
       "3    [0.0, 0.6, 0.4]  [0.005517038521205276, 0.0026989846600619545, ...   \n",
       "4    [1.0, 0.0, 0.0]  [0.9993525375531593, 7.209852719193506e-06, 0....   \n",
       "..               ...                                                ...   \n",
       "715  [0.0, 0.0, 1.0]  [0.0013414917906367661, 4.424671823678826e-05,...   \n",
       "716  [0.0, 0.0, 1.0]  [0.00045224658670595563, 4.0675894278186774e-0...   \n",
       "717  [0.0, 0.4, 0.6]  [0.0012489269800181754, 0.0016403658236976847,...   \n",
       "718  [0.0, 1.0, 0.0]  [0.03171027691239693, 0.968240916645783, 4.880...   \n",
       "719  [1.0, 0.0, 0.0]  [0.9917311933591135, 0.008189964581597592, 7.8...   \n",
       "\n",
       "                                                   NB  \\\n",
       "0                    [0.0, 8.03187518354799e-57, 1.0]   \n",
       "1                  [0.0, 7.036055772977667e-110, 1.0]   \n",
       "2                 [1.0, 1.3507614681851935e-113, 0.0]   \n",
       "3                   [0.0, 4.713636813249683e-99, 1.0]   \n",
       "4                  [1.0, 4.954100637401223e-116, 0.0]   \n",
       "..                                                ...   \n",
       "715                [0.0, 7.612106365737302e-104, 1.0]   \n",
       "716                [0.0, 5.176371076298323e-100, 1.0]   \n",
       "717                [0.0, 1.8441954013805752e-91, 1.0]   \n",
       "718  [3.567950622344031e-08, 0.9999999643204951, 0.0]   \n",
       "719                [1.0, 1.7968959207998214e-37, 0.0]   \n",
       "\n",
       "                                                   MLP  \\\n",
       "0    [5.7251503825122835e-05, 0.35460401666758673, ...   \n",
       "1    [0.006447763578538449, 3.204839741207864e-07, ...   \n",
       "2    [0.9996176887533161, 2.7422688889596234e-08, 0...   \n",
       "3    [0.0007476765786744228, 0.0005507859585771903,...   \n",
       "4    [0.9999999232608111, 9.969338684427184e-11, 7....   \n",
       "..                                                 ...   \n",
       "715  [0.0007542149238046141, 1.609872146994478e-08,...   \n",
       "716  [0.0017199734579424742, 5.203187748216963e-08,...   \n",
       "717  [0.0012299241661890127, 5.790588841318818e-05,...   \n",
       "718  [0.007298861937401153, 0.9913371305092522, 0.0...   \n",
       "719  [0.9983116925414514, 0.0001918295596286649, 0....   \n",
       "\n",
       "                                                   SVM  labels  \n",
       "0    [0.0036033589406824595, 0.028779289216808664, ...       2  \n",
       "1    [0.016705176901856304, 0.000610423649050003, 0...       2  \n",
       "2    [0.9941357485934554, 0.0004782279350967335, 0....       0  \n",
       "3    [0.04100041064911489, 0.0026026029568668417, 0...       2  \n",
       "4    [0.9984679057927461, 0.0001512566232518741, 0....       0  \n",
       "..                                                 ...     ...  \n",
       "715  [4.19226892543794e-06, 2.0952284041446033e-06,...       2  \n",
       "716  [0.002247455315579561, 0.00039247269167400626,...       2  \n",
       "717  [0.006369716676155774, 0.0006548325657352242, ...       2  \n",
       "718  [0.008789272617844778, 0.9878856340761722, 0.0...       1  \n",
       "719  [0.9962688973127314, 0.0018274035786032252, 0....       0  \n",
       "\n",
       "[720 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ADAB  XGB  DT  RF  GB  KNN  LR  NB  MLP  SVM  labels\n",
       "0       2    2   2   2   2    1   2   2    2    2       2\n",
       "1       2    2   2   2   2    2   2   2    2    2       2\n",
       "2       0    0   0   0   0    0   0   0    0    0       0\n",
       "3       2    2   2   2   2    1   2   2    2    2       2\n",
       "4       0    0   0   0   0    0   0   0    0    0       0\n",
       "..    ...  ...  ..  ..  ..  ...  ..  ..  ...  ...     ...\n",
       "715     2    2   2   2   2    2   2   2    2    2       2\n",
       "716     2    2   2   2   2    2   2   2    2    2       2\n",
       "717     2    2   2   2   2    2   2   2    2    2       2\n",
       "718     1    1   1   1   1    1   1   1    1    1       1\n",
       "719     0    0   0   0   0    0   0   0    0    0       0\n",
       "\n",
       "[720 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax = lambda x: np.argmax(x)\n",
    "cols_to_transform = [col for col in EI.meta_predictions.columns if col != 'labels']\n",
    "for column in cols_to_transform:\n",
    "    EI.meta_predictions[column] = EI.meta_predictions[column].apply(argmax)\n",
    "EI.meta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.994502</td>\n",
       "      <td>0.997245</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.995839</td>\n",
       "      <td>0.987847</td>\n",
       "      <td>0.993141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.994435</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958874</td>\n",
       "      <td>0.986177</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.987527</td>\n",
       "      <td>0.993061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADAB       XGB        DT        RF   GB       KNN        LR  \\\n",
       "precision  0.994502  0.997245  0.998617  0.998617  1.0  0.962963  0.986667   \n",
       "recall     0.994444  0.997222  0.998611  0.998611  1.0  0.958333  0.986111   \n",
       "f1         0.994435  0.997222  0.998611  0.998611  1.0  0.958874  0.986177   \n",
       "\n",
       "                 NB       MLP       SVM  \n",
       "precision  0.995839  0.987847  0.993141  \n",
       "recall     0.995833  0.987500  0.993056  \n",
       "f1         0.995833  0.987527  0.993061  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADAB': 0.9944444444444445,\n",
       " 'XGB': 0.9972222222222222,\n",
       " 'DT': 0.9986111111111111,\n",
       " 'RF': 0.9986111111111111,\n",
       " 'GB': 1.0,\n",
       " 'KNN': 0.9583333333333334,\n",
       " 'LR': 0.9861111111111112,\n",
       " 'NB': 0.9958333333333333,\n",
       " 'MLP': 0.9875,\n",
       " 'SVM': 0.9930555555555556}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = EI.meta_predictions\n",
    "model_columns = df.columns[:-1]\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for model in model_columns:\n",
    "    correct_predictions = (df[model] == df[\"labels\"]).sum()\n",
    "    total_predictions = len(df)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    accuracy_dict[model] = accuracy\n",
    "\n",
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_meta_model = max(accuracy_dict, key=lambda key: accuracy_dict[key])\n",
    "y_pred = EI.predict(X_dict=data_test, meta_model_key=\"GB\")\n",
    "y_pred = [np.argmax(np.array(y)) for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944444444444445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred))])/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222222222222223"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "X = np.concatenate([modality_0,modality_1,modality_2], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y)\n",
    "\n",
    "model = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        60\n",
      "           1       0.89      0.92      0.90        60\n",
      "           2       0.94      0.85      0.89        60\n",
      "\n",
      "    accuracy                           0.92       180\n",
      "   macro avg       0.92      0.92      0.92       180\n",
      "weighted avg       0.92      0.92      0.92       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "Modality_a = X[:, 0:2]\n",
    "Modality_b = X[:, 2:4]\n",
    "\n",
    "X_a_train, X_a_test, y_train, y_test = train_test_split(Modality_a, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_b_train, X_b_test, _,_ = train_test_split(Modality_b, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_train = {\n",
    "                \"Modality_a\": X_a_train,\n",
    "                \"Modality_b\": X_b_train\n",
    "                }\n",
    "\n",
    "iris_data_test = {\n",
    "                \"Modality_a\": X_a_test,\n",
    "                \"Modality_b\": X_b_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=0,\n",
    "                        project_name=\"iris\",\n",
    "                        model_building=True,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EnsembleIntegration' object has no attribute 'train_base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m name, modality \u001b[39min\u001b[39;00m iris_data_train\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     EI_iris\u001b[39m.\u001b[39;49mtrain_base(modality, y_train, modality_name\u001b[39m=\u001b[39mname)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EnsembleIntegration' object has no attribute 'train_base'"
     ]
    }
   ],
   "source": [
    "for name, modality in iris_data_train.items():\n",
    "    EI_iris.train_base(modality, y_train, modality_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.meta_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_meta_model = EI_iris.meta_summary[\"metrics\"].loc[\"precision\"].idxmax()\n",
    "y_pred_iris = EI_iris.predict(X_dict=iris_data_test, meta_model_key=preferred_meta_model)\n",
    "y_pred_iris = [np.argmax(np.array(y)) for y in y_pred_iris]\n",
    "y_pred_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred_iris))])/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train,y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "csvs = \"./data/binary_data\"\n",
    "modalities = {}\n",
    "for file_name in os.listdir(csvs):\n",
    "    if not file_name == \".DS_Store\":\n",
    "        if not file_name.startswith(\"labels\"):\n",
    "            file_path = os.path.join(csvs, file_name)\n",
    "            modality = os.path.splitext(file_name)[0]\n",
    "\n",
    "            data = pd.read_csv(file_path)\n",
    "            modalities[modality] = data\n",
    "\n",
    "y = pd.read_csv('./data/binary_data/labels.csv', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in modalities.keys():\n",
    "    modalities[k].drop(columns=\"Unnamed: 0\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in modalities.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_bin = EnsembleIntegration(\n",
    "                        base_predictors=bin_base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_bin.fit_base(X=data_bin_train,y=y_bin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
