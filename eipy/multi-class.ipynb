{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "import eipy.utils\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is multi-class, run a check on the allowable base and meta models.\n",
    "\n",
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(multi_class=\"multinomial\"),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor filtering base predictors by whether or not they rely on heursitics for multiclass extension\\n\\nnatively_multi_class_predictors = [\"XGBClassifier\",\\n\"BernoulliNB\",\\n\"DecisionTreeClassifier\",\\n\"ExtraTreeClassifier\",\\n\"GaussianNB\",\\n\"KNeighborsClassifier\",\\n\"LabelPropagation\",\\n\"LabelSpreading\",\\n\"LinearDiscriminantAnalysis\",\\n\"LinearSVC\", #(setting multi_class=”crammer_singer”)\\n\"LogisticRegression\", #(setting multi_class=”multinomial”)\\n\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\\n\"MLPClassifier\",\\n\"NearestCentroid\",\\n\"QuadraticDiscriminantAnalysis\",\\n\"RadiusNeighborsClassifier\",\\n\"RandomForestClassifier\",\\n\"RidgeClassifier\",\\n\"RidgeClassifierCV\"]\\n\\nbase_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "For filtering base predictors by whether or not they rely on heursitics for multiclass extension\n",
    "\n",
    "natively_multi_class_predictors = [\"XGBClassifier\",\n",
    "\"BernoulliNB\",\n",
    "\"DecisionTreeClassifier\",\n",
    "\"ExtraTreeClassifier\",\n",
    "\"GaussianNB\",\n",
    "\"KNeighborsClassifier\",\n",
    "\"LabelPropagation\",\n",
    "\"LabelSpreading\",\n",
    "\"LinearDiscriminantAnalysis\",\n",
    "\"LinearSVC\", #(setting multi_class=”crammer_singer”)\n",
    "\"LogisticRegression\", #(setting multi_class=”multinomial”)\n",
    "\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\n",
    "\"MLPClassifier\",\n",
    "\"NearestCentroid\",\n",
    "\"QuadraticDiscriminantAnalysis\",\n",
    "\"RadiusNeighborsClassifier\",\n",
    "\"RandomForestClassifier\",\n",
    "\"RidgeClassifier\",\n",
    "\"RidgeClassifierCV\"]\n",
    "\n",
    "base_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "multi modal multi-class toy data generation\"\"\"\n",
    "\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "modality_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "modality_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "modality_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_train, y_test = train_test_split(modality_0, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_1_train, X_1_test, _,_ = train_test_split(modality_1, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_2_train, X_2_test, _,_ = train_test_split(modality_2, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,  #balanced classes\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, modality in data_train.items():\n",
    "    EI.train_base(modality, y_train, modality_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[modality       Modality_0                                                \\\n",
       " base predictor       ADAB       XGB   DT    RF        GB  KNN        LR   \n",
       " sample                  0         0    0     0         0    0         0   \n",
       " 0                0.993325  0.018859  0.0  0.18  0.247269  0.0  0.494442   \n",
       " 1                0.993325  1.833657  2.0  0.92  1.383278  1.2  0.597189   \n",
       " 2                1.496350  1.490131  2.0  1.29  1.483213  1.2  1.206718   \n",
       " 3                1.496350  1.084872  1.0  1.24  1.170453  0.8  1.312846   \n",
       " 4                0.993325  1.587603  0.0  0.95  0.999460  1.2  1.071679   \n",
       " ..                    ...       ...  ...   ...       ...  ...       ...   \n",
       " 571              0.993198  0.537792  0.0  0.30  1.337322  0.4  0.362275   \n",
       " 572              0.993198  0.514297  2.0  0.54  0.475958  0.4  0.944770   \n",
       " 573              1.496485  1.077167  1.0  1.26  1.072658  1.2  1.170034   \n",
       " 574              0.993198  0.023123  0.0  0.26  0.149911  0.4  0.466367   \n",
       " 575              1.496485  1.082881  1.0  1.17  1.136310  1.2  1.177395   \n",
       " \n",
       " modality                                      ... Modality_2             \\\n",
       " base predictor        NB       MLP       SVM  ...        XGB   DT    RF   \n",
       " sample                 0         0         0  ...          0    0     0   \n",
       " 0               0.424823  0.525970  0.608380  ...   1.930094  2.0  1.62   \n",
       " 1               0.513650  0.666703  0.622958  ...   0.871184  1.0  0.73   \n",
       " 2               1.335233  1.127187  1.307132  ...   0.323872  1.0  0.44   \n",
       " 3               1.483584  1.328700  1.313071  ...   1.987399  2.0  1.88   \n",
       " 4               0.915718  0.876240  0.950348  ...   0.879564  0.0  0.80   \n",
       " ..                   ...       ...       ...  ...        ...  ...   ...   \n",
       " 571             0.473680  0.520424  0.641400  ...   0.412322  0.0  0.46   \n",
       " 572             0.683376  0.768799  0.649294  ...   0.894995  0.0  0.56   \n",
       " 573             1.179997  1.215104  1.287658  ...   1.951421  2.0  1.50   \n",
       " 574             0.692869  0.640357  0.645184  ...   0.902343  1.0  0.81   \n",
       " 575             1.212358  1.209977  1.290979  ...   1.592667  2.0  1.44   \n",
       " \n",
       " modality                                                              labels  \n",
       " base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       " sample                 0    0         0         0         0         0         \n",
       " 0               1.613151  1.2  1.081788  1.398433  1.252423  1.526283      0  \n",
       " 1               0.388614  0.8  0.709162  0.730984  0.671513  0.688343      0  \n",
       " 2               0.579570  0.6  0.741103  0.746814  0.664771  0.667107      1  \n",
       " 3               1.843688  1.6  1.280440  1.536074  1.324731  1.614541      2  \n",
       " 4               1.480210  1.6  1.267756  1.520496  1.304050  1.527308      0  \n",
       " ..                   ...  ...       ...       ...       ...       ...    ...  \n",
       " 571             0.482107  0.4  0.672557  0.684810  0.657757  0.715359      0  \n",
       " 572             0.761712  0.6  0.753287  0.721118  0.662427  0.680050      0  \n",
       " 573             1.749522  1.6  1.419898  1.555564  1.411033  1.442599      2  \n",
       " 574             0.784081  0.8  0.672081  0.653230  0.653655  0.711563      0  \n",
       " 575             1.362584  1.6  1.242230  1.514053  1.315028  1.448790      2  \n",
       " \n",
       " [576 rows x 31 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor       ADAB       XGB   DT    RF        GB  KNN        LR   \n",
       " sample                  0         0    0     0         0    0         0   \n",
       " 0                1.496788  1.957486  2.0  1.76  1.530543  1.4  1.268401   \n",
       " 1                1.496788  1.946187  2.0  1.70  1.977855  1.4  1.131859   \n",
       " 2                0.992422  1.835330  2.0  1.52  0.802058  0.8  0.444976   \n",
       " 3                0.992422  0.923638  2.0  0.62  0.600273  0.4  1.188277   \n",
       " 4                0.992422  0.478555  0.0  0.86  1.355420  0.8  0.413632   \n",
       " ..                    ...       ...  ...   ...       ...  ...       ...   \n",
       " 571              0.993516  0.218930  0.0  0.32  0.635752  0.8  0.430351   \n",
       " 572              1.496336  1.088815  1.0  1.06  1.157192  1.2  1.264460   \n",
       " 573              1.496336  1.001308  1.0  1.07  1.051044  1.0  1.189321   \n",
       " 574              1.496336  1.052912  1.0  1.29  1.059554  1.4  1.152656   \n",
       " 575              1.496336  1.176521  1.0  1.26  1.145199  1.2  1.172995   \n",
       " \n",
       " modality                                      ... Modality_2             \\\n",
       " base predictor        NB       MLP       SVM  ...        XGB   DT    RF   \n",
       " sample                 0         0         0  ...          0    0     0   \n",
       " 0               1.378664  1.243228  1.464192  ...   0.810999  0.0  0.71   \n",
       " 1               1.301934  1.187197  1.311074  ...   0.172526  0.0  0.48   \n",
       " 2               0.469482  0.575715  0.617688  ...   0.225990  0.0  0.66   \n",
       " 3               1.180450  1.111806  1.029636  ...   0.768004  0.0  0.83   \n",
       " 4               0.503822  0.552587  0.617752  ...   1.997796  2.0  1.96   \n",
       " ..                   ...       ...       ...  ...        ...  ...   ...   \n",
       " 571             0.576904  0.704995  0.667593  ...   0.607952  1.0  0.52   \n",
       " 572             1.227173  1.284581  1.260977  ...   0.980117  1.0  0.87   \n",
       " 573             1.196751  1.240503  1.268434  ...   1.791135  2.0  1.36   \n",
       " 574             1.216401  1.236278  1.278056  ...   0.984542  1.0  0.87   \n",
       " 575             1.204489  1.245163  1.275260  ...   1.920944  2.0  1.86   \n",
       " \n",
       " modality                                                              labels  \n",
       " base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       " sample                 0    0         0         0         0         0         \n",
       " 0               0.523662  0.6  0.783308  0.634668  0.759614  0.593112      1  \n",
       " 1               0.344856  0.6  0.686092  0.554011  0.621058  0.557556      1  \n",
       " 2               0.696494  0.8  1.544960  1.441614  1.388057  1.356338      0  \n",
       " 3               0.994209  1.2  0.902478  0.940610  1.003925  0.992892      2  \n",
       " 4               1.886230  2.0  1.428935  1.630802  1.384085  1.503196      0  \n",
       " ..                   ...  ...       ...       ...       ...       ...    ...  \n",
       " 571             0.768728  0.8  0.701335  0.693875  0.673271  0.746895      0  \n",
       " 572             0.771666  1.0  0.692107  0.649534  0.666476  0.714032      1  \n",
       " 573             1.041376  1.6  1.385097  1.492619  1.473705  1.460472      2  \n",
       " 574             0.764186  0.6  0.702077  0.617124  0.674929  0.690788      1  \n",
       " 575             1.544827  1.6  1.230655  1.446520  1.383905  1.454408      2  \n",
       " \n",
       " [576 rows x 31 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor       ADAB       XGB   DT    RF        GB  KNN        LR   \n",
       " sample                  0         0    0     0         0    0         0   \n",
       " 0                0.993451  0.102183  0.0  0.48  0.547855  0.4  0.559395   \n",
       " 1                0.993451  1.622870  0.0  0.96  0.527809  1.2  0.621033   \n",
       " 2                0.993451  0.529692  0.0  0.61  0.442213  0.6  1.200316   \n",
       " 3                0.993451  1.665627  2.0  1.22  0.827794  0.8  1.070317   \n",
       " 4                0.993451  0.635761  0.0  0.68  0.358103  0.8  0.932866   \n",
       " ..                    ...       ...  ...   ...       ...  ...       ...   \n",
       " 571              0.993698  0.011039  0.0  0.27  0.145021  0.2  1.141726   \n",
       " 572              0.993698  0.076823  2.0  0.34  0.645667  0.0  0.569409   \n",
       " 573              0.993698  1.360106  0.0  0.60  1.320486  0.4  0.650760   \n",
       " 574              0.993698  0.223243  0.0  0.52  0.380548  0.4  0.437559   \n",
       " 575              0.993698  0.439872  0.0  0.54  0.475854  0.0  0.347681   \n",
       " \n",
       " modality                                      ... Modality_2             \\\n",
       " base predictor        NB       MLP       SVM  ...        XGB   DT    RF   \n",
       " sample                 0         0         0  ...          0    0     0   \n",
       " 0               0.487344  0.651712  0.633804  ...   1.775968  2.0  1.58   \n",
       " 1               0.544310  0.634810  0.640358  ...   0.886919  1.0  0.98   \n",
       " 2               1.213600  1.169231  1.139522  ...   1.751442  2.0  1.36   \n",
       " 3               0.897315  0.845116  0.913279  ...   1.967308  0.0  1.37   \n",
       " 4               0.647390  0.732645  0.674493  ...   1.878890  2.0  1.52   \n",
       " ..                   ...       ...       ...  ...        ...  ...   ...   \n",
       " 571             1.196115  1.016136  1.008290  ...   1.656750  0.0  1.28   \n",
       " 572             0.422206  0.593260  0.610808  ...   0.842055  0.0  0.86   \n",
       " 573             0.546328  0.688605  0.608955  ...   1.900842  2.0  1.50   \n",
       " 574             0.657997  0.622064  0.641737  ...   0.914726  1.0  0.88   \n",
       " 575             0.476121  0.547741  0.620463  ...   1.707860  0.0  1.84   \n",
       " \n",
       " modality                                                              labels  \n",
       " base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       " sample                 0    0         0         0         0         0         \n",
       " 0               1.766066  0.8  1.065078  1.378821  1.248205  1.438981      0  \n",
       " 1               0.779794  0.8  0.693757  0.687125  0.636566  0.704935      0  \n",
       " 2               1.641739  1.6  0.867708  0.939446  1.092312  0.985138      2  \n",
       " 3               1.732445  1.6  1.237713  1.492754  1.318228  1.439172      0  \n",
       " 4               1.758077  1.2  1.080148  1.387540  1.276435  1.470759      2  \n",
       " ..                   ...  ...       ...       ...       ...       ...    ...  \n",
       " 571             0.598114  1.2  1.559739  1.428449  1.440534  1.345053      0  \n",
       " 572             0.665495  1.6  1.559444  1.464259  1.446241  1.395630      0  \n",
       " 573             1.554705  1.6  1.161466  1.437456  1.345968  1.516424      2  \n",
       " 574             0.833218  0.8  0.716243  0.693214  0.684813  0.719465      0  \n",
       " 575             1.540616  1.2  1.398256  1.490471  1.367007  1.232764      2  \n",
       " \n",
       " [576 rows x 31 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor       ADAB       XGB   DT    RF        GB  KNN        LR   \n",
       " sample                  0         0    0     0         0    0         0   \n",
       " 0                0.992938  0.247609  2.0  0.52  0.721487  0.8  0.525018   \n",
       " 1                0.992938  0.204953  0.0  0.36  0.528158  0.8  1.060039   \n",
       " 2                0.992938  0.504210  0.0  0.20  0.305175  0.0  1.008741   \n",
       " 3                1.496515  1.961548  2.0  1.81  1.680916  1.8  1.271470   \n",
       " 4                0.992938  0.032094  0.0  0.52  0.342331  0.4  1.245074   \n",
       " ..                    ...       ...  ...   ...       ...  ...       ...   \n",
       " 571              0.993819  0.325168  0.0  0.34  0.509590  0.8  1.121548   \n",
       " 572              0.993819  0.522885  2.0  0.78  0.476760  0.0  0.593055   \n",
       " 573              1.496099  1.014711  1.0  1.09  1.064675  1.0  1.163347   \n",
       " 574              0.993819  0.096171  0.0  0.46  0.925087  0.0  0.452157   \n",
       " 575              0.993819  0.102125  0.0  0.18  0.384226  0.0  0.380039   \n",
       " \n",
       " modality                                      ... Modality_2             \\\n",
       " base predictor        NB       MLP       SVM  ...        XGB   DT    RF   \n",
       " sample                 0         0         0  ...          0    0     0   \n",
       " 0               0.447731  0.595602  0.649570  ...   1.969861  2.0  1.82   \n",
       " 1               0.842485  0.945125  0.723952  ...   1.808394  2.0  1.08   \n",
       " 2               0.837709  0.776286  0.677061  ...   1.787861  0.0  1.07   \n",
       " 3               1.276847  1.360002  1.308553  ...   0.207813  0.0  0.49   \n",
       " 4               1.284308  1.223488  1.125731  ...   1.196554  0.0  0.64   \n",
       " ..                   ...       ...       ...  ...        ...  ...   ...   \n",
       " 571             1.109189  1.001583  1.030462  ...   0.253831  0.0  0.76   \n",
       " 572             0.463801  0.611559  0.665980  ...   0.261434  0.0  0.54   \n",
       " 573             1.171436  1.201856  1.283585  ...   1.958240  2.0  1.64   \n",
       " 574             0.639040  0.576060  0.661896  ...   0.853248  1.0  0.86   \n",
       " 575             0.529667  0.506843  0.659444  ...   1.892049  2.0  1.74   \n",
       " \n",
       " modality                                                              labels  \n",
       " base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       " sample                 0    0         0         0         0         0         \n",
       " 0               1.770394  1.6  1.117867  1.420353  1.270537  1.472287      0  \n",
       " 1               1.137517  1.6  1.649857  1.465903  1.458786  1.370400      0  \n",
       " 2               1.384674  1.2  1.426532  1.575824  1.385041  1.401923      2  \n",
       " 3               0.448577  0.4  0.762270  0.747514  0.670240  0.667669      1  \n",
       " 4               1.432542  0.8  0.858076  0.887223  0.961293  0.693953      2  \n",
       " ..                   ...  ...       ...       ...       ...       ...    ...  \n",
       " 571             0.296283  0.8  1.635918  1.509756  1.520222  1.456023      0  \n",
       " 572             0.394956  0.8  1.609516  1.492318  1.502987  1.449428      0  \n",
       " 573             1.166950  1.2  1.352233  1.502765  1.354022  1.436567      2  \n",
       " 574             0.807307  0.6  0.665461  0.625736  0.641776  0.706074      0  \n",
       " 575             0.311096  1.2  1.364355  1.488326  1.342770  1.334836      2  \n",
       " \n",
       " [576 rows x 31 columns],\n",
       " modality       Modality_0                                                \\\n",
       " base predictor       ADAB       XGB   DT    RF        GB  KNN        LR   \n",
       " sample                  0         0    0     0         0    0         0   \n",
       " 0                0.993698  0.344904  0.0  0.42  0.335213  0.4  0.564291   \n",
       " 1                0.993698  1.146533  0.0  0.84  0.822340  0.8  0.649276   \n",
       " 2                0.993698  0.743425  2.0  0.46  0.295023  0.0  1.058675   \n",
       " 3                1.496140  1.664780  2.0  1.46  1.374397  1.2  1.251338   \n",
       " 4                0.993698  1.046302  0.0  0.92  0.683734  0.4  1.230740   \n",
       " ..                    ...       ...  ...   ...       ...  ...       ...   \n",
       " 571              0.993325  0.593386  2.0  0.92  0.592254  0.6  1.174784   \n",
       " 572              0.993325  0.075218  0.0  0.79  0.476205  0.4  0.912783   \n",
       " 573              1.496380  1.340392  1.0  1.23  1.324205  1.0  1.306369   \n",
       " 574              2.000000  1.983704  0.0  1.20  1.930646  1.2  1.196179   \n",
       " 575              1.496380  1.365362  1.0  1.37  1.226330  1.4  1.205783   \n",
       " \n",
       " modality                                      ... Modality_2             \\\n",
       " base predictor        NB       MLP       SVM  ...        XGB   DT    RF   \n",
       " sample                 0         0         0  ...          0    0     0   \n",
       " 0               0.481069  0.658259  0.658004  ...   1.994430  2.0  1.92   \n",
       " 1               0.529479  0.743147  0.654880  ...   0.153239  0.0  0.55   \n",
       " 2               0.887754  0.896893  0.783876  ...   1.918723  0.0  1.34   \n",
       " 3               1.244454  1.316959  1.282157  ...   0.807288  1.0  0.75   \n",
       " 4               1.273151  1.206222  1.118155  ...   1.368000  2.0  0.96   \n",
       " ..                   ...       ...       ...  ...        ...  ...   ...   \n",
       " 571             1.258555  1.125486  1.266872  ...   1.081166  0.0  1.10   \n",
       " 572             0.617596  0.804351  0.633299  ...   0.668402  0.0  0.54   \n",
       " 573             1.478014  1.293208  1.382009  ...   1.873306  0.0  1.34   \n",
       " 574             1.312197  1.162784  1.330157  ...   1.908013  2.0  1.66   \n",
       " 575             1.210328  1.247234  1.296485  ...   1.910000  2.0  1.86   \n",
       " \n",
       " modality                                                              labels  \n",
       " base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       " sample                 0    0         0         0         0         0         \n",
       " 0               1.898066  1.2  1.074723  1.394528  1.298870  1.493921      0  \n",
       " 1               0.391146  0.6  0.679630  0.678765  0.631133  0.712407      0  \n",
       " 2               1.212195  1.2  1.360553  1.535894  1.387201  1.366575      2  \n",
       " 3               0.498546  0.6  0.762578  0.722456  0.660690  0.638686      1  \n",
       " 4               1.325189  0.8  0.874276  0.917414  1.033622  0.909702      2  \n",
       " ..                   ...  ...       ...       ...       ...       ...    ...  \n",
       " 571             0.906279  1.2  1.522410  1.351854  1.357401  1.114931      0  \n",
       " 572             0.631064  0.6  0.782427  0.735048  0.675887  0.678194      0  \n",
       " 573             1.267773  1.2  0.977257  1.175789  1.213819  1.363644      2  \n",
       " 574             1.534196  2.0  1.361174  1.528934  1.364393  1.503467      0  \n",
       " 575             1.606054  2.0  1.167686  1.476570  1.241736  1.441800      2  \n",
       " \n",
       " [576 rows x 31 columns]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<eipy.ei.EnsembleIntegration at 0x7f61c458c070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.926064</td>\n",
       "      <td>0.997245</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.994473</td>\n",
       "      <td>0.995885</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.989153</td>\n",
       "      <td>0.995839</td>\n",
       "      <td>0.989147</td>\n",
       "      <td>0.994496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.919244</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.995830</td>\n",
       "      <td>0.994450</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.987555</td>\n",
       "      <td>0.988911</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.988914</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ADAB       XGB        DT        RF        GB       KNN  \\\n",
       "precision  0.926064  0.997245  0.995833  0.994473  0.995885  0.987952   \n",
       "recall     0.919444  0.997222  0.995833  0.994444  0.995833  0.987500   \n",
       "f1         0.919244  0.997222  0.995830  0.994450  0.995833  0.987555   \n",
       "\n",
       "                 LR        NB       MLP       SVM  \n",
       "precision  0.989153  0.995839  0.989147  0.994496  \n",
       "recall     0.988889  0.995833  0.988889  0.994444  \n",
       "f1         0.988911  0.995833  0.988914  0.994444  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 0., 0., 2., 1., 2., 0., 2., 1., 1., 2., 1., 0., 1., 1.,\n",
       "       2., 1., 1., 0., 0., 2., 0., 1., 1., 1., 1., 2., 0., 2., 2., 0., 2.,\n",
       "       0., 0., 2., 1., 0., 1., 0., 0., 2., 1., 1., 2., 1., 0., 2., 2., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 2., 2., 1., 0., 0., 2., 0., 2., 0., 1.,\n",
       "       0., 1., 1., 2., 2., 0., 1., 2., 1., 1., 2., 0., 0., 0., 2., 1., 0.,\n",
       "       0., 1., 1., 2., 0., 0., 2., 0., 0., 0., 1., 1., 2., 2., 1., 1., 2.,\n",
       "       1., 1., 2., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       2., 2., 1., 1., 0., 0., 0., 2., 0., 1., 1., 2., 2., 2., 2., 2., 0.,\n",
       "       2., 0., 1., 1., 2., 0., 1., 0., 2., 2., 2., 2., 1., 0., 0., 2., 1.,\n",
       "       1., 2., 1., 1., 2., 0., 2., 0., 1., 0., 0., 2., 2., 0., 2., 2., 2.,\n",
       "       0., 0., 0., 2., 1., 2., 1., 2., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = EI.predict(X_dict=data_test, meta_model_key=\"XGB\")\n",
    "y_pred = np.round(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 0, 2, 1, 2, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 0,\n",
       "       2, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1,\n",
       "       1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 0, 2,\n",
       "       0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1,\n",
       "       2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 0, 1, 1, 2, 2,\n",
       "       2, 2, 2, 0, 2, 0, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 1, 0, 0, 2, 1, 1,\n",
       "       2, 1, 1, 2, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 1, 2,\n",
       "       1, 2, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944444444444445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred))])/len(y_test)\n",
    "accuracy # =179/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.997222\n",
       "recall       0.997222\n",
       "f1           0.997222\n",
       "Name: XGB, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_summary['thresholds'][\"XGB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00981237, 0.0276197 , 0.96256793],\n",
       "        [0.00948382, 0.98086462, 0.00965155],\n",
       "        [0.96882308, 0.0189461 , 0.01223082],\n",
       "        [0.01033915, 0.00398004, 0.98568081],\n",
       "        [0.96210977, 0.02622078, 0.01166945]]),\n",
       " array([0.0276197 , 0.98086462, 0.0189461 , 0.00398004, 0.02622078]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}\n",
    "model = base_predictors[\"SVM\"]\n",
    "model.fit(X_train,y_train)\n",
    "y_pred  = model.predict_proba(X_test)\n",
    "y_pred[:5],y_pred[:, 1][:5]\n",
    "\n",
    "#print(y_pred[:5])\n",
    "#y_pred = [max(range(len(prob)), key=lambda i: prob[i]) for prob in y_pred] #change all probability vectors to predictions for scoring\n",
    "#print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m precision_score(y_test, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
