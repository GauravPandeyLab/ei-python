{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "import eipy.utils as ut\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is multi-class, run a check on the allowable base and meta models.\n",
    "\n",
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(multi_class=\"multinomial\"),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor filtering base predictors by whether or not they rely on heursitics for multiclass extension\\n\\nnatively_multi_class_predictors = [\"XGBClassifier\",\\n\"BernoulliNB\",\\n\"DecisionTreeClassifier\",\\n\"ExtraTreeClassifier\",\\n\"GaussianNB\",\\n\"KNeighborsClassifier\",\\n\"LabelPropagation\",\\n\"LabelSpreading\",\\n\"LinearDiscriminantAnalysis\",\\n\"LinearSVC\", #(setting multi_class=”crammer_singer”)\\n\"LogisticRegression\", #(setting multi_class=”multinomial”)\\n\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\\n\"MLPClassifier\",\\n\"NearestCentroid\",\\n\"QuadraticDiscriminantAnalysis\",\\n\"RadiusNeighborsClassifier\",\\n\"RandomForestClassifier\",\\n\"RidgeClassifier\",\\n\"RidgeClassifierCV\"]\\n\\nbase_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "For filtering base predictors by whether or not they rely on heursitics for multiclass extension\n",
    "\n",
    "natively_multi_class_predictors = [\"XGBClassifier\",\n",
    "\"BernoulliNB\",\n",
    "\"DecisionTreeClassifier\",\n",
    "\"ExtraTreeClassifier\",\n",
    "\"GaussianNB\",\n",
    "\"KNeighborsClassifier\",\n",
    "\"LabelPropagation\",\n",
    "\"LabelSpreading\",\n",
    "\"LinearDiscriminantAnalysis\",\n",
    "\"LinearSVC\", #(setting multi_class=”crammer_singer”)\n",
    "\"LogisticRegression\", #(setting multi_class=”multinomial”)\n",
    "\"LogisticRegressionCV\", #(setting multi_class=”multinomial”)\n",
    "\"MLPClassifier\",\n",
    "\"NearestCentroid\",\n",
    "\"QuadraticDiscriminantAnalysis\",\n",
    "\"RadiusNeighborsClassifier\",\n",
    "\"RandomForestClassifier\",\n",
    "\"RidgeClassifier\",\n",
    "\"RidgeClassifierCV\"]\n",
    "\n",
    "base_predictors = {k : v for k,v in base_predictors.items() if str(v).split(\"(\")[0] in natively_multi_class_predictors}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "multi modal multi-class toy data generation\"\"\"\n",
    "\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "modality_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "modality_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "modality_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_train, y_test = train_test_split(modality_0, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_1_train, X_1_test, _,_ = train_test_split(modality_1, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_2_train, X_2_test, _,_ = train_test_split(modality_2, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=42,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EI.train_base(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_0</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_1</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.873335</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.120604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.741568</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.236010</td>\n",
       "      <td>0.787548</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.212370</td>\n",
       "      <td>0.734722</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.260691</td>\n",
       "      <td>0.694402</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.302783</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.461601</td>\n",
       "      <td>0.537134</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.446751</td>\n",
       "      <td>0.542124</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812660</td>\n",
       "      <td>0.179730</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.705237</td>\n",
       "      <td>0.294760</td>\n",
       "      <td>3.893088e-06</td>\n",
       "      <td>0.757580</td>\n",
       "      <td>0.238677</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.704742</td>\n",
       "      <td>0.286515</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.190731</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.803881</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>0.113573</td>\n",
       "      <td>0.484108</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.692139</td>\n",
       "      <td>0.344770</td>\n",
       "      <td>0.058037</td>\n",
       "      <td>0.597193</td>\n",
       "      <td>0.235021</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.082868</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.305751</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.688637</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.285826</td>\n",
       "      <td>0.743124</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.661490</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>0.328193</td>\n",
       "      <td>0.685259</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.308217</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>0.877135</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.205477</td>\n",
       "      <td>0.780552</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643465</td>\n",
       "      <td>0.320709</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.728743</td>\n",
       "      <td>0.270921</td>\n",
       "      <td>3.361942e-04</td>\n",
       "      <td>0.651904</td>\n",
       "      <td>0.333255</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.636935</td>\n",
       "      <td>0.355380</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.496820</td>\n",
       "      <td>5.031799e-01</td>\n",
       "      <td>2.222557e-16</td>\n",
       "      <td>0.130016</td>\n",
       "      <td>0.868783</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.616100</td>\n",
       "      <td>0.379187</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381799</td>\n",
       "      <td>0.527239</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.725416</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.356892</td>\n",
       "      <td>0.614702</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>0.314243</td>\n",
       "      <td>0.683171</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.223397e-16</td>\n",
       "      <td>5.036501e-01</td>\n",
       "      <td>0.496350</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.492612</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.491289</td>\n",
       "      <td>0.495962</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.260780</td>\n",
       "      <td>0.271721</td>\n",
       "      <td>0.467498</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>0.270495</td>\n",
       "      <td>0.532369</td>\n",
       "      <td>0.315407</td>\n",
       "      <td>0.241999</td>\n",
       "      <td>0.442594</td>\n",
       "      <td>0.252198</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.559330</td>\n",
       "      <td>2.222529e-16</td>\n",
       "      <td>0.496881</td>\n",
       "      <td>5.031186e-01</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.994307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.080650</td>\n",
       "      <td>0.914909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.182152</td>\n",
       "      <td>0.801596</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.219851</td>\n",
       "      <td>7.801217e-01</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.205562</td>\n",
       "      <td>0.792153</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.318134</td>\n",
       "      <td>0.676815</td>\n",
       "      <td>0.496820</td>\n",
       "      <td>5.031799e-01</td>\n",
       "      <td>2.222557e-16</td>\n",
       "      <td>0.678152</td>\n",
       "      <td>0.319825</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.427438</td>\n",
       "      <td>0.565553</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303977</td>\n",
       "      <td>0.650942</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.746303</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.651430</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.335281</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.223397e-16</td>\n",
       "      <td>5.036501e-01</td>\n",
       "      <td>0.496350</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.813579</td>\n",
       "      <td>0.178437</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.217677</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.530523</td>\n",
       "      <td>0.158370</td>\n",
       "      <td>0.199676</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.171173</td>\n",
       "      <td>0.328954</td>\n",
       "      <td>0.499873</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.396572</td>\n",
       "      <td>0.458250</td>\n",
       "      <td>2.222529e-16</td>\n",
       "      <td>0.496881</td>\n",
       "      <td>5.031186e-01</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.107689</td>\n",
       "      <td>0.889078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.188231</td>\n",
       "      <td>0.794377</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.219310</td>\n",
       "      <td>7.806570e-01</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.215564</td>\n",
       "      <td>0.781898</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.319830</td>\n",
       "      <td>0.676011</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.993652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.076960</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.920648</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.328162</td>\n",
       "      <td>0.063236</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.766259</td>\n",
       "      <td>0.322704</td>\n",
       "      <td>0.029860</td>\n",
       "      <td>0.647435</td>\n",
       "      <td>0.191561</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.806101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.033375e-01</td>\n",
       "      <td>2.222770e-16</td>\n",
       "      <td>0.496663</td>\n",
       "      <td>0.205049</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.792652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.495245</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>0.494704</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.389640</td>\n",
       "      <td>0.149040</td>\n",
       "      <td>0.461319</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>0.040081</td>\n",
       "      <td>0.437819</td>\n",
       "      <td>0.513466</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>0.389706</td>\n",
       "      <td>0.514961</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.729893</td>\n",
       "      <td>0.269725</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.337153</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689093</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>0.025567</td>\n",
       "      <td>0.737586</td>\n",
       "      <td>0.262294</td>\n",
       "      <td>1.199098e-04</td>\n",
       "      <td>0.676987</td>\n",
       "      <td>0.312717</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>0.632066</td>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.496191</td>\n",
       "      <td>2.223908e-16</td>\n",
       "      <td>5.038085e-01</td>\n",
       "      <td>0.559073</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.438637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.256467</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.736677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.334040</td>\n",
       "      <td>0.064163</td>\n",
       "      <td>0.601797</td>\n",
       "      <td>0.238629</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.334455</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>0.638505</td>\n",
       "      <td>0.235444</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.762752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.730658</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.268450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.326098</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.663420</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.813545</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>0.763151</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.236831</td>\n",
       "      <td>0.737883</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.258307</td>\n",
       "      <td>0.674201</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.771925</td>\n",
       "      <td>0.227552</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.832982</td>\n",
       "      <td>0.158148</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583089</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.751509</td>\n",
       "      <td>0.247555</td>\n",
       "      <td>9.359377e-04</td>\n",
       "      <td>0.629503</td>\n",
       "      <td>0.345457</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.759947</td>\n",
       "      <td>0.236493</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.588948</td>\n",
       "      <td>0.409782</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.523892</td>\n",
       "      <td>0.470108</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410048</td>\n",
       "      <td>0.507348</td>\n",
       "      <td>0.082605</td>\n",
       "      <td>0.319283</td>\n",
       "      <td>0.676623</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.366665</td>\n",
       "      <td>0.608913</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.286633</td>\n",
       "      <td>0.711375</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.741070</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.255368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.234676</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.491131</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.655889</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.339265</td>\n",
       "      <td>0.592587</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>0.361386</td>\n",
       "      <td>0.672380</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.321674</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.709526</td>\n",
       "      <td>0.287658</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.758846</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744517</td>\n",
       "      <td>0.242041</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.266279</td>\n",
       "      <td>1.542590e-05</td>\n",
       "      <td>0.670398</td>\n",
       "      <td>0.321818</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.710672</td>\n",
       "      <td>0.284397</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.105804</td>\n",
       "      <td>0.893397</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.243999</td>\n",
       "      <td>0.750289</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>0.711016</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.278899</td>\n",
       "      <td>0.721085</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.341974</td>\n",
       "      <td>0.653626</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.324069</td>\n",
       "      <td>0.671813</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2.223192e-16</td>\n",
       "      <td>5.035152e-01</td>\n",
       "      <td>0.496485</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.920323</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.919627</td>\n",
       "      <td>0.076515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.779247</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.819810</td>\n",
       "      <td>0.180093</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.766037</td>\n",
       "      <td>0.224534</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.701820</td>\n",
       "      <td>0.292919</td>\n",
       "      <td>2.222572e-16</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>5.031511e-01</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.012208</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.452824</td>\n",
       "      <td>0.543666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.207135</td>\n",
       "      <td>0.767142</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>7.942068e-01</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.234306</td>\n",
       "      <td>0.762720</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.305228</td>\n",
       "      <td>0.693098</td>\n",
       "      <td>0.496066</td>\n",
       "      <td>2.223978e-16</td>\n",
       "      <td>5.039340e-01</td>\n",
       "      <td>0.023767</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.975189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.119909</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.869431</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.270401</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.222018</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.777582</td>\n",
       "      <td>0.285722</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.696755</td>\n",
       "      <td>0.276874</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.719473</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>5.034012e-01</td>\n",
       "      <td>2.222858e-16</td>\n",
       "      <td>0.496599</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.011173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.924327</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.761829</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.228195</td>\n",
       "      <td>0.653560</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.676873</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.317230</td>\n",
       "      <td>0.672044</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.317228</td>\n",
       "      <td>5.038713e-01</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>2.223630e-16</td>\n",
       "      <td>0.599464</td>\n",
       "      <td>0.391220</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.798176</td>\n",
       "      <td>0.192122</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.822668</td>\n",
       "      <td>0.171797</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.525422</td>\n",
       "      <td>0.474577</td>\n",
       "      <td>4.761566e-07</td>\n",
       "      <td>0.672010</td>\n",
       "      <td>0.325162</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.457654</td>\n",
       "      <td>0.519184</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>5.030579e-01</td>\n",
       "      <td>2.222392e-16</td>\n",
       "      <td>0.097810</td>\n",
       "      <td>0.902037</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.220555</td>\n",
       "      <td>0.774808</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428953</td>\n",
       "      <td>0.470013</td>\n",
       "      <td>0.101034</td>\n",
       "      <td>0.356938</td>\n",
       "      <td>0.632894</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.380057</td>\n",
       "      <td>0.586231</td>\n",
       "      <td>0.033712</td>\n",
       "      <td>0.292738</td>\n",
       "      <td>0.702961</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2.223192e-16</td>\n",
       "      <td>5.035152e-01</td>\n",
       "      <td>0.496485</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.915664</td>\n",
       "      <td>0.083608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.141524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.783810</td>\n",
       "      <td>0.196792</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.787540</td>\n",
       "      <td>0.212409</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.780049</td>\n",
       "      <td>0.214964</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.703439</td>\n",
       "      <td>0.293770</td>\n",
       "      <td>2.222572e-16</td>\n",
       "      <td>0.496849</td>\n",
       "      <td>5.031511e-01</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.878685</td>\n",
       "      <td>0.120832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.328224</td>\n",
       "      <td>0.666778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.275193</td>\n",
       "      <td>0.483138</td>\n",
       "      <td>0.241670</td>\n",
       "      <td>0.222495</td>\n",
       "      <td>0.541858</td>\n",
       "      <td>2.356475e-01</td>\n",
       "      <td>0.307403</td>\n",
       "      <td>0.446939</td>\n",
       "      <td>0.245659</td>\n",
       "      <td>0.120573</td>\n",
       "      <td>0.528285</td>\n",
       "      <td>0.351142</td>\n",
       "      <td>0.496066</td>\n",
       "      <td>2.223978e-16</td>\n",
       "      <td>5.039340e-01</td>\n",
       "      <td>0.203063</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.795730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.313755</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.676339</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.343435</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.585666</td>\n",
       "      <td>0.241844</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.755897</td>\n",
       "      <td>0.324260</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.273303</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.722092</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality          Modality_0                                              \\\n",
       "base predictor          ADAB                               XGB             \n",
       "sample                     0                                 0             \n",
       "class                      0             1         2         0         1   \n",
       "0               5.033375e-01  2.222770e-16  0.496663  0.990476  0.000190   \n",
       "1               5.033375e-01  2.222770e-16  0.496663  0.082868  0.000607   \n",
       "2               2.223397e-16  5.036501e-01  0.496350  0.008628  0.492612   \n",
       "3               2.223397e-16  5.036501e-01  0.496350  0.000314  0.914500   \n",
       "4               5.033375e-01  2.222770e-16  0.496663  0.205049  0.002299   \n",
       "..                       ...           ...       ...       ...       ...   \n",
       "571             5.034012e-01  2.222858e-16  0.496599  0.730658  0.000891   \n",
       "572             5.034012e-01  2.222858e-16  0.496599  0.741070  0.003562   \n",
       "573             2.223192e-16  5.035152e-01  0.496485  0.001255  0.920323   \n",
       "574             5.034012e-01  2.222858e-16  0.496599  0.988050  0.000777   \n",
       "575             2.223192e-16  5.035152e-01  0.496485  0.000728  0.915664   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.009334  1.0  0.0  0.0  0.91  0.00  0.09  0.873335  0.006062   \n",
       "1               0.916525  0.0  0.0  1.0  0.54  0.00  0.46  0.305751  0.005220   \n",
       "2               0.498759  0.0  0.0  1.0  0.04  0.63  0.33  0.012749  0.491289   \n",
       "3               0.085186  0.0  1.0  0.0  0.01  0.74  0.25  0.007984  0.813579   \n",
       "4               0.792652  1.0  0.0  0.0  0.52  0.01  0.47  0.495245  0.010051   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "571             0.268450  1.0  0.0  0.0  0.85  0.00  0.15  0.326098  0.010482   \n",
       "572             0.255368  0.0  0.0  1.0  0.73  0.00  0.27  0.758719  0.006605   \n",
       "573             0.078422  0.0  1.0  0.0  0.00  0.74  0.26  0.003857  0.919627   \n",
       "574             0.011173  1.0  0.0  0.0  0.87  0.00  0.13  0.924327  0.001435   \n",
       "575             0.083608  0.0  1.0  0.0  0.00  0.83  0.17  0.005214  0.853261   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.120604  1.0  0.0  0.0  0.741568  0.022422  0.236010   \n",
       "1               0.689029  0.4  0.0  0.6  0.688637  0.025537  0.285826   \n",
       "2               0.495962  0.2  0.4  0.4  0.260780  0.271721  0.467498   \n",
       "3               0.178437  0.4  0.4  0.2  0.217677  0.251799  0.530523   \n",
       "4               0.494704  0.4  0.0  0.6  0.389640  0.149040  0.461319   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "571             0.663420  0.8  0.0  0.2  0.813545  0.010634  0.175820   \n",
       "572             0.234676  0.8  0.0  0.2  0.491131  0.072969  0.435900   \n",
       "573             0.076515  0.0  0.8  0.2  0.025359  0.779247  0.195393   \n",
       "574             0.074238  0.8  0.0  0.2  0.761829  0.009976  0.228195   \n",
       "575             0.141524  0.0  0.8  0.2  0.019398  0.783810  0.196792   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.787548  0.000082  0.212370  0.734722  0.004587  0.260691   \n",
       "1               0.743124  0.000103  0.256774  0.661490  0.010317  0.328193   \n",
       "2               0.197136  0.270495  0.532369  0.315407  0.241999  0.442594   \n",
       "3               0.158370  0.199676  0.641954  0.171173  0.328954  0.499873   \n",
       "4               0.522100  0.040081  0.437819  0.513466  0.096828  0.389706   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.763151  0.000017  0.236831  0.737883  0.003810  0.258307   \n",
       "572             0.655889  0.004847  0.339265  0.592587  0.046026  0.361386   \n",
       "573             0.000097  0.819810  0.180093  0.009429  0.766037  0.224534   \n",
       "574             0.653560  0.000010  0.346429  0.676873  0.005897  0.317230   \n",
       "575             0.000051  0.787540  0.212409  0.004987  0.780049  0.214964   \n",
       "\n",
       "modality                                        Modality_1            \\\n",
       "base predictor       SVM                              ADAB             \n",
       "sample                 0                                 0             \n",
       "class                  0         1         2             0         1   \n",
       "0               0.694402  0.002815  0.302783  5.038713e-01  0.496129   \n",
       "1               0.685259  0.006523  0.308217  5.038713e-01  0.496129   \n",
       "2               0.252198  0.188472  0.559330  2.222529e-16  0.496881   \n",
       "3               0.145179  0.396572  0.458250  2.222529e-16  0.496881   \n",
       "4               0.514961  0.019730  0.465309  5.038713e-01  0.496129   \n",
       "..                   ...       ...       ...           ...       ...   \n",
       "571             0.674201  0.010199  0.315600  5.038713e-01  0.496129   \n",
       "572             0.672380  0.005945  0.321674  5.038713e-01  0.496129   \n",
       "573             0.005261  0.701820  0.292919  2.222572e-16  0.496849   \n",
       "574             0.672044  0.010727  0.317228  5.038713e-01  0.496129   \n",
       "575             0.002791  0.703439  0.293770  2.222572e-16  0.496849   \n",
       "\n",
       "modality                                                                   \\\n",
       "base predictor                     XGB                       DT             \n",
       "sample                               0                        0             \n",
       "class                      2         0         1         2    0    1    2   \n",
       "0               2.223630e-16  0.461601  0.537134  0.001266  0.0  1.0  0.0   \n",
       "1               2.223630e-16  0.120333  0.877135  0.002532  0.0  1.0  0.0   \n",
       "2               5.031186e-01  0.000192  0.005501  0.994307  0.0  0.0  1.0   \n",
       "3               5.031186e-01  0.000097  0.001815  0.998088  0.0  0.0  1.0   \n",
       "4               2.223630e-16  0.729893  0.269725  0.000383  1.0  0.0  0.0   \n",
       "..                       ...       ...       ...       ...  ...  ...  ...   \n",
       "571             2.223630e-16  0.771925  0.227552  0.000523  1.0  0.0  0.0   \n",
       "572             2.223630e-16  0.709526  0.287658  0.002815  1.0  0.0  0.0   \n",
       "573             5.031511e-01  0.000191  0.012208  0.987600  0.0  0.0  1.0   \n",
       "574             2.223630e-16  0.599464  0.391220  0.009316  1.0  0.0  0.0   \n",
       "575             5.031511e-01  0.000482  0.878685  0.120832  0.0  0.0  1.0   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor    RF                    GB                      KNN             \n",
       "sample             0                     0                        0             \n",
       "class              0     1     2         0         1         2    0    1    2   \n",
       "0               0.51  0.49  0.00  0.446751  0.542124  0.011125  0.8  0.2  0.0   \n",
       "1               0.35  0.65  0.00  0.205477  0.780552  0.013971  0.6  0.4  0.0   \n",
       "2               0.00  0.04  0.96  0.004441  0.080650  0.914909  0.0  0.0  1.0   \n",
       "3               0.00  0.01  0.99  0.003233  0.107689  0.889078  0.0  0.2  0.8   \n",
       "4               0.89  0.11  0.00  0.656200  0.337153  0.006647  0.8  0.2  0.0   \n",
       "..               ...   ...   ...       ...       ...       ...  ...  ...  ...   \n",
       "571             0.71  0.29  0.00  0.832982  0.158148  0.008870  0.6  0.4  0.0   \n",
       "572             0.69  0.31  0.00  0.758846  0.231045  0.010109  0.8  0.2  0.0   \n",
       "573             0.00  0.10  0.90  0.003511  0.452824  0.543666  0.0  0.2  0.8   \n",
       "574             0.44  0.56  0.00  0.798176  0.192122  0.009702  0.4  0.6  0.0   \n",
       "575             0.00  0.50  0.50  0.004998  0.328224  0.666778  0.0  0.6  0.4   \n",
       "\n",
       "modality                                                          \\\n",
       "base predictor        LR                            NB             \n",
       "sample                 0                             0             \n",
       "class                  0         1         2         0         1   \n",
       "0               0.812660  0.179730  0.007610  0.705237  0.294760   \n",
       "1               0.643465  0.320709  0.035826  0.728743  0.270921   \n",
       "2               0.016252  0.182152  0.801596  0.000027  0.219851   \n",
       "3               0.017392  0.188231  0.794377  0.000033  0.219310   \n",
       "4               0.689093  0.285340  0.025567  0.737586  0.262294   \n",
       "..                   ...       ...       ...       ...       ...   \n",
       "571             0.583089  0.367700  0.049211  0.751509  0.247555   \n",
       "572             0.744517  0.242041  0.013442  0.733706  0.266279   \n",
       "573             0.025723  0.207135  0.767142  0.000044  0.205749   \n",
       "574             0.822668  0.171797  0.005535  0.525422  0.474577   \n",
       "575             0.275193  0.483138  0.241670  0.222495  0.541858   \n",
       "\n",
       "modality                                                              \\\n",
       "base predictor                     MLP                           SVM   \n",
       "sample                               0                             0   \n",
       "class                      2         0         1         2         0   \n",
       "0               3.893088e-06  0.757580  0.238677  0.003743  0.704742   \n",
       "1               3.361942e-04  0.651904  0.333255  0.014840  0.636935   \n",
       "2               7.801217e-01  0.002285  0.205562  0.792153  0.005052   \n",
       "3               7.806570e-01  0.002537  0.215564  0.781898  0.004159   \n",
       "4               1.199098e-04  0.676987  0.312717  0.010295  0.632066   \n",
       "..                       ...       ...       ...       ...       ...   \n",
       "571             9.359377e-04  0.629503  0.345457  0.025041  0.759947   \n",
       "572             1.542590e-05  0.670398  0.321818  0.007784  0.710672   \n",
       "573             7.942068e-01  0.002974  0.234306  0.762720  0.001675   \n",
       "574             4.761566e-07  0.672010  0.325162  0.002828  0.457654   \n",
       "575             2.356475e-01  0.307403  0.446939  0.245659  0.120573   \n",
       "\n",
       "modality                           Modality_2                              \\\n",
       "base predictor                           ADAB                               \n",
       "sample                                      0                               \n",
       "class                  1         2          0             1             2   \n",
       "0               0.286515  0.008744   0.496191  2.223908e-16  5.038085e-01   \n",
       "1               0.355380  0.007685   0.496820  5.031799e-01  2.222557e-16   \n",
       "2               0.318134  0.676815   0.496820  5.031799e-01  2.222557e-16   \n",
       "3               0.319830  0.676011   0.496191  2.223908e-16  5.038085e-01   \n",
       "4               0.361283  0.006652   0.496191  2.223908e-16  5.038085e-01   \n",
       "..                   ...       ...        ...           ...           ...   \n",
       "571             0.236493  0.003560   0.496942  5.030579e-01  2.222392e-16   \n",
       "572             0.284397  0.004932   0.496942  5.030579e-01  2.222392e-16   \n",
       "573             0.305228  0.693098   0.496066  2.223978e-16  5.039340e-01   \n",
       "574             0.519184  0.023162   0.496942  5.030579e-01  2.222392e-16   \n",
       "575             0.528285  0.351142   0.496066  2.223978e-16  5.039340e-01   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor       XGB                       DT              RF               \n",
       "sample                 0                        0               0               \n",
       "class                  0         1         2    0    1    2     0     1     2   \n",
       "0               0.034906  0.000094  0.965000  0.0  0.0  1.0  0.19  0.00  0.81   \n",
       "1               0.130016  0.868783  0.001201  0.0  1.0  0.0  0.27  0.73  0.00   \n",
       "2               0.678152  0.319825  0.002023  0.0  1.0  0.0  0.56  0.44  0.00   \n",
       "3               0.006253  0.000095  0.993652  0.0  0.0  1.0  0.06  0.00  0.94   \n",
       "4               0.559073  0.002290  0.438637  1.0  0.0  0.0  0.60  0.00  0.40   \n",
       "..                   ...       ...       ...  ...  ...  ...   ...   ...   ...   \n",
       "571             0.588948  0.409782  0.001270  1.0  0.0  0.0  0.54  0.46  0.00   \n",
       "572             0.105804  0.893397  0.000799  1.0  0.0  0.0  0.44  0.56  0.00   \n",
       "573             0.023767  0.001044  0.975189  0.0  0.0  1.0  0.25  0.00  0.75   \n",
       "574             0.097810  0.902037  0.000153  0.0  1.0  0.0  0.19  0.81  0.00   \n",
       "575             0.203063  0.001206  0.795730  0.0  0.0  1.0  0.28  0.00  0.72   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor        GB                      KNN                  LR   \n",
       "sample                 0                        0                   0   \n",
       "class                  0         1         2    0    1    2         0   \n",
       "0               0.190731  0.005388  0.803881  0.4  0.0  0.6  0.402319   \n",
       "1               0.616100  0.379187  0.004714  0.2  0.8  0.0  0.381799   \n",
       "2               0.427438  0.565553  0.007009  0.4  0.6  0.0  0.303977   \n",
       "3               0.076960  0.002392  0.920648  0.2  0.0  0.8  0.328162   \n",
       "4               0.256467  0.006856  0.736677  0.2  0.0  0.8  0.334040   \n",
       "..                   ...       ...       ...  ...  ...  ...       ...   \n",
       "571             0.523892  0.470108  0.005999  0.6  0.4  0.0  0.410048   \n",
       "572             0.243999  0.750289  0.005711  0.4  0.6  0.0  0.267849   \n",
       "573             0.119909  0.010660  0.869431  0.2  0.0  0.8  0.270401   \n",
       "574             0.220555  0.774808  0.004636  0.2  0.8  0.0  0.428953   \n",
       "575             0.313755  0.009906  0.676339  0.2  0.0  0.8  0.343435   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor                            NB                           MLP   \n",
       "sample                                     0                             0   \n",
       "class                  1         2         0         1         2         0   \n",
       "0               0.113573  0.484108  0.293706  0.014156  0.692139  0.344770   \n",
       "1               0.527239  0.090961  0.271800  0.725416  0.002784  0.356892   \n",
       "2               0.650942  0.045081  0.253442  0.746303  0.000256  0.341900   \n",
       "3               0.063236  0.608602  0.230185  0.003556  0.766259  0.322704   \n",
       "4               0.064163  0.601797  0.238629  0.002247  0.759124  0.334455   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "571             0.507348  0.082605  0.319283  0.676623  0.004094  0.366665   \n",
       "572             0.711016  0.021135  0.278899  0.721085  0.000017  0.341974   \n",
       "573             0.039299  0.690299  0.222018  0.000400  0.777582  0.285722   \n",
       "574             0.470013  0.101034  0.356938  0.632894  0.010168  0.380057   \n",
       "575             0.070899  0.585666  0.241844  0.002259  0.755897  0.324260   \n",
       "\n",
       "modality                                                         labels  \n",
       "base predictor                           SVM                             \n",
       "sample                                     0                             \n",
       "class                  1         2         0         1         2         \n",
       "0               0.058037  0.597193  0.235021  0.003676  0.761303      0  \n",
       "1               0.614702  0.028406  0.314243  0.683171  0.002586      0  \n",
       "2               0.651430  0.006671  0.335281  0.662332  0.002388      1  \n",
       "3               0.029860  0.647435  0.191561  0.002338  0.806101      2  \n",
       "4               0.027040  0.638505  0.235444  0.001804  0.762752      0  \n",
       "..                   ...       ...       ...       ...       ...    ...  \n",
       "571             0.608913  0.024422  0.286633  0.711375  0.001992      0  \n",
       "572             0.653626  0.004401  0.324069  0.671813  0.004119      0  \n",
       "573             0.017523  0.696755  0.276874  0.003653  0.719473      2  \n",
       "574             0.586231  0.033712  0.292738  0.702961  0.004301      0  \n",
       "575             0.036452  0.639288  0.273303  0.004605  0.722092      2  \n",
       "\n",
       "[576 rows x 91 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_0</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_1</th>\n",
       "      <th colspan=\"30\" halign=\"left\">Modality_2</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ADAB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XGB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DT</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RF</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">KNN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">NB</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MLP</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.223189e-16</td>\n",
       "      <td>5.035294e-01</td>\n",
       "      <td>0.496471</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.720623</td>\n",
       "      <td>0.278758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.731360</td>\n",
       "      <td>0.261460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.015874</td>\n",
       "      <td>0.766577</td>\n",
       "      <td>0.217548</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.769516</td>\n",
       "      <td>0.230457</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.728071</td>\n",
       "      <td>0.268918</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.308256</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>0.968510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.442907</td>\n",
       "      <td>0.550936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.062645</td>\n",
       "      <td>0.332167</td>\n",
       "      <td>0.605188</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.246503</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.312141</td>\n",
       "      <td>0.675923</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.321329</td>\n",
       "      <td>0.676580</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.908271</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.562974</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.426065</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.443625</td>\n",
       "      <td>0.161026</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.412818</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.521374</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.098474</td>\n",
       "      <td>0.551626</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.582502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.219468</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.775102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.534920</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.456517</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.445201</td>\n",
       "      <td>0.090013</td>\n",
       "      <td>0.464786</td>\n",
       "      <td>0.622085</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>0.555652</td>\n",
       "      <td>0.052631</td>\n",
       "      <td>0.391717</td>\n",
       "      <td>0.636889</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.350295</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.844419</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.525537</td>\n",
       "      <td>0.468141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.061354</td>\n",
       "      <td>0.332486</td>\n",
       "      <td>0.606160</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.240839</td>\n",
       "      <td>0.757716</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.320727</td>\n",
       "      <td>0.667721</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.304024</td>\n",
       "      <td>0.694727</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.784510</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.214130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.381531</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.611428</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.160084</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.827499</td>\n",
       "      <td>0.254391</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.745556</td>\n",
       "      <td>0.272021</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.724295</td>\n",
       "      <td>0.283650</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.709450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.732608</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.707335</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.285682</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.801036</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>0.184152</td>\n",
       "      <td>0.780021</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.219927</td>\n",
       "      <td>0.726409</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.686473</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.307403</td>\n",
       "      <td>5.037331e-01</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>2.223411e-16</td>\n",
       "      <td>0.465257</td>\n",
       "      <td>0.533994</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.757383</td>\n",
       "      <td>0.233014</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633054</td>\n",
       "      <td>0.328613</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.238771</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.656826</td>\n",
       "      <td>0.328632</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.705697</td>\n",
       "      <td>0.291707</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.765530</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.234118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.614759</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.381359</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.191402</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.791778</td>\n",
       "      <td>0.267024</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.732901</td>\n",
       "      <td>0.293355</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.702068</td>\n",
       "      <td>0.307633</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.876348</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.123398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.850283</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.260913</td>\n",
       "      <td>0.198842</td>\n",
       "      <td>0.540244</td>\n",
       "      <td>0.301386</td>\n",
       "      <td>0.114217</td>\n",
       "      <td>0.584397</td>\n",
       "      <td>0.258367</td>\n",
       "      <td>0.243032</td>\n",
       "      <td>0.498601</td>\n",
       "      <td>0.265139</td>\n",
       "      <td>0.186146</td>\n",
       "      <td>0.548715</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.770131</td>\n",
       "      <td>0.106752</td>\n",
       "      <td>0.123117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.150026</td>\n",
       "      <td>0.846710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.280249</td>\n",
       "      <td>0.488608</td>\n",
       "      <td>0.231143</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.539250</td>\n",
       "      <td>0.190350</td>\n",
       "      <td>0.347345</td>\n",
       "      <td>0.428086</td>\n",
       "      <td>0.224569</td>\n",
       "      <td>0.270439</td>\n",
       "      <td>0.465189</td>\n",
       "      <td>0.264373</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.120875</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.876084</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.455666</td>\n",
       "      <td>0.198010</td>\n",
       "      <td>0.346325</td>\n",
       "      <td>0.468849</td>\n",
       "      <td>0.142448</td>\n",
       "      <td>0.388703</td>\n",
       "      <td>0.393194</td>\n",
       "      <td>0.156214</td>\n",
       "      <td>0.450592</td>\n",
       "      <td>0.555346</td>\n",
       "      <td>0.069046</td>\n",
       "      <td>0.375608</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.492079</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.507294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.272582</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.717821</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.805281</td>\n",
       "      <td>0.012175</td>\n",
       "      <td>0.182545</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.714202</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.283443</td>\n",
       "      <td>0.684181</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.309324</td>\n",
       "      <td>5.037331e-01</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>2.223411e-16</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.204328</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.727153</td>\n",
       "      <td>0.267495</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557519</td>\n",
       "      <td>0.379345</td>\n",
       "      <td>0.063136</td>\n",
       "      <td>0.719914</td>\n",
       "      <td>0.277717</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.631407</td>\n",
       "      <td>0.343918</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>0.732465</td>\n",
       "      <td>0.264654</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263961</td>\n",
       "      <td>0.037628</td>\n",
       "      <td>0.698411</td>\n",
       "      <td>0.204523</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.794454</td>\n",
       "      <td>0.285422</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.702337</td>\n",
       "      <td>0.232020</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.765230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.598946</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.399808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.562459</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.429612</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.660310</td>\n",
       "      <td>0.035683</td>\n",
       "      <td>0.304007</td>\n",
       "      <td>0.757708</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.241745</td>\n",
       "      <td>0.687454</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.303047</td>\n",
       "      <td>0.691182</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>5.037331e-01</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>2.223411e-16</td>\n",
       "      <td>0.380407</td>\n",
       "      <td>0.619274</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.400438</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434019</td>\n",
       "      <td>0.453015</td>\n",
       "      <td>0.112966</td>\n",
       "      <td>0.602076</td>\n",
       "      <td>0.376522</td>\n",
       "      <td>0.021402</td>\n",
       "      <td>0.598784</td>\n",
       "      <td>0.334281</td>\n",
       "      <td>0.066936</td>\n",
       "      <td>0.673849</td>\n",
       "      <td>0.311067</td>\n",
       "      <td>0.015083</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.986214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.425577</td>\n",
       "      <td>0.141522</td>\n",
       "      <td>0.432901</td>\n",
       "      <td>0.377372</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.572277</td>\n",
       "      <td>0.318369</td>\n",
       "      <td>0.071767</td>\n",
       "      <td>0.609864</td>\n",
       "      <td>0.376655</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.608749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5.034139e-01</td>\n",
       "      <td>2.222883e-16</td>\n",
       "      <td>0.496586</td>\n",
       "      <td>0.895722</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.103899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.676814</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.721730</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.263578</td>\n",
       "      <td>0.681658</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.318310</td>\n",
       "      <td>0.672675</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.322580</td>\n",
       "      <td>0.678148</td>\n",
       "      <td>0.013602</td>\n",
       "      <td>0.308251</td>\n",
       "      <td>5.037331e-01</td>\n",
       "      <td>0.496267</td>\n",
       "      <td>2.223411e-16</td>\n",
       "      <td>0.979047</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.789191</td>\n",
       "      <td>0.207425</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.472125</td>\n",
       "      <td>0.174863</td>\n",
       "      <td>0.442759</td>\n",
       "      <td>0.487746</td>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.502833</td>\n",
       "      <td>0.383264</td>\n",
       "      <td>0.113902</td>\n",
       "      <td>0.629780</td>\n",
       "      <td>0.349123</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.067536</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.931972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.120218</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.872058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.731435</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.777019</td>\n",
       "      <td>0.293802</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.697751</td>\n",
       "      <td>0.282284</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.716424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2.223189e-16</td>\n",
       "      <td>5.035294e-01</td>\n",
       "      <td>0.496471</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.628569</td>\n",
       "      <td>0.370825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.713472</td>\n",
       "      <td>0.280984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.190736</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.535441</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.266462</td>\n",
       "      <td>0.596738</td>\n",
       "      <td>0.133570</td>\n",
       "      <td>0.382941</td>\n",
       "      <td>0.483489</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>0.427876</td>\n",
       "      <td>0.514744</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.148884</td>\n",
       "      <td>0.849675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.004522</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>0.883856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.145438</td>\n",
       "      <td>0.844771</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.266566</td>\n",
       "      <td>0.733430</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.241926</td>\n",
       "      <td>0.757403</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.306077</td>\n",
       "      <td>0.689945</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.109366</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.890257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.359522</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.630501</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.150108</td>\n",
       "      <td>0.412529</td>\n",
       "      <td>0.392514</td>\n",
       "      <td>0.051587</td>\n",
       "      <td>0.555899</td>\n",
       "      <td>0.337723</td>\n",
       "      <td>0.083950</td>\n",
       "      <td>0.578327</td>\n",
       "      <td>0.363116</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>0.623206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2.223189e-16</td>\n",
       "      <td>5.035294e-01</td>\n",
       "      <td>0.496471</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.901953</td>\n",
       "      <td>0.097772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.654730</td>\n",
       "      <td>0.339645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.159464</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.721223</td>\n",
       "      <td>0.278774</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.754727</td>\n",
       "      <td>0.244020</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.689814</td>\n",
       "      <td>0.302774</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.881385</td>\n",
       "      <td>0.117442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.616826</td>\n",
       "      <td>0.374963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.461152</td>\n",
       "      <td>0.355048</td>\n",
       "      <td>0.074223</td>\n",
       "      <td>0.485933</td>\n",
       "      <td>0.439845</td>\n",
       "      <td>0.134681</td>\n",
       "      <td>0.462223</td>\n",
       "      <td>0.403096</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.536763</td>\n",
       "      <td>0.392430</td>\n",
       "      <td>0.496688</td>\n",
       "      <td>5.033118e-01</td>\n",
       "      <td>2.222723e-16</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137506</td>\n",
       "      <td>0.854570</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308509</td>\n",
       "      <td>0.650478</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.250095</td>\n",
       "      <td>0.749646</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.341602</td>\n",
       "      <td>0.652026</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.323515</td>\n",
       "      <td>0.675633</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2.223189e-16</td>\n",
       "      <td>5.035294e-01</td>\n",
       "      <td>0.496471</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.853588</td>\n",
       "      <td>0.145850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.618650</td>\n",
       "      <td>0.372683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.665495</td>\n",
       "      <td>0.309077</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.729249</td>\n",
       "      <td>0.270567</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.640442</td>\n",
       "      <td>0.354185</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.693722</td>\n",
       "      <td>0.304278</td>\n",
       "      <td>2.222654e-16</td>\n",
       "      <td>0.496788</td>\n",
       "      <td>5.032118e-01</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>0.900618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.482717</td>\n",
       "      <td>0.509897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.100848</td>\n",
       "      <td>0.408252</td>\n",
       "      <td>0.490900</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.314138</td>\n",
       "      <td>0.678312</td>\n",
       "      <td>0.031035</td>\n",
       "      <td>0.368524</td>\n",
       "      <td>0.600440</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.294211</td>\n",
       "      <td>0.704024</td>\n",
       "      <td>0.496301</td>\n",
       "      <td>2.223652e-16</td>\n",
       "      <td>5.036992e-01</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.976695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.885791</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.460586</td>\n",
       "      <td>0.205796</td>\n",
       "      <td>0.333617</td>\n",
       "      <td>0.479250</td>\n",
       "      <td>0.149968</td>\n",
       "      <td>0.370782</td>\n",
       "      <td>0.400836</td>\n",
       "      <td>0.172430</td>\n",
       "      <td>0.426734</td>\n",
       "      <td>0.552639</td>\n",
       "      <td>0.075290</td>\n",
       "      <td>0.372071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality          Modality_0                                              \\\n",
       "base predictor          ADAB                               XGB             \n",
       "sample                     0                                 0             \n",
       "class                      0             1         2         0         1   \n",
       "0               2.223189e-16  5.035294e-01  0.496471  0.000618  0.720623   \n",
       "1               5.034139e-01  2.222883e-16  0.496586  0.219468  0.005430   \n",
       "2               5.034139e-01  2.222883e-16  0.496586  0.732608  0.000160   \n",
       "3               5.034139e-01  2.222883e-16  0.496586  0.876348  0.000254   \n",
       "4               5.034139e-01  2.222883e-16  0.496586  0.492079  0.000627   \n",
       "..                       ...           ...       ...       ...       ...   \n",
       "139             5.034139e-01  2.222883e-16  0.496586  0.598946  0.001246   \n",
       "140             5.034139e-01  2.222883e-16  0.496586  0.895722  0.000379   \n",
       "141             2.223189e-16  5.035294e-01  0.496471  0.000606  0.628569   \n",
       "142             2.223189e-16  5.035294e-01  0.496471  0.000275  0.901953   \n",
       "143             2.223189e-16  5.035294e-01  0.496471  0.000562  0.853588   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.278758  0.0  1.0  0.0  0.00  0.83  0.17  0.007180  0.731360   \n",
       "1               0.775102  0.0  0.0  1.0  0.24  0.00  0.76  0.534920  0.008563   \n",
       "2               0.267231  1.0  0.0  0.0  0.70  0.00  0.30  0.707335  0.006983   \n",
       "3               0.123398  1.0  0.0  0.0  0.76  0.00  0.24  0.850283  0.002924   \n",
       "4               0.507294  0.0  0.0  1.0  0.63  0.00  0.37  0.272582  0.009598   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "139             0.399808  1.0  0.0  0.0  0.65  0.01  0.34  0.562459  0.007929   \n",
       "140             0.103899  1.0  0.0  0.0  0.72  0.00  0.28  0.676814  0.001660   \n",
       "141             0.370825  0.0  1.0  0.0  0.00  0.74  0.26  0.005543  0.713472   \n",
       "142             0.097772  0.0  1.0  0.0  0.01  0.75  0.24  0.005624  0.654730   \n",
       "143             0.145850  0.0  1.0  0.0  0.00  0.53  0.47  0.008667  0.618650   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.261460  0.0  0.8  0.2  0.015874  0.766577  0.217548   \n",
       "1               0.456517  0.6  0.0  0.4  0.445201  0.090013  0.464786   \n",
       "2               0.285682  0.8  0.0  0.2  0.801036  0.014812  0.184152   \n",
       "3               0.146793  0.6  0.0  0.4  0.260913  0.198842  0.540244   \n",
       "4               0.717821  0.8  0.0  0.2  0.805281  0.012175  0.182545   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "139             0.429612  0.4  0.0  0.6  0.660310  0.035683  0.304007   \n",
       "140             0.321527  0.6  0.0  0.4  0.721730  0.014693  0.263578   \n",
       "141             0.280984  0.0  0.8  0.2  0.190736  0.273824  0.535441   \n",
       "142             0.339645  0.0  0.8  0.2  0.007671  0.832865  0.159464   \n",
       "143             0.372683  0.0  0.6  0.4  0.025428  0.665495  0.309077   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.000027  0.769516  0.230457  0.003011  0.728071  0.268918   \n",
       "1               0.622085  0.008826  0.369089  0.555652  0.052631  0.391717   \n",
       "2               0.780021  0.000052  0.219927  0.726409  0.002624  0.270968   \n",
       "3               0.301386  0.114217  0.584397  0.258367  0.243032  0.498601   \n",
       "4               0.743119  0.000028  0.256853  0.714202  0.002355  0.283443   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "139             0.757708  0.000547  0.241745  0.687454  0.009499  0.303047   \n",
       "140             0.681658  0.000031  0.318310  0.672675  0.004744  0.322580   \n",
       "141             0.136800  0.266462  0.596738  0.133570  0.382941  0.483489   \n",
       "142             0.000003  0.721223  0.278774  0.001253  0.754727  0.244020   \n",
       "143             0.000184  0.729249  0.270567  0.005373  0.640442  0.354185   \n",
       "\n",
       "modality                                        Modality_1            \\\n",
       "base predictor       SVM                              ADAB             \n",
       "sample                 0                                 0             \n",
       "class                  0         1         2             0         1   \n",
       "0               0.002542  0.689202  0.308256  2.222654e-16  0.496788   \n",
       "1               0.636889  0.012816  0.350295  2.222654e-16  0.496788   \n",
       "2               0.686473  0.006124  0.307403  5.037331e-01  0.496267   \n",
       "3               0.265139  0.186146  0.548715  2.222654e-16  0.496788   \n",
       "4               0.684181  0.006495  0.309324  5.037331e-01  0.496267   \n",
       "..                   ...       ...       ...           ...       ...   \n",
       "139             0.691182  0.003897  0.304922  5.037331e-01  0.496267   \n",
       "140             0.678148  0.013602  0.308251  5.037331e-01  0.496267   \n",
       "141             0.057380  0.427876  0.514744  2.222654e-16  0.496788   \n",
       "142             0.007412  0.689814  0.302774  2.222654e-16  0.496788   \n",
       "143             0.002000  0.693722  0.304278  2.222654e-16  0.496788   \n",
       "\n",
       "modality                                                                   \\\n",
       "base predictor                     XGB                       DT             \n",
       "sample                               0                        0             \n",
       "class                      2         0         1         2    0    1    2   \n",
       "0               5.032118e-01  0.000556  0.030934  0.968510  0.0  0.0  1.0   \n",
       "1               5.032118e-01  0.000828  0.844419  0.154753  0.0  1.0  0.0   \n",
       "2               2.223411e-16  0.465257  0.533994  0.000749  1.0  0.0  0.0   \n",
       "3               5.032118e-01  0.770131  0.106752  0.123117  0.0  0.0  1.0   \n",
       "4               2.223411e-16  0.795016  0.204328  0.000656  1.0  0.0  0.0   \n",
       "..                       ...       ...       ...       ...  ...  ...  ...   \n",
       "139             2.223411e-16  0.380407  0.619274  0.000319  0.0  1.0  0.0   \n",
       "140             2.223411e-16  0.979047  0.020876  0.000077  1.0  0.0  0.0   \n",
       "141             5.032118e-01  0.001441  0.148884  0.849675  0.0  0.0  1.0   \n",
       "142             5.032118e-01  0.001173  0.881385  0.117442  0.0  1.0  0.0   \n",
       "143             5.032118e-01  0.000113  0.099269  0.900618  0.0  0.0  1.0   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor    RF                    GB                      KNN             \n",
       "sample             0                     0                        0             \n",
       "class              0     1     2         0         1         2    0    1    2   \n",
       "0               0.00  0.05  0.95  0.006157  0.442907  0.550936  0.0  0.2  0.8   \n",
       "1               0.00  0.79  0.21  0.006322  0.525537  0.468141  0.0  0.6  0.4   \n",
       "2               0.68  0.32  0.00  0.757383  0.233014  0.009603  0.6  0.4  0.0   \n",
       "3               0.05  0.35  0.60  0.003264  0.150026  0.846710  0.0  0.2  0.8   \n",
       "4               0.64  0.36  0.00  0.727153  0.267495  0.005352  0.6  0.4  0.0   \n",
       "..               ...   ...   ...       ...       ...       ...  ...  ...  ...   \n",
       "139             0.75  0.25  0.00  0.596115  0.400438  0.003447  0.8  0.2  0.0   \n",
       "140             0.92  0.08  0.00  0.789191  0.207425  0.003384  1.0  0.0  0.0   \n",
       "141             0.00  0.16  0.84  0.004522  0.111622  0.883856  0.0  0.0  1.0   \n",
       "142             0.01  0.78  0.21  0.008211  0.616826  0.374963  0.0  0.4  0.6   \n",
       "143             0.00  0.38  0.62  0.007386  0.482717  0.509897  0.0  0.4  0.6   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        LR                            NB                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.062645  0.332167  0.605188  0.001618  0.246503  0.751880   \n",
       "1               0.061354  0.332486  0.606160  0.001445  0.240839  0.757716   \n",
       "2               0.633054  0.328613  0.038332  0.760700  0.238771  0.000530   \n",
       "3               0.280249  0.488608  0.231143  0.270400  0.539250  0.190350   \n",
       "4               0.557519  0.379345  0.063136  0.719914  0.277717  0.002369   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "139             0.434019  0.453015  0.112966  0.602076  0.376522  0.021402   \n",
       "140             0.353012  0.472125  0.174863  0.442759  0.487746  0.069495   \n",
       "141             0.009791  0.145438  0.844771  0.000004  0.266566  0.733430   \n",
       "142             0.183800  0.461152  0.355048  0.074223  0.485933  0.439845   \n",
       "143             0.100848  0.408252  0.490900  0.007549  0.314138  0.678312   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor       MLP                           SVM                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.011936  0.312141  0.675923  0.002091  0.321329  0.676580   \n",
       "1               0.011552  0.320727  0.667721  0.001249  0.304024  0.694727   \n",
       "2               0.656826  0.328632  0.014543  0.705697  0.291707  0.002596   \n",
       "3               0.347345  0.428086  0.224569  0.270439  0.465189  0.264373   \n",
       "4               0.631407  0.343918  0.024675  0.732465  0.264654  0.002881   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "139             0.598784  0.334281  0.066936  0.673849  0.311067  0.015083   \n",
       "140             0.502833  0.383264  0.113902  0.629780  0.349123  0.021098   \n",
       "141             0.000672  0.241926  0.757403  0.003978  0.306077  0.689945   \n",
       "142             0.134681  0.462223  0.403096  0.070806  0.536763  0.392430   \n",
       "143             0.031035  0.368524  0.600440  0.001766  0.294211  0.704024   \n",
       "\n",
       "modality       Modality_2                                                  \\\n",
       "base predictor       ADAB                                   XGB             \n",
       "sample                  0                                     0             \n",
       "class                   0             1             2         0         1   \n",
       "0                0.496301  2.223652e-16  5.036992e-01  0.908271  0.002862   \n",
       "1                0.496301  2.223652e-16  5.036992e-01  0.784510  0.001360   \n",
       "2                0.496301  2.223652e-16  5.036992e-01  0.765530  0.000351   \n",
       "3                0.496301  2.223652e-16  5.036992e-01  0.016474  0.000094   \n",
       "4                0.496301  2.223652e-16  5.036992e-01  0.008265  0.000167   \n",
       "..                    ...           ...           ...       ...       ...   \n",
       "139              0.496301  2.223652e-16  5.036992e-01  0.013676  0.000110   \n",
       "140              0.496301  2.223652e-16  5.036992e-01  0.067536  0.000492   \n",
       "141              0.496301  2.223652e-16  5.036992e-01  0.109366  0.000377   \n",
       "142              0.496688  5.033118e-01  2.222723e-16  0.089760  0.910099   \n",
       "143              0.496301  2.223652e-16  5.036992e-01  0.023143  0.000163   \n",
       "\n",
       "modality                                                                       \\\n",
       "base predictor             DT              RF                    GB             \n",
       "sample                      0               0                     0             \n",
       "class                  2    0    1    2     0     1     2         0         1   \n",
       "0               0.088867  1.0  0.0  0.0  0.62  0.00  0.38  0.562974  0.010962   \n",
       "1               0.214130  1.0  0.0  0.0  0.50  0.01  0.49  0.381531  0.007041   \n",
       "2               0.234118  1.0  0.0  0.0  0.66  0.00  0.34  0.614759  0.003882   \n",
       "3               0.983433  1.0  0.0  0.0  0.30  0.00  0.70  0.120875  0.003040   \n",
       "4               0.991569  0.0  0.0  1.0  0.15  0.00  0.85  0.088668  0.004193   \n",
       "..                   ...  ...  ...  ...   ...   ...   ...       ...       ...   \n",
       "139             0.986214  0.0  0.0  1.0  0.11  0.00  0.89  0.246981  0.006279   \n",
       "140             0.931972  0.0  0.0  1.0  0.08  0.00  0.92  0.120218  0.007723   \n",
       "141             0.890257  0.0  0.0  1.0  0.29  0.00  0.71  0.359522  0.009978   \n",
       "142             0.000141  0.0  1.0  0.0  0.18  0.82  0.00  0.137506  0.854570   \n",
       "143             0.976695  0.0  0.0  1.0  0.11  0.00  0.89  0.110131  0.004078   \n",
       "\n",
       "modality                                                               \\\n",
       "base predictor            KNN                  LR                       \n",
       "sample                      0                   0                       \n",
       "class                  2    0    1    2         0         1         2   \n",
       "0               0.426065  0.6  0.0  0.4  0.443625  0.161026  0.395349   \n",
       "1               0.611428  0.4  0.0  0.6  0.160084  0.012417  0.827499   \n",
       "2               0.381359  0.6  0.0  0.4  0.191402  0.016820  0.791778   \n",
       "3               0.876084  0.6  0.0  0.4  0.455666  0.198010  0.346325   \n",
       "4               0.907138  0.0  0.0  1.0  0.263961  0.037628  0.698411   \n",
       "..                   ...  ...  ...  ...       ...       ...       ...   \n",
       "139             0.746740  0.2  0.0  0.8  0.425577  0.141522  0.432901   \n",
       "140             0.872058  0.0  0.0  1.0  0.239997  0.028569  0.731435   \n",
       "141             0.630501  0.4  0.0  0.6  0.437364  0.150108  0.412529   \n",
       "142             0.007924  0.2  0.8  0.0  0.308509  0.650478  0.041013   \n",
       "143             0.885791  0.6  0.0  0.4  0.460586  0.205796  0.333617   \n",
       "\n",
       "modality                                                                    \\\n",
       "base predictor        NB                           MLP                       \n",
       "sample                 0                             0                       \n",
       "class                  0         1         2         0         1         2   \n",
       "0               0.412818  0.065808  0.521374  0.349900  0.098474  0.551626   \n",
       "1               0.254391  0.000053  0.745556  0.272021  0.003683  0.724295   \n",
       "2               0.267024  0.000076  0.732901  0.293355  0.004577  0.702068   \n",
       "3               0.468849  0.142448  0.388703  0.393194  0.156214  0.450592   \n",
       "4               0.204523  0.001023  0.794454  0.285422  0.012241  0.702337   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "139             0.377372  0.050351  0.572277  0.318369  0.071767  0.609864   \n",
       "140             0.222622  0.000360  0.777019  0.293802  0.008447  0.697751   \n",
       "141             0.392514  0.051587  0.555899  0.337723  0.083950  0.578327   \n",
       "142             0.250095  0.749646  0.000259  0.341602  0.652026  0.006372   \n",
       "143             0.479250  0.149968  0.370782  0.400836  0.172430  0.426734   \n",
       "\n",
       "modality                                     labels  \n",
       "base predictor       SVM                             \n",
       "sample                 0                             \n",
       "class                  0         1         2         \n",
       "0               0.398528  0.018970  0.582502      2  \n",
       "1               0.283650  0.006901  0.709450      2  \n",
       "2               0.307633  0.001984  0.690382      0  \n",
       "3               0.555346  0.069046  0.375608      2  \n",
       "4               0.232020  0.002750  0.765230      0  \n",
       "..                   ...       ...       ...    ...  \n",
       "139             0.376655  0.014596  0.608749      0  \n",
       "140             0.282284  0.001291  0.716424      0  \n",
       "141             0.363116  0.013678  0.623206      2  \n",
       "142             0.323515  0.675633  0.000853      1  \n",
       "143             0.552639  0.075290  0.372071      2  \n",
       "\n",
       "[144 rows x 91 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.meta_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     (Modality_0, ADAB, 0)  (Modality_0, DT, 0)  (Modality_0, GB, 0)  \\\n",
      "0                        1                    1                    1   \n",
      "1                        0                    2                    0   \n",
      "2                        0                    0                    0   \n",
      "3                        0                    0                    0   \n",
      "4                        0                    2                    2   \n",
      "..                     ...                  ...                  ...   \n",
      "139                      0                    0                    0   \n",
      "140                      0                    0                    0   \n",
      "141                      1                    1                    1   \n",
      "142                      1                    1                    1   \n",
      "143                      1                    1                    1   \n",
      "\n",
      "     (Modality_0, KNN, 0)  (Modality_0, LR, 0)  (Modality_0, MLP, 0)  \\\n",
      "0                       1                    1                     1   \n",
      "1                       0                    2                     0   \n",
      "2                       0                    0                     0   \n",
      "3                       0                    2                     2   \n",
      "4                       0                    0                     0   \n",
      "..                    ...                  ...                   ...   \n",
      "139                     2                    0                     0   \n",
      "140                     0                    0                     0   \n",
      "141                     1                    2                     2   \n",
      "142                     1                    1                     1   \n",
      "143                     1                    1                     1   \n",
      "\n",
      "     (Modality_0, NB, 0)  (Modality_0, RF, 0)  (Modality_0, SVM, 0)  \\\n",
      "0                      1                    1                     1   \n",
      "1                      0                    2                     0   \n",
      "2                      0                    0                     0   \n",
      "3                      2                    0                     2   \n",
      "4                      0                    0                     0   \n",
      "..                   ...                  ...                   ...   \n",
      "139                    0                    0                     0   \n",
      "140                    0                    0                     0   \n",
      "141                    2                    1                     2   \n",
      "142                    1                    1                     1   \n",
      "143                    1                    1                     1   \n",
      "\n",
      "     (Modality_0, XGB, 0)  (Modality_1, ADAB, 0)  (Modality_1, DT, 0)  \\\n",
      "0                       1                      2                    2   \n",
      "1                       2                      2                    1   \n",
      "2                       0                      0                    0   \n",
      "3                       0                      2                    2   \n",
      "4                       2                      0                    0   \n",
      "..                    ...                    ...                  ...   \n",
      "139                     0                      0                    1   \n",
      "140                     0                      0                    0   \n",
      "141                     1                      2                    2   \n",
      "142                     1                      2                    1   \n",
      "143                     1                      2                    2   \n",
      "\n",
      "     (Modality_1, GB, 0)  (Modality_1, KNN, 0)  (Modality_1, LR, 0)  \\\n",
      "0                      2                     2                    2   \n",
      "1                      1                     1                    2   \n",
      "2                      0                     0                    0   \n",
      "3                      2                     2                    1   \n",
      "4                      0                     0                    0   \n",
      "..                   ...                   ...                  ...   \n",
      "139                    0                     0                    1   \n",
      "140                    0                     0                    1   \n",
      "141                    2                     2                    2   \n",
      "142                    1                     2                    1   \n",
      "143                    2                     2                    2   \n",
      "\n",
      "     (Modality_1, MLP, 0)  (Modality_1, NB, 0)  (Modality_1, RF, 0)  \\\n",
      "0                       2                    2                    2   \n",
      "1                       2                    2                    1   \n",
      "2                       0                    0                    0   \n",
      "3                       1                    1                    2   \n",
      "4                       0                    0                    0   \n",
      "..                    ...                  ...                  ...   \n",
      "139                     0                    0                    0   \n",
      "140                     0                    1                    0   \n",
      "141                     2                    2                    2   \n",
      "142                     1                    1                    1   \n",
      "143                     2                    2                    2   \n",
      "\n",
      "     (Modality_1, SVM, 0)  (Modality_1, XGB, 0)  (Modality_2, ADAB, 0)  \\\n",
      "0                       2                     2                      2   \n",
      "1                       2                     1                      2   \n",
      "2                       0                     1                      2   \n",
      "3                       1                     0                      2   \n",
      "4                       0                     0                      2   \n",
      "..                    ...                   ...                    ...   \n",
      "139                     0                     1                      2   \n",
      "140                     0                     0                      2   \n",
      "141                     2                     2                      2   \n",
      "142                     1                     1                      1   \n",
      "143                     2                     2                      2   \n",
      "\n",
      "     (Modality_2, DT, 0)  (Modality_2, GB, 0)  (Modality_2, KNN, 0)  \\\n",
      "0                      0                    0                     0   \n",
      "1                      0                    2                     2   \n",
      "2                      0                    0                     0   \n",
      "3                      0                    2                     0   \n",
      "4                      2                    2                     2   \n",
      "..                   ...                  ...                   ...   \n",
      "139                    2                    2                     2   \n",
      "140                    2                    2                     2   \n",
      "141                    2                    2                     2   \n",
      "142                    1                    1                     1   \n",
      "143                    2                    2                     0   \n",
      "\n",
      "     (Modality_2, LR, 0)  (Modality_2, MLP, 0)  (Modality_2, NB, 0)  \\\n",
      "0                      0                     2                    2   \n",
      "1                      2                     2                    2   \n",
      "2                      2                     2                    2   \n",
      "3                      0                     2                    0   \n",
      "4                      2                     2                    2   \n",
      "..                   ...                   ...                  ...   \n",
      "139                    2                     2                    2   \n",
      "140                    2                     2                    2   \n",
      "141                    0                     2                    2   \n",
      "142                    1                     1                    1   \n",
      "143                    0                     2                    0   \n",
      "\n",
      "     (Modality_2, RF, 0)  (Modality_2, SVM, 0)  (Modality_2, XGB, 0)  labels  \n",
      "0                      0                     2                     0       2  \n",
      "1                      0                     2                     0       2  \n",
      "2                      0                     2                     0       0  \n",
      "3                      2                     0                     2       2  \n",
      "4                      2                     2                     2       0  \n",
      "..                   ...                   ...                   ...     ...  \n",
      "139                    2                     2                     2       0  \n",
      "140                    2                     2                     2       0  \n",
      "141                    2                     2                     2       2  \n",
      "142                    1                     1                     1       1  \n",
      "143                    2                     0                     2       2  \n",
      "\n",
      "[144 rows x 31 columns]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "axis must be a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_937525/2301411486.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;31m# create a summary of base predictor performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mEI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_base_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eipy/eipy/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(meta_test_dataframe)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta_test_dataframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     meta_test_averaged_samples = pd.concat(\n\u001b[0;32m--> 140\u001b[0;31m         [\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta_test_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         ]\n",
      "\u001b[0;32m~/eipy/eipy/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mpred_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5254\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m250.0\u001b[0m   \u001b[0;36m150.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5255\u001b[0m         \u001b[0mfalcon\u001b[0m  \u001b[0mspeed\u001b[0m   \u001b[0;36m320.0\u001b[0m   \u001b[0;36m250.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5256\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5257\u001b[0m         \"\"\"\n\u001b[0;32m-> 5258\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5259\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5260\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5261\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4545\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4547\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4549\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4586\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4587\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4588\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis must be a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4589\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4590\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4591\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: axis must be a MultiIndex"
     ]
    }
   ],
   "source": [
    "# create a summary of base predictor performance\n",
    "EI.base_summary = ut.create_base_summary(EI.meta_test_data)\n",
    "EI.base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |          |  0%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/multi-class.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/multi-class.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m EI\u001b[39m.\u001b[39;49mtrain_meta(meta_predictors\u001b[39m=\u001b[39;49mbase_predictors)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/_testing.py:188\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    187\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategory)\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/eipy/eipy/ei.py:282\u001b[0m, in \u001b[0;36mEnsembleIntegration.train_meta\u001b[0;34m(self, meta_predictors)\u001b[0m\n\u001b[1;32m    278\u001b[0m         y_pred_combined\u001b[39m.\u001b[39mextend(y_pred)\n\u001b[1;32m    280\u001b[0m     meta_predictions[model_name] \u001b[39m=\u001b[39m y_pred_combined\n\u001b[1;32m    281\u001b[0m     performance_metrics\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 282\u001b[0m         scores(y_test_combined, y_pred_combined, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m meta_predictions[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m y_test_combined\n\u001b[1;32m    287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_predictions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(meta_predictions)\n",
      "File \u001b[0;32m~/eipy/eipy/utils.py:336\u001b[0m, in \u001b[0;36mscores\u001b[0;34m(y_true, y_pred, beta, metric_to_maximise, verbose)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[39mprint\u001b[39m(metric_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m, score[\u001b[39m0\u001b[39m])\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     precision_macro \u001b[39m=\u001b[39m precision_score(y_true, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    337\u001b[0m     recall_macro \u001b[39m=\u001b[39m recall_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    338\u001b[0m     f1_macro \u001b[39m=\u001b[39m f1_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     y_true,\n\u001b[1;32m   1827\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1834\u001b[0m ):\n\u001b[1;32m   1835\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1955\u001b[0m         y_true,\n\u001b[1;32m   1956\u001b[0m         y_pred,\n\u001b[1;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[1;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "EI.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = EI.predict(X_dict=data_test, meta_model_key=\"XGB\")\n",
    "y_pred = np.round(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred))])/len(y_test)\n",
    "accuracy # =179/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.meta_summary['thresholds'][\"XGB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "Modality_a = X[:, 0:2]\n",
    "Modality_b = X[:, 2:4]\n",
    "\n",
    "X_a_train, X_a_test, y_train, y_test = train_test_split(Modality_a, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_b_train, X_b_test, _,_ = train_test_split(Modality_b, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_train = {\n",
    "                \"Modality_a\": X_a_train,\n",
    "                \"Modality_b\": X_b_train\n",
    "                }\n",
    "\n",
    "iris_data_test = {\n",
    "                \"Modality_a\": X_a_test,\n",
    "                \"Modality_b\": X_b_test\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        random_state=0,\n",
    "                        project_name=\"iris\",\n",
    "                        model_building=True,\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, modality in iris_data_train.items():\n",
    "    EI_iris.train_base(modality, y_train, modality_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.meta_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.train_meta(meta_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI_iris.meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_iris = EI_iris.predict(X_dict=iris_data_test, meta_model_key=\"SVM\")\n",
    "y_pred_iris = np.round(y_pred_iris)\n",
    "y_pred_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, y_pred_iris))])/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary with 2D arrays as values\n",
    "data = {\n",
    "    'Column1': [np.array([1, 2]), np.array([3, 4]), np.array([5, 6])],\n",
    "    'Column2': [np.array([10, 20]), np.array([30, 40]), np.array([50, 60])]\n",
    "}\n",
    "\n",
    "# Create a DataFrame with MultiIndex\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate over the dictionary items and reshape 2D arrays into sub-columns\n",
    "for key, value in data.items():\n",
    "    num_cols = value[0].shape[0]  # Get the shape of the 2D array\n",
    "    print(num_cols)\n",
    "    for i in range(num_cols):\n",
    "        # Create sub-columns for each element of the 2D array\n",
    "        sub_column_name = f'SubColumn{i + 1}'\n",
    "        df[(key, sub_column_name)] = [row[i] for row in value]\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
